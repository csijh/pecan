<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-gb" xml:lang="en-gb">
<head>
<title>Pecan Manual</title>
<style>
  body { font-size: 120%; }
  pre, table, .indent { margin-left:40px; }
  table, th, td { border: 1px solid black; border-collapse: collapse; }
  table.char td:nth-child(2) { text-align: right; padding-right: 10px; }
</style>
</head>
<body>

<img src="pecan.png" width="300" height="65" />
<hr/>

<h1>Pecan Reference Manual</h1>

<ul>
<li><a href="#use">Using Pecan</a></li>
<li><a href="#intro">Background</a></li>
<ul>
<li><a href="#rd">Recursive descent</a></li>
<li><a href="#cfg">CFG grammars</a></li>
<li><a href="#peg">PEG grammars</a></li>
<li><a href="#pecan">Pecan grammars</a></li>
</ul>
<li><a href="#notation">Notation</a>
<ul>
<li><a href="#rules">Rules</a></li>
<li><a href="#comments">Comments</a></li>
<li><a href="#parentheses">Parentheses</a></li>
<li><a href="#continuations">Continuations</a></li>
<li><a href="#choices">Choices</a></li>
<li><a href="#sequences">Sequences</a></li>
<li><a href="#repetition">Repetition</a></li>
<li><a href="#lookahead">Lookahead</a></li>
<li><a href="#text">Text</a></li>
<li><a href="#escapes">Escapes</a></li>
<li><a href="#errors">Errors</a></li>
<li><a href="#actions">Actions</a></li>
<li><a href="#tokens">Tokens</a></li>
<li><a href="#literals">Literals</a></li>
</ul>
</li>
<li><a href="#testing">Testing</a></li>
<li><a href="#checks">Consistency checks</a>
<ul>
<li><a href="#loop">Left recursion checking</a></li>
<!--<li><a href="#token">Token checking</a></li>-->
<li><a href="#output">Output checking</a></li>
</ul>
<li><a href="#compile">Compilation</a>
<ul>
<li><a href="#functions">Recursive functions</a></li>
<li><a href="#code">Bytecode</a></li>
</ul>
</li>
</li>
<li><a href="#transforms">Transforms</a></li>
<li><a href="#changes">Recent changes</a></li>
</ul>

<h2 id="use">Using Pecan</h2>

<p>Pecan is a tool for developing and checking grammars, and generating scanners
and parsers. It is aimed at parsers for programming languages, <a
href="https://en.wikipedia.org/wiki/Domain-specific_language">domain specific
languages</a>, and other unambiguous computer languages. It provides a precise
grammar notation, which is independent of implementation language, based on
recursive descent with lookahead. This manual describes Pecan version 1.0 which
has these features:</p>

<ul>

<li>a grammar is an executable prototype parser</li>

<li>output actions and error markers are included</li>

<li>transformations on grammars preserve actions and error handling</li>

<li>many consistency checks are applied to grammars</li>

<li>there is support for development and testing of grammars</li>

<li>compilation can be direct or via bytecode</li>

<li>compilation can be to almost any target language</li>

</ul>

<p>Having a separate notation for grammars helps to focus attention on the
various issues that have to be addressed, separately from the programming
details. However, that also makes grammars rather dense. Creating or translating
a grammar accurately can be difficult. In addition, programmers typically use
parser generators only rarely, and are often not grammar experts. For those
reasons, Pecan has explicit support for test-driven grammar development.</p>

<p>The Pecan system is written in Java, so the first step is to make sure that
version 8 or better of Java is available. Pecan is provided as an executable jar
file <code>pecan.jar</code>. The jar file contains both the compiled program and
also the source code. If this jar file is downloaded, it can be run with:</p>

<pre>java -jar pecan.jar ...
</pre>

<p>However, it is more convenient to create a batch file or shell script, or use
an alias or equivalent, so that the program can be run just by typing:</p>

<pre>pecan ...
</pre>

<p>The way to do this differs from system to system.</p>

<p>To run tests on a grammar, type a command of the form:</p>

<pre>pecan [-t | -trace] [line] tests
</pre>

<p>To generate a bytecode version of a grammar, type a command with one of the
forms:</p>

<pre>pecan grammar -c program

pecan grammar -b program
</pre>

<p>The option <code>-c program</code> indicates that the grammar is to be
compiled to a set of recursive descent functions. The option <code>-b
program</code> indicates that the grammar is to be compiled into a bytecode
array. Either way, the program is a template in the desired target programming
language, into which the result of the compilation is embedded, to form a parser
or application program.</p>

<h2 id="intro">Background</h2>

<p>Other approaches to developing parsers are usually based on writing them
manually in the <a
href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive
descent</a> style, or using a parser generator based on the <a
href="http://en.wikipedia.org/wiki/Context-free_grammar">context free
grammar</a> (CFG) formalism, or the <a
href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing
expression grammar</a> (PEG) notation.</p>

<h3 id="rd">Recursive descent</h3>

<p>Recursive descent parsers have the advantage of being efficient, intuitive,
and capable of being hand-written. However, for large projects, parsers tend to
become repetitive and error prone. One of the main problems is that a simple
approach is hardly ever enough. In order to deal with the difficult cases which
arise in practice, extra features such as lookahead or backtracking are needed.
These extra features are often added in an ad hoc fashion on practical grounds,
which typically makes parsers complex, obscure and error-prone.</p>

<p>A library of <a href="http://en.wikipedia.org/wiki/Parser_combinator">parser
combinators</a> can ease the process of writing a parser in the recursive
descent style, by providing components which reduce verbosity and automate
features such as lookahead.  However, a combinator library typically still has
two problems. The first is that parsers have to be written in a specific
language in which the library is written, or to which the library has been
ported. The second is that there is typically no separate and independent
grammar, and so there is a shortage of analysis and development tools to help
with the development of parsers.</p>

<h3 id="cfg">CFG grammars</h3>

<p>The CFG notation (in the form of BNF and many variations) has been the main
formalism for grammars for a long time, and it has been well studied. However,
it has been argued quite strongly that it is not an ideal formalism
to use for unambiguous languages. According to <a
href="http://dl.acm.org/citation.cfm?id=964001.964011">Bryan Ford</a>:</p>

<blockquote>The power of generative grammars to express ambiguity is crucial to
their original purpose of modelling natural languages, but this very power makes
it unnecessarily difficult both to express and to parse machine-oriented
languages using CFGs.</blockquote>

<p>One fundamental theoretical problem is that CFG grammars can contain
ambiguities, and there is no computable algorithm to detect whether or not a
grammar is unambiguous. There is also the associated practical problem that many
published CFG grammars contain ambiguities. Some of these are local, i.e. a
particular rule allows two possible parses, but there is a surrounding, more
global, rule that resolves the ambiguity by only accepting one of the
possibilities. But many ambiguities in published grammars are inherent, the
ambiguity being resolved only by accompanying descriptive text or particular
approaches to generating parsers.</p>

<p>As well as ambiguity, there is also the problem that a CFG grammar describes
a language in a generative way, which is not directly and intuitively linked to
the recognition problem faced in parsing. Indeed the meaning of a grammar is
often different from the parser generated from it. There is an awkward semantic
gap.</p>

<p>Conventional CFG-based parser generators have a variety of other flaws,
partly due to the difficulties of the CFG formalism, and partly due to the age
of their designs. They often have arbitrary heuristic rules for disambiguation.
They often support a subset of CFG grammars which is not at all intuitive. They
often use bottom-up parsing techniques to make parsers near-linear, which makes
the way they operate impenetrable. And they often support actions and error
reporting using embedded code fragments which are not part of the grammar. The
code fragments are often restricted to a particular implementation language, and
the approach is any case very fragile.</p>

<p>These problems with the CFG formalism might be worth putting up with, if the
formalism had excellent theoretical or practical properties. But it doesn't.
For example, CFG grammars have poor composability properties, and poor closure
properties. And, in general, parsing CFG grammars takes O(n<sup>3</sup>) time in
the worst case.</p>

<h3 id="peg">PEG grammars</h3>

<p>The main difference with PEG grammars compared to CFG grammars is that the
symmetrical choice operator <code>|</code> is replaced by an ordered choice
operator <code>/</code> which has a more operational meaning. The expressive
power of PEG grammars is extremely close to that of CFG grammars. Certainly,
grammars for all practical everyday languages can be expressed in either
notation.</p>

<p>The theoretical and practical properties of the PEG formalism are far
superior to the CFG formalism. PEG grammars never contain any ambiguity, they
have a direct operational meaning as parsers, they are composable, they are
closed under many operations, and they can be parsed in linear time
using the packrat algorithm. This makes the PEG grammar formalism a much better
starting point for studying grammars and parsers.</p>

<p>Unfortunately, there are practical problems with PEG parsers. Although the
packrat algorithm is linear, it is slower and more space hungry than one would
like for efficient large scale parsing. Also, because of the implicit unlimited
backtracking, it can be difficult to understand or predict the operation of
PEGs, it is difficult to produce accurate error messages, and difficult to
express actions. As a result, PEG grammars are typically only used for search
expressions, or for small domain specific languages, and not for larger
applications such as full programming languages.</p>

<p>There is also a relatively minor problem with PEG grammars, which is that
they don't support left recursion. There have been attempts to add it, but the
results are not compelling. It is worth noting, though, that left recursion is
arguably unintuitive, that it would probably never have become common if it
weren't for the prevalence of CFG grammars, and that it is well known how to
transform it away. Most uses of left recursion are very simple, of the kind
<code>a = x | a y</code> which can be translated easily into <code>a = x
y*</code>.</p>

<h3 id="pecan">Pecan grammars</h3>

<p>Pecan provides a notation for grammars which is an adaptation of the PEG
notation to remove the implicit backtracking. Actions and markers for error
handling are easily embedded as symbols, independently of any target programming
language. Explicit lookahead features are provided to help in making choices,
but they don't involve actions or error handling, so a grammar closely
corresponds to conventional simple recursive descent.</p>

<p>Pecan provides direct support for parser development. Tools are provided to
aid in development and testing, including consistency checks on grammars,
features for automated testing, and the ability to execute grammars as symbolic
parsers.</p>

<p>Manual transformations can be carried out on grammars, e.g. to convert CFG
grammars into Pecan grammars or improve efficiency, and these preserve the
actions and error handling properties of generated parsers.</p>

<p>Once a grammar has been developed, it can either be used to guide the manual
construction of a parser, or to generate a parser automatically. A grammar can
be compiled into a collection of recursive descent functions, with very few
restrictions on the target language. Support for a new target language can be
constructed easily. A parser can also be generated as bytecode, with even fewer
restrictions on the target language. An interpreter for a new language can be
constructed fairly easily by translating one of the example interpreters
provided.</p>

<h2 id="notation">Notation</h2>

<p>The Pecan language is a grammar language for writing parsers, loosely based
on the <a href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">PEG</a>
notation. Pecan has a sequential choice operator <code>x/y</code> but, unlike
the PEG notation, the operator does not automatically involve backtracking.
There are separate lookahead operators, for the controlled use of backtracking,
which provide greater control over the progress of parsing. That makes it much
easier to generate accurate error messages, while having the full power of the
PEG notation available to decide between alternatives. The approach gives
programmers the expressiveness to make parsers efficient without relying on
obscure automatic optimisations, and parsers normally run without the space
overhead of such techniques as the PEG packrat algorithm. The syntax of Pecan
grammars is explained below. For reference, there is a Pecan grammar for the
Pecan language, with tests, in the files:</p>

<p class="indent"><a href="pecan.txt">pecan.txt</a><br/>
<a href="pecan-test.txt">pecan-test.txt</a></p>

<p>As with PEG grammars, any parsing expression within a grammar represents a
matching operation which succeeds or fails when applied at a particular position
in the input, and which may cause progress, i.e. may cause the current position
to move forwards in the input, according to how much of it is matched.</p>

<h3 id="rules">Rules</h3>

<p>A parser consists of a sequence of rules, each of which gives a name to a
parsing expression. By default, the first rule specifies the output of the
whole parsing process. For example, a parser might start with:</p>

<pre>module = function+ &lt;>

function = id arguments body

...
</pre>

<p>Apart from being the starting point of the parser, the first rule is not
treated in any special way. In particular, it may succeed without consuming all
the input. So an explicit test is often included, as here, to check that the end
of the input has been reached. The notation <code>&lt;></code> which is a less
than sign followed by a greater than sign, matches the end of the input.</p>

<p>An identifier introduced by a rule starts with a letter and continues with
letters, digits, hyphens or underscores. The text of a grammar is assumed to be
encoded using UTF-8, so Unicode letter and digit characters can be included.
There is also a literal form of identifier, consisting of arbitrary characters
in backquotes, which is described further in the section on literal names
below.</p>

<p>In place of a rule, an inclusion may be used:</p>

<pre>{expressions.txt}
</pre>

<p>This is a string giving a file name or path to another file of grammar rules
to be included at this point. This can help in presenting and testing large
grammars in a modular way.</p>

<p>If a parser fails, only the first failure is reported. There is no attempt to
recover. If error recovery is required, this can be accomplished by writing a
separate rule to be tried on the remaining input.</p>

<h3 id="comments">Comments</h3>

<p>Comments start with <code>--</code> and extend to the end of the line. For
example:</p>

<pre>-- A number is a sequence of one or more digits.
number = '0123456789'+
</pre>

<p>There is no multi-line comment convention.</p>

<h3 id="parentheses">Parentheses</h3>

<p>Parentheses, i.e. round brackets, have their usual meaning, indicating
grouping of operations. For example:</p>

<pre>(x / y) z
</pre>

<p>means parse <code>x</code> or <code>y</code>, then parse <code>z</code>, as
opposed to:</p>

<pre>x / y z
</pre>

<p>which means either parse <code>x</code>, or else parse <code>y</code> and
<code>z</code>.</p>

<h3 id="continuations">Continuations</h3>

<p>No explicit symbol is used to terminate a rule. A rule is terminated at the
end of a line, unless it is continued. A rule is continued on the next line if
the last token on the current line is an infix symbol or open bracket, i.e. one
of <code>=/([</code>. Here is an example rule where each line except the last
ends with <code>=</code> or the <code>/</code> operator:</p>

<pre>atom =
  id /
  number /
  bracket
</pre>

<p>Also, a rule is continued on the next line if the first token of the next
line is an infix symbol or close bracket, i.e. one of <code>=/)]</code>. This
allows an alternative style for a multi-line rule:</p>

<pre>atom
= id
/ number
/ bracket
</pre>

<p>In this example, each line that starts with <code>=</code> or <code>/</code>
is a continuation of the previous line.</p>

<h3 id="choices">Choices</h3>

<p>The choice operator <code>/</code> separates alternatives, which are tried
one after the other. For example:</p>

<pre>atom = id / number / bracket
</pre>

<p>If parsing of an alternative succeeds, then the parsing of the whole
expression succeeds. Otherwise, if no progress was made, the next alternative is
tried.</p>

<p>The choice operator involves a single item lookahead. If progress is made on
an alternative, i.e. at least one input character or token is matched, then the
parser is committed to that alternative, and further alternatives are not
tried.</p>

<p>There are separate lookahead operators which allow speculative parsing of an
alternative with backtracking.</p>

<h3 id="sequences">Sequences</h3>

<p>When items follow each other with no visible operator in between, this
indicates "followed by". For example:</p>

<pre>assignment = identifier "=" expression
</pre>

<p>This means that an assignment is an identifier followed by an equals sign
followed by an expression. The items are parsed one by one and, if parsing of
any item fails, parsing of the sequence is abandoned. Sequencing binds tighter
than the choice operator.</p>

<h3 id="repetition">Repetition</h3>

<p>There are three postfix repetition operators. The <code>*</code> operator
indicates that an item is to be repeated any number of times, i.e. zero or more
times. The <code>+</code> operator indicates that an item is to be repeated one
or more times. The <code>?</code> operator indicates that an item is optional,
i.e. repeated zero times or once. Postfix operators bind tighter than
sequencing, so <code>x y*</code> means <code>x (y*)</code>. Examples are:</p>

<pre>string = '"' stringchar* '"'
number = digit+
call = function "(" arguments? ")"
</pre>

<p>The <code>string</code> rule specifies that a string consists of a double
quote followed by any number of allowable characters followed by a closing
double quote. The <code>number</code> rule specifies that a number consists of
one or more digits. The <code>call</code> rule specifies that a call consists of
a function name followed by brackets, and the brackets may optionally contain
arguments.</p>

<p>The three expressions <code>x*</code>, <code>x+</code>, <code>x?</code> act
in exactly the same way as the three rules <code>xs</code>, <code>xp</code>,
<code>xq</code> defined by:</p>

<pre>xs = x xs / ""
xp = x (xp / "")
xq = x / ""
</pre>

<p>This means that <code>x*</code> or <code>x+</code> will accept as
many <code>x</code>'s as are present in the input. In all three cases, in line
with the fact that the choice operator does no backtracking by default, if
progress is made on a final <code>x</code> without success, the whole
expression fails.</p>

<h3 id="lookahead">Lookahead</h3>

<p>There are three lookahead constructs, the <dfn>see</dfn> operator
<code>[...]</code>, the <dfn>has</dfn> operator <code>&amp;</code> and the
<dfn>not</dfn> operator <code>!</code>.</p>

<p>The see operator (also called the try or commit operator) is specified using
square brackets. In an expression <code>[x]</code>, the subexpression
<code>x</code> is parsed speculatively. If it succeeds, parsing continues as
normal. If it fails, the parser backtracks to the point just before
<code>x</code>. The see operator is usually used to indicate the point at
which the parser should accept an alternative. For example:</p>

<pre>statement = [identifier "="] expression / ...
</pre>

<p>This specifies that if the parser sees an identifier and equal sign, then it
should commit to the first alternative. If an error occurs before that, e.g. an
identifier has been matched but there is no equal sign, backtracking is done by
resetting the parser to the point before the identifier, and the next
alternative is tried.</p>

<p>The has <code>&amp;</code> and not <code>!</code> operators represent
positive and negative lookahead. In the PEG notation, <code>&amp;</code> and
<code>!</code> are prefix operators, but in Pecan, they are postfix, to make the
syntax of rules simpler and more uniform and, in particular, to avoid precedence
issues which would arise if there were both prefix and postfix operators. The
<code>&amp;</code> and <code>!</code> operators bind more tightly than
sequencing.</p>

<p>With <code>x&amp;</code> or <code>x!</code>, the expression <code>x</code> is
parsed speculatively to check whether it appears next in the input or not.
Whether the expression <code>x</code> succeeds or fails, the parser backtracks
to the beginning. Then <code>x&amp;</code> succeeds if the parsing of
<code>x</code> succeeded, whereas <code>x!</code> succeeds if the parsing of
<code>x</code> failed. For example:</p>

<pre>statement = (type identifier)&amp; declaration / assignment
</pre>

<p>The parser looks ahead to see if there is a type and identifier next in the
input. If there is, the parser backtracks to the point before the type, but
continues with the same alternative and parses a declaration. If the lookahead
fails, an assignment is parsed. A negative example is:</p>

<pre>string = '"' ('"'! visible)* '"'
</pre>

<p>This says that a string contains any visible character other than a double
quote. The bracketed expression only matches a visible character if a double
quote does not appear next in the input.</p>

<p>Lookahead expressions are regarded only as ways to decide which alternative
to take, so actions and error reporting are suspended. During has and not
operations <code>x&amp;</code> or <code>x!</code>, actions and error markers are
ignored. A see operation <code>[x]</code> is equivalent to <code>x&amp;
x</code>, so actions and error reporting are only performed if <code>x</code>
succeeds.</p>

<h3 id="text">Text</h3>

<p>Text notations are used to match input characters. Single quotes indicate
individual characters, e.g. <code>'x'</code> matches the letter <code>x</code>.
Several characters in single quotes indicate a set of distinct alternatives, any
one of which can be matched.  For example:</p>

<pre>op = '+-*/'
digit = '0123456789'
</pre>

<p>The expression <code>'+-*/'</code> matches any one of the four arithmetic
operator characters, and is equivalent to <code>'+' / '-' / '*' / '/'</code>.
The expression <code>'0123456789'</code> matches any digit.</p>

<p>Double quotes indicate a string of characters, which are matched in sequence.
For example:</p>

<pre>keyword = "int" / "if" / "while" / ...
pi = "&#960;"
</pre>

<p>The string <code>"int"</code> only matches if all three characters appear in
the input in sequence, i.e. it is equivalent to <code>['i' 'n' 't']</code>. The
square brackets indicate that if a string matches only partially, the input
position returns to the beginning of the string, and other alternatives can be
tried.</p>

<p>Single characters can be represented using either single or double
quotes. For example:</p>

<pre>double_quote = '"'
single_quote = "'"
</pre>

<p>Grammar files are assumed to use the UTF-8 encoding, and any Unicode
characters can be used in set or string quotes. However, Pecan does not handle
normalization or graphemes, so care needs to be taken. For example,
<code>'é'</code> is visually ambiguous because it could contain one or two code
points, depending on whether a combiner is used to add the accent. In Pecan
sets, each code point is treated as a separate character, so if <code>é</code>
consists of two code points, then <code>'é'</code> represents a choice between
those two code points. If the intended meaning is a single character, it is
better to write <code>"é"</code> in case there are two code points. Similarly,
if the intention of <code>'éè'</code> is a choice between two characters, it is
better to write <code>"é" / "è"</code> to avoid problems.</p>

<p>A range of characters can be expressed using two dots:</p>

<pre>letter = 'a..z'
</pre>

<p>There must be one character (code point) either side of the two dots.</p>

<p>Common sets of characters can be specified using Unicode general categories.
The names <code>Uc, Cc, Cf, Cn, Co, Cs, Ll, Lm, Lo, Lt, Lu, Mc, Me, Mn, Nd, Nl,
No, Pc, Pd, Pe, Pf, Pi, Po, Ps, Sc, Sk, Sm, So, Zl, Zp, Zs</code> are provided.
The name <code>Uc</code> represents all Unicode code points. The others are the
standard two-letter abbreviations for the Unicode general categories which
partition all the code points. For example:</p>

<pre>letter = Lu / Ll / Lt / Lm / Lo
digit = Nd
connector = '_'! Pc
visible = (Cc/Cn/Co/Cs/Zl/Zp)! Uc
</pre>

<p>The Unicode categories starting with <code>L</code> are letters. The letter
rule allows any kind of letters: upper case, lower case, title case, modifier
and other. Categories starting with <code>N</code> are number characters, of
which <code>Nd</code> is the set of decimal digits. The connector rule uses the
<code>Pc</code> connector punctuation category, but excludes the underscore
character. The rule for <code>visible</code> excludes character code points
which are unassigned, private, surrogate, controls, or line or paragraph
separators.</p>

<p>A splitter is a string in angle brackets such as <code>&lt;abc></code> which
represents a lookahead. It does not consume any input characters, but succeeds
if the remaining input, regarded as a string, is lexicographically less than or
equal to <code>"abc"</code>. For example:</p>

<pre>keyword = &lt;df> keyword1 / keyword2
keyword1 = "break" / "case" / "catch" / "continue" / "default"
keyword2 = "do" / "else" / "for" / "if" / "switch" / "while"
</pre>

<p>Here, some keywords are listed in alphabetical order, and a splitter is used
to speed up their recognition by separating the keywords up to
<code>"default"</code> from the keywords from <code>"do"</code> onwards. Note
that <code>&lt;default></code> should not be used as the splitter in this
example, because if <code>"default"</code> is next in the input, the input
continues after that and is therefore lexicographically greater. Nor should the
splitter be <code>&lt;do></code>, just in case <code>do</code> is at the end of
the input text.</p>

<p>The empty string <code>""</code> always succeeds, the empty set
<code>''</code> always fails, and the empty splitter succeeds only at the end of
the input:</p>

<pre>succeed = ""
fail = ''
end = &lt;>
</pre>

<h3 id="escapes">Escapes</h3>

<p>There are escape conventions within sets, strings, ranges, splitters and
literal names (see later), to include control characters, or to represent
Unicode characters using plain text. A summary of the escape conventions
is:</p>

<table class="char">
<tr><th>Escape</th><th>Code</th><th>Character</th>
<tr><td><code>\b</code></td><td>8</td><td>backspace</td>
<tr><td><code>\f</code></td><td>12</td><td>formfeed</td>
<tr><td><code>\n</code></td><td>10</td><td>newline</td>
<tr><td><code>\r</code></td><td>13</td><td>return</td>
<tr><td><code>\t</code></td><td>9</td><td>tab</td>
<tr><td><code>\"</code></td><td>34</td><td>double quote</td>
<tr><td><code>\'</code></td><td>39</td><td>single quote</td>
<tr><td><code>\\</code></td><td>92</td><td>backslash</td>
</table>

<p></p>

<table>
<tr><th>Escape</th><th>Meaning</th>
<tr><td><code>\ddd...</code></td><td>character with decimal code</td>
<tr><td><code>\0xxx...</code></td><td>character with hexadecimal code</td>
<tr><td><code>\&amp;</code></td><td>optional terminator</td>
</table>

<p>A numerical escape is a backslash followed by digits, used to represent a
single character, using its decimal character code. For example:</p>

<pre>pi = '\960'
newline = '\13'? '\10'
any = '\0..\1114111'
</pre>

<p>If the first digit is zero, then the character code is in hexadecimal, using
<code>a</code> to <code>f</code> or <code>A</code> to <code>F</code>, e.g.</p>

<pre>pi = '\03C0'
newline = '\0d'? '\0a'
any = '\0..\010ffff'
</pre>

<p>Numerical escape sequences are variable length. A decimal sequence ends when
a non-digit is encountered, and a hex sequence ends when a non-hex digit is
encountered. If an escape sequence is to be followed by a digit, it can be
terminated by <code>\&amp;</code>, e.g. <code>"&#960;3"</code> can be escaped as
<code>"\960\&amp;3"</code>.</p>

<h3 id="errors">Errors</h3>

<p>By default, a parser produces an error message which points to the furthest
position reached in the input text, other than in lookaheads, but which gives no
details. For example, suppose this rule is being parsed:</p>

<pre>sum = number ("+" number / "-" number)
</pre>

<p>Then a message like this might be produced for an incorrect operator:</p>

<pre>Error on line 1:
40%2
  ^
</pre>

<p>Markers can be added to parser rules, to describe the items which would have
allowed parsing to continue. A marker is a symbol consisting of the
<code>#</code> character followed by a name. The name has the same form as an
identifier. In particular, it can be literal, as described in the literals
section. For example, suppose the rule above is changed to:</p>

<pre>sum = number (#plus "+" number / #minus "-" number)
</pre>

<p>Then, for an incorrect operator, the expressions <code>"+"</code>
and <code>"-"</code> both fail, so the error message produced becomes:</p>

<pre>Error on line 1: expecting minus, plus
40%2
  ^
</pre>

<p>When a marker is encountered, it is associated with the current position in
the input. It records something that the parser is expecting at that point. If
progress is made past that input position, the markers are cleared. When the
parser encounters an error, the set of things that the parser was expecting at
that point is reported. Duplicates are removed, for example suppose the rule
is changed to:</p>

<pre>sum = number (#operator "+" number / #operator "-" number)
</pre>

<p>Then the error message becomes:</p>

<pre>Error on line 1: expecting operator
40%2
  ^
</pre>

<p>During testing, the order in which markers are reported is alphabetical. When
a grammar is compiled, the order is determined by the external code, and the
text produced can be customised.</p>

<p>One way to ensure that all the items which could possibly allow parsing to
continue are reported is to write separate rules to describe low level features
of a grammar involving primitive character matchers, i.e. strings, sets,
character codes, or Unicode identifiers, and begin each with a marker. For
example, a parser for a programming language might contain rules such as:</p>

<pre>plus = #operator "+" @
letter = #letter (Lu / Ll / Lt / Lm / Lo)
number = #number ('0'..'9')+ @number
newline = #newline 13? 10 @
end = #end &lt;>
</pre>

<p>The <code>plus</code> rule specifies that the plus sign is to be described as
an operator in error messages, that it may be followed by optional spaces, and
that the plus sign and spaces are discarded. The <code>letter</code> rule
applies an error marker to a choice of Unicode categories, to avoid having to
attach a marker to each one individually.</p>

<p>With these rules, an incorrect operator might lead to an error message which
says that an operator is expected. The fact that an extra digit on the preceding
number, or a space, could also have allowed parsing to continue is not reported.
That is because individual digits and spaces in the rules haven't been given
markers.</p>

<h3 id="actions">Actions</h3>

<p>Actions allow a parser to operate on values or data structures, using a
stack, to produce an output. An action is a symbol which consists of the
<code>@</code> character followed by a number followed by a name. If there is no
number, it is assumed to be zero. The name follows the same rules as an
identifier. In particular, it can be a literal name, as discussed in the section
on literals. For example:</p>

<pre>sum = term (plus term @2add)*
</pre>

<p>Suppose that the <code>term</code> rule pushes a single item onto the stack,
and the <code>plus</code> rule doesn't affect the stack. The <code>@2add</code>
symbol in the <code>sum</code> rule indicates that two items should be popped
off the stack, the <code>add</code> action should be performed, which creates a
new item, and the new item should be pushed onto the stack. A parser as a whole
ends with a single item on the stack, which is the output from the parsing
process.</p>

<p>Defining an action as a stack-based operation allows it to be expressed as a
self-contained symbol at a specific point in a grammar. That in turn allows
actions to take part in grammar transformations which move actions away from
their arguments. For example, the above rule can be transformed to these rules,
where the two arguments to the <code>add</code> action are separated:</p>

<pre>sum = term more*
more = plus term @2add
</pre>

<p>The stack is provided and manipulated by external code when a parser is
generated from the grammar. An action symbol such as <code>@2add</code> is
translated into the execution of a fragment of external code. The parser could
be part of a calculator, in which case the <code>add</code> action might add two
numbers. Alternatively, the parser might become part of a compiler, in which
case the <code>add</code> action might combine two expression trees into a
larger tree. When executing a grammar symbolically for testing, the name of the
action is simply printed out.</p>

<p>An action has access to the characters or tokens from the input which have
been matched since the previous action. For example:</p>

<pre>number = digit+ @number
</pre>

<p>The action <code>@number</code> creates a new item from the digits which
have just been matched, and pushes it onto the stack. There is a further
convention which allows matched characters to be discarded. For example:</p>

<pre>spaces = ' '+ @
</pre>

<p>An <code>@</code> sign on its own causes any recently matched characters (or
tokens) to be discarded by the parser, without any external code being
executed.</p>

<p>Recently matched characters are available to an action, no matter what arity
it has. However, for an action like <code>@2add</code> which combines output
items, it is common to ignore them. If there are any such characters, and they
are ignored by an action, they are implicitly discarded. Also, a discard with
non-zero arity such as <code>@2</code> is allowed. This discards two output
items, as well as any outstanding matched characters.</p>

<p>There are severe consistency restrictions on actions. Every expression or
rule must produce or consume a fixed number of output items. Each alternative in
a choice must create or consume the same number of output items. Within a
repetition, i.e. <code>x*</code> or <code>x+</code> or <code>x?</code>, the
inner expression <code>x</code> must have no net effect on the number of output
items.</p>

<p>The compensation for these severe restrictions is that Pecan can carry out
strong consistency checks on grammars, ensuring that every expression produces a
fixed and known number of output items overall, and needs a known number of
items to be on the stack before it is executed.</p>

<p>The first rule in a grammar must produce a single output item overall, and
must not need any items on the stack before execution, so that it cannot cause
the output stack to underflow. However, if this is not the case, the error is
reported only when attempting to generate a parser from the grammar. That means,
during development and testing, a grammar with no actions is legal, and also any
self-contained fragment of a grammar is legal.</p>

<p>Scanners are normally thought of as producing a sequence of tokens. But in
Pecan, even a scanner must produce a fixed number of output items. A scanner
can be defined like this:</p>

<pre>tokens = @tokens token+ end
token = number @1number / id @1id / ...
</pre>

<p>The <code>@tokens</code> action creates an output item representing the list
or array of tokens to be generated, initially empty. Each action such as
<code>@1number</code> takes the recently matched characters, creates a token
from them, and adds it to the list. The list is the only output from the
scanner.</p>

<p>In a token-based parser, there are often variable-length sequences, which
need to be dealt with in a similar way. For example, a comma-separated list of
identifiers can be expressed by:</p>

<pre>ids = @list id @2id ("," id @2id)* @1end
</pre>

<p>The <code>id</code> rule is assumed to push a single item onto the output
stack. The <code>@list</code> action creates an empty list. The
<code>@2id</code> action pops the list and most recent id, adds the id to the
list, and pushes the resulting list back on the stack. The <code>@1end</code>
action does anything necessary to finalize the list.</p>

<p>The external code in a generated parser may choose a different implementation
with the same overall effect. For example, <code>@list</code> may mark a
position in the output stack, <code>@2id</code> may do nothing, so that ids
accumulate on the stack, and <code>@1end</code> may use the marked stack
position to create an array out of the accumulated ids. Alternatively,
<code>@list</code> could create a linked list, each subsequent
<code>@2id</code> could chain the next id onto the end of the list, and
<code>@1end</code> could do nothing.</p>

<p>Techniques like this for handling variable-length lists can easily lead to a
left hand alternative which begins with an action, for example:</p>

<pre>@a x / y
</pre>

<p>The action <code>@a</code> is performed whether or not <code>x</code>
succeeds. This is not completely intuitive, and probably not what was intended.
It is not reported during development, so that transformations remain valid, but
is reported as a warning when compilation is requested. A similar situation
arises with error markers:</p>

<pre>#m x / y
</pre>

<p>However, the fact that the marker takes effect even if <code>x</code> fails
is normal, so that if parsing as a whole fails without progressing beyond this
point, the marker is reported as one of the things expected.</p>

<h3 id="tokens">Tokens</h3>

<p>Support is provided for parsers where the input consists of tokens produced
by a separate scanner. The input is thought of as an array of tokens instead of
an array of characters.</p>

<p>A tag is represented as a symbol consisting of the <code>%</code> character
followed by a name. The name has the same form as an identifier. In particular,
it can be literal, as described in the next section. Each tag represents a
specific kind of token. For example, a token-based parser for a simple
calculator with no brackets might look like this:</p>

<pre>sum = term (%plus term @2add / %minus term @2subtract)* end
term = number (%times number @2multiply / %over number @2divide)*
number = %number @number
end = &lt;>
</pre>

<p>In this case, the input is an array of tokens with tags <code>%number</code>,
<code>%plus</code>, <code>%minus</code>, <code>%times</code> or
<code>%over</code>.</p>

<p>In token-based parsers, text matching notations are not allowed, except for
<code>''</code>, <code>""</code> and <code>&lt;></code>.</p>

<p>A tag represents a call to an external function to find the type of the
current token. This allows a limited form of context dependence while parsing.
For example, it is well known that parsing of the C language requires typedef
names to be recognised separately from other identifiers, and that typedef
constructs have to be parsed to provide that information. This can be achieved
by classifying both types of token as identifiers in the scanner. Then, in the
parser, the actions carry out sufficient symbol table construction to represent
typedef constructs. Then, when the external tag function is executed, it uses
the symbol table to decide whether to return an identifier tag or typedef
tag.</p>

<h3 id="literals">Literals</h3>

<p>The names used in identifiers, actions, markers and tags normally consist of
a letter followed by letters, digits, hyphens or underscores. Literal names can
be used as an alternative. A literal name consists of one or more characters
inside backquotes. The numerical escapes described earlier are also available.
This helps to make grammars more readable when a separate scanner and parser are
being designed. For example, a scanner might contain:</p>

<pre>ge = ">=" @1`>=`
</pre>

<p>Each character in a literal name is automatically converted to an
alphanumeric form, e.g. <code>@1`>=`</code> is equivalent to
<code>@1GtEq</code>. Then, when the scanner is compiled, the action name
<code>GtEq</code> is a valid identifier or constant in the target programming
language. If action names are used as token tags, this notation avoids the need
to invent tag names for tokens with fixed spellings.</p>

<p>In the corresponding token-based parser, the tag name produced can be matched
by a tag with the same literal name. For example:</p>

<pre>ge = #op %`>=`
</pre>

<p>The same translation to alphanumeric form is used, so the tag
<code>%`>=`</code> is equivalent to <code>%GtEq</code> and the compiled parser
thus matches up with the compiled scanner.</p>

<p>To improve the readability of a token-based parser further, e.g. so that it
corresponds closely to a published grammar, literal names can also be used for
identifiers. For example:</p>

<pre>comparison = expression `>=` expression
...
`>=` = #op %`>=`
</pre>

<p>For an alphanumeric literal, the quotes have no effect, so <code>`int`</code>
is equivalent to <code>int</code>, making the quotes unnecessary, but using
<code>`int`</code> may still be desirable to emphasize that the identifier
stands for a keyword token with a fixed spelling.</p>

<p>When a grammar is compiled to produce a parser, custom adjustments can be
specified for each different type of name, to prevent name clashes. The same
adjustment should be specified for actions in the scanner as for tags in the
parser, so that the generated tag names correspond.</p>

<h2 id="testing">Testing</h2>

<p>During development of a grammar, testing can be carried out by symbolic
execution without having to generate a parser. This is done by typing a command
of the form:</p>

<pre>pecan [-t | -trace] [line] testfile
</pre>

<p>The test file contains the tests to be carried out. The <code>-trace</code>
option switches on tracing, so that the individual steps taken during parsing
are displayed. If a line number is given, only the single test that starts on
that line of the test file is executed.</p>

<p>A test file contains a number of sections separated by lines consisting of
five or more equal signs. If a section contains a line of five or more dots as a
separator, then it is a test with sample input and expected output. If a section
has no separator, it is a grammar or self-contained grammar fragment which is
used for subsequent tests, until another grammar is given. For example:</p>

<pre>// Match one digit
number = ("0".."9") @number
==========
2
..........
number 2
==========
42
..........
number 4
==========
// Match any number of digits
number = ("0".."9") @number
==========
42
..........
number 42
</pre>

<p>The first section of this file sets up a grammar, then there are two tests
using that grammar, then a new grammar is given, then there is a final test
using the second grammar.</p>

<p>The output from running a test using a given grammar and sample input is a
list of the actions that would be performed by a parser generated from the
grammar. If the input is text, the characters matched since the previous action
or discard are displayed.</p>

<p>For a token-based grammar, the input consists of a sequence of tag names
separated by white space:</p>

<pre>// Match a list of numbers.
list = %number @value (%comma %number @value @2and)*
==========
number comma number comma number
..........
value
value
and
value
and
</pre>

<p>When a test fails, its line number is reported in the error message. That
line number can then be used to re-run the testing, but picking out only that
one test to be performed, perhaps with tracing:</p>

<pre>pecan tests.txt
Fail test on line 24 of tests.txt:
---------- Expected ----------
...
---------- Actual ----------
...

pecan -trace 24 tests.txt
...
</pre>

<p>A grammar in a test file can have an inclusion. For example, a file
<code>tests.txt</code> of tests for a grammar in <code>grammar.txt</code> can
start with:</p>

<pre>{grammar.txt}
==========
...
</pre>

<p>The grammar fragment containing the inclusion can specify a particular rule
to test, add <code>&lt;></code> to ensure that the rule parses all of the input
supplied in each test. It may also provide definitions for any undefined
identifiers in the grammar file, which could be necessary if the grammar file
contains one module of a modular grammar, which depends on another module. For
example, a test file could begin:</p>

<pre>start = expression &lt;>
{expressions.txt}
statement = ...
==========
...
</pre>

<p>The expression rule is the one to be tested, each test provides a complete
expression, and the file <code>expressions.txt</code> has a forward reference to
a module defining statements.</p>

<p>If a grammar fragment consists of a single line which is an inclusion, then
the included file can be another test file, rather than just a grammar, allowing
tests to be grouped:</p>

<pre>{group1.txt}
==========
{group2.txt}
==========
...
</pre>

<p>There is no conflict between a filename representing a grammar and one
representing a subfile of tests. That is because a grammar file is equivalent to
a test file which sets up a grammar, but contains no tests.</p>

<p>Test files can use the UTF-8 encoding. They are normalized to avoid visual
ambiguity problems, by changing all line endings to <code>\n</code>, removing
trailing spaces at the ends of lines, and removing trailing blank lines at the
very end of the test file.</p>

<h2 id="checks">Consistency checks</h2>

<p>A number of checks are performed on a grammar which help to ensure
consistency. Some obvious checks are done first, such as syntax checking of the
grammar, checking that each rule name is defined exactly once, and checking that
no rule name clashes with a category name.</p>

<p>A grammar is checked to see if it represents a text parser or a token parser.
A text parser must contain no tags. A token parser must not contain text
matchers, i.e. strings, splitters, sets, ranges or numbers, with the exception
of <code>""</code> or <code>''</code> or <code>&lt;></code>.</p>

<p>There are also checks on sets and ranges. Sets must contain distinct
characters, and a range must have a single code point either side of the
<code>..</code> and the range must be non-empty.</p>

<p>Many parsing expressions are
equivalent, which considerably reduces the number of cases that need be
discussed. For example:</p>

<pre>'\32'     &#8801;  ' '
'a'       &#8801;  "a"
"ab"      &#8801;  ['a' 'b']
'ab'      &#8801;  'a' / 'b'
'a..z'    &#8801;  'a' / ... / 'z'
Ll        &#8801;  'a' / ... / 'z' / ...
x?        &#8801;  x / ""
x*        &#8801;  xs  where  xs = (x xs)?
x+        &#8801;  x x*
[x]       &#8801;  x&amp; x
x&amp;        &#8801;  x!!
''        &#8801;  ""!
&lt;bd>      &#8801;  &lt;> / ('\0..a' / 'b' &lt;d>)&amp;
&lt;b>       &#8801;  &lt;> / '\0..a'&amp;
&lt;>        &#8801;  Uc!
</pre>

<p>The core features remaining are:</p>

<pre><code>id = x</code>      rules
<code>""</code>          the empty string (always succeeds)
<code>"x"</code>         single characters
<code>x/y</code>         choices
<code>x y</code>         sequences
<code>x!</code>          the 'not' lookahead
<code>%a</code>          tags
<code>@2a, @a, @</code>  actions
<code>#a</code>          markers
</pre>

<p>The main remaining checks are making sure that there is no left recursion,
and that output items are handled consistently.</p>

<h3 id="loop">Left recursion checking</h3>

<p>Pecan checks that the grammar contains no infinite loops caused by left
recursion. The simplest example is where a rule mentions its own name at the
start of its right hand side, or at the start of one of its alternatives:</p>

<pre>sum = sum "+" term / term
</pre>

<p>In a Pecan grammar, a rule of this form leads to an immediate infinite loop,
and so is reported as an error. Indirect left recursion is also detected. That
is where two or more rules mention each other at the beginning:</p>

<pre>expression1 = expression2 ...
expression2 = expression1 ...
</pre>

<p>Less obvious cases of left recursion are also detected, e.g.</p>

<pre>statement = label* statement
</pre>

<p>Although <code>statement</code> does not mention itself right at the
beginning, the expression <code>label*</code> may succeed without any input
being matched, and therefore an infinite loop ensues.</p>

<p>To implement the checks, four boolean properties of expressions
<code>SP</code>, <code>SN</code>, <code>FP</code>, <code>FN</code> are
calculated for each expression. The <code>SP</code>, <code>SN</code> properties
mean the expression can succeed with or without progress being made in the
input, and <code>FP</code>, <code>FN</code> mean that an expression can fail,
with or without progress. These are very similar way to the properties used in
the analysis of PEG grammars, though there <code>FP</code> and <code>FN</code>
are not distinguished.</p>

<p>As well as the equivalences already mentioned, there are further parsing
expressions which are equivalent from the point of view of success or failure,
and progress or not:</p>

<pre>%a          &#8801;  "a"
@2a, @a, @  &#8801;  ""
#a          &#8801;  ""
</pre>

<p>The way the properties are calculated for the remaining features of grammars
(using <code>&amp;</code> for 'and' and <code>|</code> for 'or', with
<code>&amp;</code> binding tighter, and using <code>def(id)</code> for the right
hand expression of a rule for identifier <code>id</code>) are:</p>

<pre>SN(id) = SN(def(id))
SP(id) = SP(def(id))
FN(id) = FN(def(id))
FP(id) = FP(def(id))

SN("") = true
SP("") = false
FP("") = false
FN("") = false

SP("a") = true
FN("a") = true
SN("a") = false
FP("a") = false

SN(x y) = SN(x) &amp; SN(y)
SP(x y) = SP(x) &amp; SP(y) | SP(x) &amp; SN(y) | SN(x) &amp; SP(y)
FN(x y) = FN(x) | SN(x) &amp; FN(y)
FP(x y) = FP(x) | SN(x) &amp; FP(y) | SP(x) &amp; FN(y) | SP(x) &amp; FP(y)

SN(x/y) = SN(x) | FN(x) &amp; SN(y)
SP(x/y) = SP(x) | FN(x) &amp; SP(y)
FN(x/y) = FN(x) &amp; FN(y)
FP(x/y) = FP(x) | FN(x) &amp; FP(y)

SN(x!) = FN(x) | FP(x)
SP(x!) = false
FN(x!) = SN(x) | SP(x)
FP(x!) = false
</pre>

<p>Because the rules are themselves recursive, fixed point iteration is used,
i.e. the values are calculated repeatedly until they don't change. If all the
values are set to <code>false</code> at the start, the only possible changes are
from <code>false</code> to <code>true</code>, so the iteration terminates.</p>

<p>Once these values are known, a further boolean property, <code>WF</code> is
calculated to check that the grammar is well formed. The <code>WF</code>
property is calculated (using <code>~</code> for 'not') by:</p>

<pre>WF(id) = WF(def(id))
WF("") = true
WF("a") = true
WF(x y) = WF(x) &amp; (~SN(x) | WF(y))
WF(x / y) = WF(x) &amp; WF(y)
WF(x!) = WF(x)
</pre>

<p>If <code>WF</code> turns out to be false for any expression, that expression
is reported as an error because it contains left recursion.</p>

<!--
<h3 id="token">Token checking</h3>


<p>For grammars which have text as input, a check is made that all tokens
produced are non-empty, so that continual progress is made through the
characters in the input. For example:</p>

<pre>id = letter+ @identifier
letter = 'a..z'
</pre>

<p>Here, it is clear that by the time the accept action
<code>@identifier</code> is reached, at least one letter has been matched from
the input. On the other hand, suppose the <code>id</code> rule was:</p>

<pre>id = letter* @identifier
</pre>

<p>This causes an error message, because <code>@identifer</code> can be reached
without matching any input characters. However, if this <code>id</code> rule
is always used in a context where at least one character has already been
matched, i.e. the <code>id</code> rule refers to the remainder of a token
rather than a whole token, then there is no error.</p>

<p>This check is implemented by making as many deductions as possible about
positions in the grammar at which input characters have definitely been matched
since the previous token. This is a conservative check - it is possible for a
pathological grammar to produce an error message even though no empty token
would ever be created in practice.</p>

<p>There is a further check that a scanner makes no attempt to read past the
end of the input. For example, suppose there is a scanner rule like
this:</p>

<pre>tokens = token+ UC! @end
token =  space / identifier / keyword / operator / punctuation
</pre>

<p>This is fine, because all that follows the end of text <code>''</code> is an
action, not any attempt to match any characters. However, suppose the
rule is:</p>

<pre>tokens = token+
token = space / identifier / keyword / operator / punctuation / end
end = '' @end
</pre>

<p>This does cause an error, because after recognising the end of text, the
scanner could continue to look for more tokens.</p>
-->
<h3 id="output">Output checking</h3>

<p>Actions are assumed to treat output items in a stack-like manner. Restrictive
checks are made to guarantee consistent handling of output items. The arity of
each action has to be specified, and has to be consistent each time the action
appears. For example if a grammar contains both <code>@1add</code> and
<code>@2add</code>, that is reported as an error. The arities are used to check
that each expression in the grammar produces a fixed, known number of output
items.</p>

<p>The net overall number of items added to the stack, possibly negative, is
calculated for each expression in the grammar.</p>

<p>Both alternatives in a choice expression must have the same net effect. For
example, this rule causes an error:</p>

<pre>token = ('0..9')+ @token / ' '+
</pre>

<p>The first alternative adds one item to the stack, but the second adds
nothing. On the other hand, this rule is legal:</p>

<pre>token = ('0..9')+ @1token / ' '+
</pre>

<p>The <code>@1token</code> action pops an item from the stack, presumably a
list of tokens, and pushes one item back on the stack, presumably the updated
list. It thus has zero net effect. Since both alternatives now have a zero net
effect, the <code>token</code> rule itself can be deduced as having a zero net
effect.</p>

<p>A repeated expression must have zero net effect. For example, suppose the
grammar contains:</p>

<pre>tokens = (('0..9')+ @token)*
</pre>

<p>The inner expression causes one output item to be pushed on the stack. This
is reported as an error, because <code>tokens</code> as a whole pushes an
unknown number of items onto the stack. On the other hand, this definition is
allowed:</p>

<pre>tokens = (('0..9')+ @1token)*
</pre>

<p>The inner expression pops a previous list item, adds a token to it, and
pushes the updated list onto the stack. As a result, it has a zero net effect.
It can be repeated any number of times, still with a zero net effect, and so the
<code>tokens</code> rule can be deduced to have zero net effect.</p>

<p>As well as repeated expressions, recursion is also restricted so that the
number of output items produced is fixed. For example:</p>

<pre>x = 'a' x @a
</pre>

<p>Here, the number of items pushed onto the stack depends on the number of
times <code>x</code> calls itself recursively. So this is reported as an
error.</p>

<p>A second check is that the stack never underflows. To check this, for each
expression, the number of items which need to be on the stack when the
expression is executed is calculated. For example, the expression
<code>('0..9')+ @1token</code> needs one item to be on the stack. There are
situations where the needed number can't be calculated, for example:</p>

<pre>x = 'a' / 'b' @2c x @d
</pre>

<p>Every time <code>x</code> calls itself recursively, one more item is needed
on the stack, even though the net effect of <code>x</code> is zero. Such a
situation is reported as an error.</p>

<p>Any situation where the net effect or the needed number can't be calculated
as a fixed integer is reported. For a complete grammar which is about to be
compiled, the first rule is checked to make sure its net effect is one, and its
needed number is zero, so that stack underflow is impossible.</p>

<p>These checks are conservative, i.e. there could be pathological grammars
which always work correctly in practice, but which don't pass the checks.</p>

<h2 id="compile">Compilation</h2>

<p>A grammar can be compiled either to a set of recursive functions, or to a
bytecode array, in almost any desired target programming language. Compilation
to recursive functions is more intuitive, but compilation to bytecode can be
used in more dynamic situations, e.g. where grammars need to be executed 'live'
without external compilation and dynamic loading.</p>

<h3 id="functions">Recursive functions</h3>

<p>A grammar is compiled into recursive functions using a command of the
form:</p>

<pre>pecan grammar -c program
</pre>

<p>The option <code>-c program</code> specifies a template program file. The
file must already exist, and can be written in any desired target programming
language. It must contain a placeholder such as:</p>

<pre>// &lt;pecan ...
// >
...
// &lt;/pecan>
</pre>

<p>The placeholder begins with a commented out open tag <code>&lt;pecan></code>,
with attributes as described below, and ends with a commented out close tag
<code>&lt;/pecan></code>. Lines in between the two tags, if any, are removed,
and the result of compiling the grammar is inserted in their place.</p>

<p>Very few restrictions are placed on the target programming language when
compiling to recursive functions. The main assumption is that the language has
two binary and/or operators which are guaranteed to use short-circuit
evaluation, i.e. they do not evaluate their right hand arguments
unnecessarily. In many languages, the symbols <code>&amp;&amp;</code> and
<code>||</code> are suitable. The <code>&amp;&amp;</code> operator does exactly
what is required for a sequence <code>x y</code>, evaluating <code>x</code> and
then, only if <code>x</code> succeeds, continuing with <code>y</code>. A choice
<code>x / y</code> is complicated by the need to test whether <code>x</code> has
progressed or not before deciding whether to try <code>y</code> instead. So, in
general, <code>x / y</code> is compiled into something like:</p>

<pre>alt((go() &amp;&amp; tx) || (ok() &amp;&amp; ty))
</pre>

<p>Here <code>tx</code>, <code>ty</code> represent the translations of
<code>x</code>, <code>y</code>. The <code>go</code> function pushes the current
input position on a stack before <code>tx</code> is executed, the
<code>ok</code> function checks for progress, and the <code>alt</code> function
pops the saved position off the stack after the choice has been completed. The
<code>go</code> function is also used in the compilation of other Pecan
features. For example, an expression <code>x&amp;</code> is compiled to:</p>

<pre>has(go() &amp;&amp; tx)
</pre>

<p>The <code>has</code> function pops the position saved by <code>go</code> and
backtracks to it, before returning the result of <code>tx</code>.</p>

<p>This general approach, using a background stack for progress checking, allows
every parsing expression to be compiled into a boolean expression, with only the
<code>&amp;&amp;</code> and <code>||</code> operators being used to combine
expressions.</p>

<p>The open tag <code>&lt;pecan...></code> of the placeholder includes
attributes. The attributes specify details of how to generate functions in the
target language for the given application:</p>

<pre>// &lt;pecan
//     comment = "// %s"
//     rule    = "bool %l(parser *p) { %n%treturn %r; %n}"
//     call    = "%s(p)"
// >
...
// &lt;/pecan>
</pre>

<p>This example is suitable for C as a target language, where a pointer to a
parsing state is to be passed to every parsing function. Each attribute must be
on a separate line, and consists of one of the attribute names described below,
followed by an equal sign followed by a string in single or double quotes. The
whole attribute may be preceded or followed by comment characters. Each
attribute string is a format string in a printf style specifying the text to be
generated for a specific Pecan feature.</p>

<p>In a format string, the percent character is the only special character, used
for specifiers. There are no backslash escape conventions. Each specifier
determines what to extract and print from the current construct.</p>

<p>The specifier <code>%n</code> followed by spaces indicates that if an
expression does not fit on the current line, a newline and indent are printed,
and any space at the end of the previous line is deleted. The specifier
<code>%t</code> increases the indent, temporarily. The specifiers
<code>%l</code>, <code>%r</code> indicate that a left or right subexpression is
to be compiled and printed. The specifier <code>%s</code> indicates that a
string or name should be printed. Identifier names with hyphens or underscores
are translated to <a href="https://en.wikipedia.org/wiki/Camel_case">camel
case</a>. The specifier <code>%S</code> indicates additionally that the first
letter of names should be upper case. A character can be printed directly using
<code>%c</code>, or its integer code can be printed using <code>%d</code> for
decimal, <code>%o</code> for octal, or <code>%x</code> for hexadecimal. A fixed
number of digits can be specified for <code>%d</code>, <code>%o</code> or
<code>%x</code>, e.g. <code>%4x</code>. When printing a range, two character or
numeric specifiers are used to refer to the low and high characters, e.g. the
format for a range might be <code>"range('%c','%c')"</code>.</p>

<p>Spaces at the beginning of a line in a format represent an indent to be
applied to anything generated from that line. For example, the spaces before
<code>return</code> above represent an indent applied to the entire body of the
function generated by the <code>%e</code> specifier. The number of spaces in the
first indent encountered is used as the amount for any further indenting which
may be added during compilation and pretty printing.</p>

<p>The attributes that can be specified are:</p>

<ul>

<li><p><code><b>declare</b>:</code> the format for generating a forward
declaration of a function. The format string might be <code
style="white-space:nowrap">"bool %s();"</code> for example. The default is
<code>""</code> so that no forward declarations are generated.</p></li>

<li><p><code><b>comment</b>:</code> the format for generating each line of a
comment before each function generated. The format string might be <code
style="white-space:nowrap">"// %s"</code> or <code
style="white-space:nowrap">"/* %s */"</code> for example. The <code>%s</code>
refers to the source text of the Pecan rule that the function corresponds to.
The default is <code>""</code> so that no comments are generated.</p></li>

<li><p><code><b>define</b>:</code> the format for a function definition
generated from a rule <code>id = e</code>. The specifier <code>%s</code> refers
to the identifier name, and <code>%e</code> to the right hand side expression.
The default is <code style="white-space:pre"
>"bool %s() {%n  return %e;%n}"</code>.</p></li>

<li><p><code><b>and</b>, <b>or</b>, <b>true</b>, <b>false</b>:</code> the
formats for the boolean operators and constants. The defaults are <code
style="white-space:nowrap">"&amp;&amp;"</code>, <code
style="white-space:nowrap">"||"</code>, <code>"true"</code> and
<code>"false"</code>.</p></li>

<li><p><code><b>call</b>:</code> the format for making a call to a parsing
function. This affects all the supporting functions, which are <code>go</code>,
<code>ok</code>, <code>alt</code> for choices, <code>opt(x)</code> for
<code>x?</code>, <code>see(x)</code> for <code>[x]</code>, <code>has(x)</code>
for <code>x&amp;</code>, <code>not(x)</code> for <code>x!</code>,
<code>tag(t)</code> for <code>%t</code>, <code>eot()</code> for
<code>&lt;></code>, <code>string("x")</code> for <code>"x"</code>,
<code>set("x")</code> for <code>'x'</code>, <code>split("x")</code> for
<code>&lt;x></code>, <code>range('a','z')</code> for a range such as
<code>'a..z'</code>, <code>cat(Nd)</code> for a category such as
<code>Nd</code>, <code>mark(m)</code> for <code>#m</code>, and
<code>drop(2)</code> for a drop action such as <code>@2</code>. The call format
can be used to add an argument to every call, e.g. <code>"%s(p)"</code> causes
<code>go(p)</code>, <code>ok(p)</code> etc. to be generated. It can also be used
to make a uniform change to the names of all the support functions, e.g.
<code>%S()</code> would cause <code>Go()</code>, <code>Ok()</code> and so on to
be generated. The default is <code>%s()</code>.</p></li>

<li><p><code><b>id</b>:</code> the format for generating a call to represent the
occurrence of an identifier. This can be used to add an argument or adjust
identifier names. For example, an id format <code>"p%S(p)"</code> would cause an
occurrence of an identifier <code>term</code> to be compiled as
<code>pTerm(p)</code>. The default is to use the call format.</p></li>

<li><p><code><b>act</b>, <b>act0</b>, ...:</code> the format for printing
actions, and formats to override it for specific arities. The default for the
act format depends on the call format, e.g. <code>"act%d(%s)"</code> where the
<code>%d</code> refers to the arity and <code>%s</code> refers to the name of
the action. The defaults for specific arities are to use the act
format.</p></li>

<li><p><code><b>tab</b></code>: the spacing for <code>%t</code> specifiers and
for indenting generally. The default is <code
style="white-space:pre">"  "</code> (two spaces).</p></li>

<li><p><code><b>escape1</b>, <b>escape2</b>, <b>escape4</b>:</code> formats to
change the way string or character literals are printed in calls to
<code>text</code>, <code>set</code>, <code>split</code> or
<code>range</code> calls, by printing escape sequences instead of UTF-8. The
<b>escape1</b> format is for one-byte control characters, <b>escape2</b> is for
two-byte Unicode characters, and <b>escape4</b> is for four-byte Unicode
characters. The defaults are <code>"\u%4x"</code>, <code>"\u%4x"</code>,
<code>"\U%8x"</code>. For example, a string <code>"ab&#x03c0;"</code> is
translated as <code>string("ab\u03c0")</code>.</p></li>

</ul>

<p>These format strings provide considerable flexibility. For example,
compilation to Java could be specified by:</p>

<pre>// &lt;pecan
//     comment = "%t// %s"
//     rule    = "%tboolean %s() { %n%t%treturn %e; %n%t}"
//     call    = "%s()"
// >
</pre>

<p>This establishes an indent for all the methods generated, and passes no
arguments to parsing functions because the state is implicitly made available by
the surrounding object.</p>
<!--
<p>For <code>go</code>, <code>ok</code>, <code>alt</code>, the format
can be the empty string <code>""</code> to switch off the special treatment of
choices. That would suit a functional language such as Haskell, for example,
where custom operators can be defined with lazy evaluation, so the resulting
code would be equivalent to using a parser combinator library.</p>
-->

<p>The default act format <code>"act%d(%s)"</code> treats action names as
enumerated constants. Instead, the act format could be specified as
<code>"%s()"</code> so that each action has its own function with implicit
arity. Alternatively, the formats for actions of each arity could be specified
as:</p>

<pre>// &lt;pecan
//   ...
//   act0 = "act(0,%s(text()))"
//   act1 = "act(1,%s(top(0)))"
//   act2 = "act(2,%s(top(1),top(0)))"
//   ...
// >
</pre>

<p>Then the handling of the output stack is covered by the generated code and
only pure external action functions need to be provided. Here
<code>text()</code> forms a string from the recently matched characters,
<code>top(n)</code> returns the n'th item from the top of the output stack and
<code>act(n,x)</code> pops n items from the output stack, pushes
<code>x</code>, and discards any recently matched characters.</p>

<h3 id="bytecode">Bytecode</h3>

<p>Compilation of a grammar into bytecode is provided, along similar lines to
compilation into recursive functions. An interpreted bytecode is somewhat
similar to the table-driven techniques used in bottom-up CFG-based parser
generators.</p>

<p>This bytecode facility is provided mainly for demonstration purposes. The
real advantage of a bytecode approach would be in a library setting. For
example, one could imagine an editor or IDE which uses a variant of Pecan as a
library. It could dynamically load a Pecan language description file, according
to the language of the source file it is editing, convert the description to a
bytecode, and interpret the bytecode to parse the source file. This would be
preferable to writing out a parser program, compiling it, then dynamically
loading it on the fly. The process of loading a language description and
compiling it to bytecode could bypass much of the processing currently built
into Pecan, assuming that the description was previously developed and tested
offline.</p>

<p>A grammar is compiled into bytecode using a command of the form:</p>

<pre>pecan grammar -b program
</pre>

<p>The option <code>-b program</code> specifies a template program file
containing an interpreter for the bytecode. The file must already exist, as a
source file template, written in any desired target programming language. It
must contain a placeholder such as:</p>

<pre>// &lt;pecan>
    ...
// &lt;/pecan>
</pre>

<p>The placeholder begins with an open tag <code>&lt;pecan></code> in a
target-language comment and ends with a close tag <code>&lt;/pecan></code>, also
embedded in a comment. Lines in between, if any, are removed, and the result of
compiling the grammar is inserted.</p>

<p>The bytecode sequence is printed as text, as a comma-separated list of
unsigned byte values. Those values which are opcodes, categories, tags, actions
or error markers are represented symbolically. Suppose the grammar file
contains:</p>

<pre>digit = '0..9' @number
</pre>

<p>Then the bytecode sequence generated might be:</p>

<pre>START, 6, LOW, 1, 48, HIGH, 1, 57, ACT, number, STOP
</pre>

<p>The values of the symbols are specified by the surrounding interpreter, eg.
using enumerations to define each symbol as a number in the range <code>0</code>
to <code>255</code>. By default, the same names are used as in the grammar,
after removing the prefix character. That means the names of actions, error
markers and tags must normally all be distinct.</p>

<p>In a library setting, values for opcodes and names in the grammar would be
passed to the Pecan compiler, and an array of bytes returned.</p>

<p>An interpreter can be constructed by taking the example interpreter provided,
translating it into the desired programming language, and adapting it to a
particular application by customising tags, actions and error handling as
appropriate.</p>

<p>The bytecode produced from a grammar is a fairly simple flattening of the
parse tree for the grammar. Examples are given of how every construct is
translated into bytecode:</p>

<pre>{id = x}    =   START, nx, {x}, STOP
</pre>

<p>A rule is translated using the <code>START</code> and <code>STOP</code>
opcodes. The notation <code>{x}</code> means "the bytecode sequence generated
for expression x" and <code>nx</code> stands for the number of bytes in
<code>{x}</code>. The <code>START</code> opcode takes a one-byte operand in the
range 0..255, whereas <code>STOP</code> needs no operand.</p>

<p>If any instruction needs an operand which is greater than 255, a variant of
the opcode can be used which takes a two-byte operand. There may also be
variants which allows a one-byte operand to be omitted for some small
values.</p>

<p>The <code>START</code> opcode creates a call to <code>{x}</code>, setting up
the address of <code>STOP</code> as the return address. The <code>STOP</code>
instruction ends parsing. The operand <code>nx</code> to <code>START</code> can
be thought of as a relative offset in the code, from the position after the
<code>START</code> instruction to the <code>STOP</code> instruction.</p>

<p><code>START</code> and <code>STOP</code> opcodes are generated for every
rule, even though they are only executed once for the overall call to the
parser. This is so that any rule can be used as an entry point, if desired. The
bytecode can be scanned, skipping the body <code>{x}</code> of each rule using
the number <code>nx</code>, to find the start of the next rule.</p>

<pre>{id}        =   GO, px
{id}        =   BACK, px
</pre>

<p>When the name <code>id</code> of a rule such as <code>id = x</code> is used
elsewhere in the grammar, it is translated using <code>GO</code> or
<code>BACK</code>. The number <code>px</code> is an offset in the code to the
body <code>{x}</code> of the relevant rule, relative to the end of the
instruction. The <code>GO</code> opcode is used when the offset is positive, and
<code>BACK</code> is used, with a positive operand, when the offset is
negative.</p>

<pre>{"a"}       =   STRING, 1, 97
{97}        =   STRING, 1, 97
{128}       =   STRING, 2, 194, 128
{"ab"}      =   STRING, 2, 97, 98
{""}        =   STRING, 0
{"&#960;"}       =   STRING, 2, 207, 128
{"a&#960;"}      =   STRING, 3, 97, 207, 128
{'&#960;'}       =   STRING, 2, 207, 128
{&lt;a>}       =   LESS, 1, 97
{&lt;ab>}      =   LESS, 2, 97, 98
{'a..z'}    =   LOW, 1, 97, HIGH, 1, 122
{'&#945;..&#969;'}    =   LOW, 2, 206, 177, HIGH, 2, 207, 137
{''}        =   SET, 0
{'a'}       =   SET, 1, 97
{'ab'}      =   SET, 2, 97, 98
{'&#945;&#946;'}      =   SET, 4, 206, 177, 206, 178</pre>

<p>A character matching opcode is followed by a one-byte count, and then that
number of bytes in UTF-8 format. For opcodes other than <code>SET</code>, a byte
sequence containing characters of mixed UTF-8 lengths causes no problem, because
UTF-8 text can be compared byte by byte, without taking account of character
boundaries. With the <code>SET</code> opcode, a sequence with mixed UTF-8 byte
lengths cannot be handled byte by byte, but the first byte of each character can
be used to find the character's length.</p>

<pre>{@a}        =   ACT, a
{@}         =   DROP
{#e}        =   MARK, e
{%id}       =   TAG, id
{Nd}        =   CAT, Nd
</pre>

<p>An action is translated using the <code>ACT</code> opcode. Actions need to be
switched off during has <code>x&amp;</code> or not <code>x!</code> expressions.
An integer keeps track of the depth of nesting of lookahead constructs, and
actions are only performed if the integer is zero. For see <code>[x]</code>
expressions, if <code>x</code> contains actions, it is transformed to
<code>(x&amp; x)</code> before compiling.</p>

<p>Error markers, signalled by the <code>MARK</code> opcode, are collected as a
set, and cleared whenever a new marker is found further on in the input. Tags
are used only in token-based parsers. They cause a call to external code to find
the tag of a particular token. Currently, there is a limit of 256 different
action names, 256 marker names, and 256 tag names, so that only one-byte
operands are needed. If the interpreter uses a 64-bit integer as a bitset of
markers, then there is a limit of 64 marker names.</p>

<p>A category is translated using the <code>CAT</code> opcode. The target
programming language may not have a facility for finding the category of a
character. Even if it does, the category information may vary according to the
version of the language. For stable category information, Pecan provides a
two-stage lookup table in the two files <code>table1.bin</code> and
<code>table2.bin</code> which may be read into memory by the target
language.</p>

<pre>{x/y}       =   EITHER, nx, {x}, OR, {y}
{x y}       =   BOTH, nx, {x}, AND, {y}
</pre>

<p>The <code>EITHER</code> opcode initializes a choice, and <code>OR</code>
checks what happens after <code>{x}</code> to decide whether or not to continue
with <code>{y}</code>. Similarly, the <code>BOTH</code> and <code>AND</code>
opcodes handle a sequence. The <code>EITHER</code> or <code>BOTH</code> opcode
can be thought of as causing a call to <code>{x}</code> returning to
<code>OR</code> or <code>AND</code>, which causes a tail-call to
<code>{y}</code>.</p>

<pre>{x?}        =   MAYBE, ONE, {x}
{x*}        =   MAYBE, MANY, {x}
{x+}        =   DO, AND, MAYBE, MANY, {x}
{[x]}       =   LOOK, TRY, {x}
{x&amp;}        =   LOOK, HAS, {x}
{x!}        =   LOOK, NOT, {x}
</pre>

<p>The <code>MAYBE</code> opcode initializes a repetition, then causes a call to
<code>{x}</code>, returning to <code>ONE</code> or <code>MANY</code>. The
<code>ONE</code> opcode converts the result of <code>{x}</code> into the result
of <code>x?</code>. The <code>MANY</code> opcode is similarly executed after
<code>{x}</code> and checks the result of <code>{x}</code> to decide whether or
not to call it again. The opcode sequence used here, with the termination check
before the code for <code>{x}</code>, avoids the need for an <code>nx</code>
operand. The code for <code>x+</code> is equivalent to the code for <code>x
x*</code>, except that the <code>DO</code> opcode avoids the need for a second
copy of <code>{x}</code> by jumping forwards to <code>{x}</code>, and arranging
for the call to return to <code>AND</code>. The <code>LOOK</code> opcode
initializes any of the lookahead constructs, arranging to return to
<code>TRY</code> or <code>HAS</code> or <code>NOT</code> which sorts out the
result.</p>


<!--, and a tag is translated using the
<code>TAG</code> opcode-->

<p>Further details of what each opcode does can be gleaned from the provided
interpreters and their comments.</p>

<p>The main example interpreter currently provided is in C. It can be used as
starting point for developing interpreters in other languages:</p>

<p class="indent"><a href="interpret.h">interpret.h</a><br/>
<a href="interpret.c">interpret.c</a></p>

<p>There is an array of characters or tokens as input, and two indexes
<code>start</code> and <code>in</code> into it. The items up to
<code>start</code> have been processed, and <code>in</code> is the current
position. So when an action is performed, the items between <code>start</code>
and <code>in</code> are processed, and <code>start</code> is updated to be equal
to <code>in</code>.</p>

<h2 id="transforms">Transforms</h2>

<p>The Pecan grammar language is intended to be sufficiently simple and precise
to support equational transforms. At present, such transforms are carried out
manually and informally on grammars, but it is possible to imagine a theory of
transforms being developed more formally and used to develop and justify
automatic optimisations, or to build an assistant which would suggest and check
user-driven transforms while developing grammars. Equations such as these can be
used:</p>

<pre>(x y) z == x (y z)
(x / y) / z == x / (y / z)
x+ == x x*
x* = (x+)?
x? = x / ""
[[x] y] z == [x y] z
[x y] z / [x u] v == [x] ([y] z / [u] v)
(x / y) z = x z / y z
</pre>

<p>Care has to be taken, because not all 'obvious' equations hold. For example,
<code>x (y / z)</code> is not equivalent to <code>x y / x z</code> because if
<code>x</code> succeeds, in the first case the parser is free to make the choice
between <code>y</code> and <code>z</code>, but in the second case it is already
committed to <code>y</code>. Also <code>x / y</code> and <code>y / x</code> are
not equivalent. However, they are equivalent if it can be established that
<code>x</code> and <code>y</code> begin differently. In these equations, actions
and error markers are included, and the transformed expression has precisely the
same output effect and error handling properties as the original.</p>

<h2 id="changes">Recent changes</h2>

<p>The previous version of Pecan was 0.4. Changes in version 1.0 are:</p>

<ul>
<li>error markers are no longer postfix</li>
<li>the splitter notation <code>&lt;abc></code> and end notation
    <code>&lt;></code> have been added</li>
<li>backquoted tags have been replaced by literal names</li>
<li>separate grammar and test files are supported</li>
<li>one test file can be called from within another</li>
<li>compilation to recursive functions and bytecode is supported</li>
</ul>

<!--
<h2>Tutorial Topics</h2>

<p>Topics: grammar operators, left recursion, right recursion, iteration.
Stack-based actions. Actions not done and undone if backtrack. Actions can do
stuff or build trees. Built-in scanning and drawbacks. Separate scanner. How
to join them up.</p>
-->

</body>
</html>
