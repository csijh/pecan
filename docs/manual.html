<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-gb" xml:lang="en-gb">
<head>
<title>Pecan Manual</title>
<style>
  body { font-size: 120%; }
  pre, table, .indent { margin-left:40px; }
  table, th, td { border: 1px solid black; border-collapse: collapse; }
  table.char td:nth-child(2) { text-align: right; padding-right: 10px; }
</style>
</head>
<body>

<img src="pecan.png" width="300" height="65" />
<hr/>

<h1>Pecan Reference Manual</h1>

<ul>
<li><a href="#use">Using Pecan</a></li>
<li><a href="#intro">Background</a></li>
<ul>
<li><a href="#rd">Recursive descent</a></li>
<li><a href="#cfg">CFG grammars</a></li>
<li><a href="#peg">PEG grammars</a></li>
<li><a href="#pecan">Pecan grammars</a></li>
</ul>
<li><a href="#notation">Notation</a>
<ul>
<li><a href="#rules">Rules</a></li>
<li><a href="#comments">Comments</a></li>
<li><a href="#parentheses">Parentheses</a></li>
<li><a href="#continuations">Continuations</a></li>
<li><a href="#choices">Choices</a></li>
<li><a href="#sequences">Sequences</a></li>
<li><a href="#repetition">Repetition</a></li>
<li><a href="#lookahead">Lookahead</a></li>
<li><a href="#text">Text</a></li>
<li><a href="#escapes">Escapes</a></li>
<li><a href="#errors">Errors</a></li>
<li><a href="#actions">Actions</a></li>
<li><a href="#tokens">Tokens</a></li>
<li><a href="#literals">Literals</a></li>
</ul>
</li>
<li><a href="#testing">Testing</a></li>
<li><a href="#checks">Consistency checks</a>
<ul>
<li><a href="#loop">Left recursion checks</a></li>
<li><a href="#output">Output checks</a></li>
<li><a href="#final">Final checks</a></li>
</ul>
<li><a href="#compile">Compilation</a>
<li><a href="#bytecode">Bytecode</a></li>
</li>
</li>
<li><a href="#transforms">Transforms</a></li>
<li><a href="#changes">Recent changes</a></li>
</ul>

<h2 id="use">Using Pecan</h2>

<p>Pecan is a tool for developing and checking grammars, and generating scanners
and parsers. It is aimed at parsers for programming languages, <a
href="https://en.wikipedia.org/wiki/Domain-specific_language">domain specific
languages</a>, and other unambiguous computer languages. It provides a precise
grammar notation, which is independent of implementation language, based on
recursive descent with lookahead. This manual describes Pecan version 1.0 which
has these features:</p>

<ul>

<li>a grammar is an executable prototype parser</li>

<li>output actions and error markers are included</li>

<li>transformations on grammars preserve actions and error handling</li>

<li>many consistency checks are applied to grammars</li>

<li>there is support for development and testing of grammars</li>

<li>compilation can be direct or via bytecode</li>

<li>compilation can be to almost any target programming language</li>

</ul>

<p>Having a separate notation for grammars helps to focus attention on the
various issues that have to be addressed, separately from the programming
details. However, that also makes grammars rather dense. Creating or translating
a grammar accurately can be difficult. In addition, programmers typically use
parser generators only rarely, and are often not grammar experts. For those
reasons, Pecan has explicit support for test-driven grammar development.</p>

<p>The Pecan system is written in Java, so the first step is to make sure that
version 8 or better of Java is available. Pecan is provided as an executable jar
file <code>pecan.jar</code>. If this jar file is downloaded, it can be run
with:</p>

<pre>java -jar pecan.jar ...
</pre>

<p>However, it is more convenient to create a batch file or shell script, or use
an alias or equivalent, so that the program can be run just by typing:</p>

<pre>pecan ...
</pre>

<p>The way to do this differs from system to system, so isn't described here. To
run tests on a grammar, type a command of the form:</p>

<pre>pecan [-t | -trace] [line] testfile
</pre>

<p>To compile a grammar, type a command of the form:</p>

<pre>pecan grammar -c programfile
</pre>

<p>The option <code>-c programfile</code> indicates that the grammar is to be
compiled to a set of recursive descent functions. The program is a template in
the desired target programming language, into which the functions are embedded,
to form a parser or application program. To translate a grammar to bytecode,
type a command:</p>

<pre>pecan grammar -b binaryfile
</pre>

<p>The option <code>-b binaryfile</code> indicates that the grammar is to be
compiled into a bytecode array in the given binary file. This can then be loaded
into an interpreter program in any desired language to form a parser or
application program.</p>

<h2 id="intro">Background</h2>

<p>Other approaches to developing parsers are usually based on writing them
manually in the <a
href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive
descent</a> style, or using a parser generator based on the <a
href="http://en.wikipedia.org/wiki/Context-free_grammar">context free
grammar</a> (CFG) formalism, or the <a
href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing
expression grammar</a> (PEG) notation.</p>

<h3 id="rd">Recursive descent</h3>

<p>Recursive descent parsers have the advantage of being efficient, intuitive,
and capable of being hand-written. However, for large projects, parsers tend to
become repetitive and error prone. One of the main problems is that a simple
approach is hardly ever enough. In order to deal with the difficult cases which
arise in practice, extra features such as lookahead or backtracking are needed.
These extra features are often added in an ad hoc fashion on practical grounds,
which typically makes parsers complex, obscure and error-prone.</p>

<p>A library of <a href="http://en.wikipedia.org/wiki/Parser_combinator">parser
combinators</a> can ease the process of writing a parser in the recursive
descent style, by providing components which reduce verbosity and automate
features such as lookahead.  However, a combinator library typically still has
two problems. The first is that parsers have to be written in a specific
language in which the library is written, or to which the library has been
ported. The second is that there is typically no separate and independent
grammar, and so there is a shortage of analysis and development tools to help
with the development of parsers.</p>

<h3 id="cfg">CFG grammars</h3>

<p>The CFG notation (in the form of BNF and many variations) has been the main
formalism for grammars for a long time, and it has been well studied. However,
it has been argued quite strongly that it is not an ideal formalism
to use for unambiguous languages. According to <a
href="http://dl.acm.org/citation.cfm?id=964001.964011">Bryan Ford</a>:</p>

<blockquote>The power of generative grammars to express ambiguity is crucial to
their original purpose of modelling natural languages, but this very power makes
it unnecessarily difficult both to express and to parse machine-oriented
languages using CFGs.</blockquote>

<p>One fundamental theoretical problem is that CFG grammars can contain
ambiguities, and there is no computable algorithm to detect whether or not a
grammar is unambiguous. There is also the associated practical problem that many
published CFG grammars contain ambiguities. Some of these are local, i.e. a
particular rule allows two possible parses, but there is a surrounding, more
global, rule that resolves the ambiguity by only accepting one of the
possibilities. But many ambiguities in published grammars are inherent, the
ambiguity being resolved only by accompanying descriptive text or particular
approaches to generating parsers.</p>

<p>As well as ambiguity, there is also the problem that a CFG grammar describes
a language in a generative way, which is not directly and intuitively linked to
the recognition problem faced in parsing. Indeed the meaning of a grammar is
often different from the parser generated from it. There is an awkward semantic
gap.</p>

<p>Conventional CFG-based parser generators have a variety of other flaws,
partly due to the difficulties of the CFG formalism, and partly due to the age
of their designs. They often have arbitrary heuristic rules for disambiguation.
They often support a subset of CFG grammars which is not at all intuitive. They
often use bottom-up parsing techniques to make parsers near-linear, which makes
the way they operate impenetrable. And they often support actions and error
reporting using embedded code fragments which are not part of the grammar. The
code fragments are often restricted to a particular implementation language, and
the approach is any case very fragile.</p>

<p>These problems with the CFG formalism might be worth putting up with, if the
formalism had excellent theoretical or practical properties. But it doesn't.
For example, CFG grammars have poor composability properties, and poor closure
properties. And, in general, parsing CFG grammars takes O(n<sup>3</sup>) time in
the worst case.</p>

<h3 id="peg">PEG grammars</h3>

<p>The main difference with PEG grammars compared to CFG grammars is that the
symmetrical choice operator <code>|</code> is replaced by an ordered choice
operator <code>/</code> which has a more operational meaning. The expressive
power of PEG grammars is extremely close to that of CFG grammars. Certainly,
grammars for all practical everyday languages can be expressed in either
notation.</p>

<p>The theoretical and practical properties of the PEG formalism are far
superior to the CFG formalism. PEG grammars never contain any ambiguity, they
have a direct operational meaning as parsers, they are composable, they are
closed under many operations, and they can be parsed in linear time
using the packrat algorithm. This makes the PEG grammar formalism a much better
starting point for studying grammars and parsers.</p>

<p>Unfortunately, there are practical problems with PEG parsers. Although the
packrat algorithm is linear, it is slower and more space hungry than one would
like for efficient large scale parsing. Also, because of the implicit unlimited
backtracking, it can be difficult to understand or predict the operation of
PEGs, it is difficult to produce accurate error messages, and difficult to
express actions. As a result, PEG grammars are typically only used for search
expressions, or for small domain specific languages, and not for larger
applications such as full programming languages.</p>

<p>There is also a relatively minor problem with PEG grammars, which is that
they don't support left recursion. There have been attempts to add it, but the
results are not compelling. Most uses of left recursion are very simple, of the
kind:</p>

<pre>a = x | a y
</pre>

<p>This can be translated very easily into:</p>

<pre>a = x y*
</pre>

<p>It is well known how to transform away any cases of left recursion.  It is
worth noting that left recursion is arguably unintuitive, and that it would
probably never have become common if it weren't for the prevalence of CFG
grammars.</p>

<h3 id="pecan">Pecan grammars</h3>

<p>Pecan provides a notation for grammars which is an adaptation of the PEG
notation to remove the implicit backtracking. Actions and markers for error
handling are easily embedded as symbols, independently of any target programming
language. Explicit lookahead features are provided to help in making choices,
but they don't involve actions or error handling, so a grammar closely
corresponds to conventional simple recursive descent.</p>

<p>Pecan provides direct support for parser development. Tools are provided to
aid in development and testing, including consistency checks on grammars,
features for automated testing, and the ability to execute grammars as symbolic
parsers.</p>

<p>Manual transformations can be carried out on grammars, e.g. to convert CFG
grammars into Pecan grammars or improve efficiency, and these preserve the
actions and error handling properties of generated parsers.</p>

<p>Once a grammar has been developed, it can be compiled into a set of recursive
descent functions in almost any desired target programming language. A grammar
can alternatively be translated into a bytecode, so that it can be dynamically
loaded into an application.</p>

<h2 id="notation">Notation</h2>

<p>The Pecan language is a grammar language for writing parsers, loosely based
on the <a href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">PEG</a>
notation. Pecan has a sequential choice operator <code>x/y</code> but, unlike
the PEG notation, the operator does not automatically involve backtracking.
There are separate lookahead operators, for the controlled use of backtracking,
which provide greater control over the progress of parsing. That makes it much
easier to generate accurate error messages, while having the full power of the
PEG notation available to decide between alternatives. The approach gives
programmers the expressiveness to make parsers efficient without relying on
obscure automatic optimisations, and parsers normally run without the space
overhead of such techniques as the PEG packrat algorithm. The syntax of Pecan
grammars is explained below. For reference, there is a Pecan grammar for the
Pecan language, with tests, in the files:</p>

<p class="indent"><a href="pecan.txt">pecan.txt</a><br/>
<a href="pecan-test.txt">pecan-test.txt</a></p>

<p>As with PEG grammars, any parsing expression within a grammar represents a
matching operation which succeeds or fails when applied at a particular position
in the input, and which may cause progress, i.e. may cause the current position
to move forwards in the input, according to how much of it is matched.</p>

<h3 id="rules">Rules</h3>

<p>A parser consists of a sequence of rules, each of which gives a name to a
parsing expression. By default, the first rule specifies the output of the
whole parsing process. For example, a parser might start with:</p>

<pre>module = function+ &lt;>

function = id arguments body

...
</pre>

<p>Apart from being the starting point of the parser, the first rule is not
treated in any special way. In particular, it may succeed without consuming all
the input. So an explicit test is often included, as here, to check that the end
of the input has been reached. The notation <code>&lt;></code> which is a less
than sign followed by a greater than sign, matches the end of the input.</p>

<p>An identifier introduced by a rule starts with a letter and continues with
letters, digits, hyphens or underscores. The text of a grammar is assumed to be
encoded using UTF-8, so Unicode letter and digit characters can be included.
There is also a literal form of identifier, consisting of arbitrary characters
in backquotes, which is described further in the section on literal names
below.</p>

<p>In place of a rule, an inclusion may be used:</p>

<pre>{expressions.txt}
</pre>

<p>This is a string giving a file name or path to another file of grammar rules
to be included at this point. This can help in presenting and testing large
grammars in a modular way.</p>

<p>If a parser fails, only the first failure is reported. There is no attempt to
recover. If error recovery is required, this can be accomplished by writing a
separate rule to be tried on the remaining input.</p>

<h3 id="comments">Comments</h3>

<p>Comments start with <code>--</code> and extend to the end of the line. For
example:</p>

<pre>-- A number is a sequence of one or more digits.
number = '0..9'+
</pre>

<p>There is no multi-line comment convention.</p>

<h3 id="parentheses">Parentheses</h3>

<p>Parentheses, i.e. round brackets, have their usual meaning, indicating
grouping of operations. For example:</p>

<pre>(x / y) z
</pre>

<p>means parse <code>x</code> or <code>y</code>, then parse <code>z</code>, as
opposed to:</p>

<pre>x / y z
</pre>

<p>which means either parse <code>x</code>, or else parse <code>y</code> and
<code>z</code>.</p>

<h3 id="continuations">Continuations</h3>

<p>No explicit symbol is used to terminate a rule. A rule is terminated at the
end of a line, unless it is continued. A rule is continued on the next line if
the last token on the current line is an infix symbol or open bracket, i.e. one
of <code>=/([</code>. Here is an example rule where each line except the last
ends with <code>=</code> or the <code>/</code> operator:</p>

<pre>atom =
  id /
  number /
  bracket
</pre>

<p>Also, a rule is continued on the next line if the first token of the next
line is an infix symbol or close bracket, i.e. one of <code>=/)]</code>. This
allows an alternative style for a multi-line rule:</p>

<pre>atom
= id
/ number
/ bracket
</pre>

<p>In this example, each line that starts with <code>=</code> or <code>/</code>
is a continuation of the previous line.</p>

<h3 id="choices">Choices</h3>

<p>The choice operator <code>/</code> separates alternatives, which are tried
one after the other. For example:</p>

<pre>atom = id / number / bracket
</pre>

<p>If parsing of an alternative succeeds, then the parsing of the whole
expression succeeds. Otherwise, if no progress was made, the next alternative is
tried.</p>

<p>The choice operator involves a single item lookahead. If progress is made on
an alternative, i.e. at least one input character or token is matched, then the
parser is committed to that alternative, and further alternatives are not
tried.</p>

<p>There are separate lookahead operators which allow speculative parsing of an
alternative with backtracking.</p>

<h3 id="sequences">Sequences</h3>

<p>When items follow each other with no visible operator in between, this
indicates "followed by". For example:</p>

<pre>assignment = identifier "=" expression
</pre>

<p>This means that an assignment is an identifier followed by an equals sign
followed by an expression. The items are parsed one by one and, if parsing of
any item fails, parsing of the sequence is abandoned. Sequencing binds tighter
than the choice operator.</p>

<h3 id="repetition">Repetition</h3>

<p>There are three postfix repetition operators. The <code>*</code> operator
indicates that an item is to be repeated any number of times, i.e. zero or more
times. The <code>+</code> operator indicates that an item is to be repeated one
or more times. The <code>?</code> operator indicates that an item is optional,
i.e. repeated zero times or once. Postfix operators bind tighter than
sequencing, so <code>x y*</code> means <code>x (y*)</code>. Examples are:</p>

<pre>string = '"' stringchar* '"'
number = digit+
call = function "(" arguments? ")"
</pre>

<p>The <code>string</code> rule specifies that a string consists of a double
quote followed by any number of allowable characters followed by a closing
double quote. The <code>number</code> rule specifies that a number consists of
one or more digits. The <code>call</code> rule specifies that a call consists of
a function name followed by brackets, and the brackets may optionally contain
arguments.</p>

<p>The three expressions <code>x*</code>, <code>x+</code>, <code>x?</code> act
in exactly the same way as the three rules <code>xs</code>, <code>xp</code>,
<code>xq</code> defined by:</p>

<pre>xs = x xs / ""
xp = x (xp / "")
xq = x / ""
</pre>

<p>This means that <code>x*</code> or <code>x+</code> will accept as
many <code>x</code>'s as are present in the input. In all three cases, in line
with the fact that the choice operator does no backtracking by default, if
progress is made on a final <code>x</code> without success, the whole
expression fails.</p>

<h3 id="lookahead">Lookahead</h3>

<p>There are three lookahead constructs, the <dfn>see</dfn> operator
<code>[...]</code>, the <dfn>has</dfn> operator <code>&amp;</code> and the
<dfn>not</dfn> operator <code>!</code>.</p>

<p>The see operator (also called the try or commit operator) is specified using
square brackets. In an expression <code>[x]</code>, the subexpression
<code>x</code> is parsed speculatively. If it succeeds, parsing continues as
normal. If it fails, the parser backtracks to the point just before
<code>x</code>. The see operator is usually used to indicate the point at
which the parser should accept an alternative. For example:</p>

<pre>statement = [identifier "="] expression / ...
</pre>

<p>This specifies that if the parser sees an identifier and equal sign, then it
should commit to the first alternative. If an error occurs before that, e.g. an
identifier has been matched but there is no equal sign, backtracking is done by
resetting the parser to the point before the identifier, and the next
alternative is tried.</p>

<p>The has <code>&amp;</code> and not <code>!</code> operators represent
positive and negative lookahead. In the PEG notation, <code>&amp;</code> and
<code>!</code> are prefix operators, but in Pecan, they are postfix, to make the
syntax of rules simpler and more uniform and, in particular, to avoid precedence
issues which would arise if there were both prefix and postfix operators. The
<code>&amp;</code> and <code>!</code> operators bind more tightly than
sequencing.</p>

<p>With <code>x&amp;</code> or <code>x!</code>, the expression <code>x</code> is
parsed speculatively to check whether it appears next in the input or not.
Whether the expression <code>x</code> succeeds or fails, the parser backtracks
to the beginning. Then <code>x&amp;</code> succeeds if the parsing of
<code>x</code> succeeded, whereas <code>x!</code> succeeds if the parsing of
<code>x</code> failed. For example:</p>

<pre>statement = (type identifier)&amp; declaration / assignment
</pre>

<p>The parser looks ahead to see if there is a type and identifier next in the
input. If there is, the parser backtracks to the point before the type, but
continues with the same alternative and parses a declaration. If the lookahead
fails, an assignment is parsed. A negative example is:</p>

<pre>string = '"' ('"'! visible)* '"'
</pre>

<p>This says that a string contains any visible character other than a double
quote. The bracketed expression only matches a visible character if a double
quote does not appear next in the input.</p>

<p>Lookahead expressions are regarded only as ways to decide which alternative
to take, so actions and error reporting are suspended. During has and not
operations <code>x&amp;</code> or <code>x!</code>, actions and error markers are
ignored. A see operation <code>[x]</code> is equivalent to <code>x&amp;
x</code>, so actions and error reporting are only performed if <code>x</code>
succeeds.</p>

<h3 id="text">Text</h3>

<p>Text notations are used to match input characters. Single quotes indicate
individual characters, e.g. <code>'x'</code> matches the letter <code>x</code>.
Several characters in single quotes indicate a set of distinct alternatives, any
one of which can be matched.  For example:</p>

<pre>op = '+-*/'
digit = '0123456789'
</pre>

<p>The expression <code>'+-*/'</code> matches any one of the four arithmetic
operator characters, and is equivalent to <code>'+' / '-' / '*' / '/'</code>.
The expression <code>'0123456789'</code> matches any digit.</p>

<p>Double quotes indicate a string of characters, which are matched in sequence.
For example:</p>

<pre>keyword = "int" / "if" / "while" / ...
pi = "&#960;"
</pre>

<p>The string <code>"int"</code> only matches if all three characters appear in
the input in sequence, i.e. it is equivalent to <code>['i' 'n' 't']</code>. The
square brackets indicate that if a string matches only partially, the input
position returns to the beginning of the string, and other alternatives can be
tried.</p>

<p>Single characters can be represented using either single or double
quotes. For example:</p>

<pre>double_quote = '"'
single_quote = "'"
</pre>

<p>Grammar files are assumed to use the UTF-8 encoding, and any Unicode
characters can be used in set or string quotes. However, Pecan does not handle
normalization or graphemes, so care needs to be taken. For example,
<code>'é'</code> is visually ambiguous because it could contain one or two code
points, depending on whether a combiner is used to add the accent. In Pecan
sets, each code point is treated as a separate character, so if <code>é</code>
consists of two code points, then <code>'é'</code> represents a choice between
those two code points. If the intended meaning is a single character, it is
better to write <code>"é"</code> in case there are two code points. Similarly,
if the intention of <code>'éè'</code> is a choice between two characters, it is
better to write <code>"é" / "è"</code> to avoid problems.</p>

<p>A range of characters can be expressed using two dots:</p>

<pre>letter = 'a..z'
</pre>

<p>There must be one character (code point) either side of the two dots.</p>

<p>Common sets of characters can be specified using Unicode general categories.
The standard two-letter abbreviations for the Unicode general categories
<code>Cc, Cf, Cn, Co, Cs, Ll, Lm, Lo, Lt, Lu, Mc, Me, Mn, Nd, Nl, No, Pc, Pd,
Pe, Pf, Pi, Po, Ps, Sc, Sk, Sm, So, Zl, Zp, Zs</code> are provided. In addition,
a dot <code>.</code> stands for any Unicode code point. For example:</p>

<pre>letter = Lu / Ll / Lt / Lm / Lo
digit = Nd
connector = '_'! Pc
visible = (Cc/Cn/Co/Cs/Zl/Zp)! .
</pre>

<p>The Unicode categories starting with <code>L</code> are letters. The letter
rule allows any kind of letters: upper case, lower case, title case, modifier
and other. Categories starting with <code>N</code> are number characters, of
which <code>Nd</code> is the set of decimal digits. The connector rule uses the
<code>Pc</code> connector punctuation category, but excludes the underscore
character. The <code>visible</code> rule matches any character, excluding code
points which are unassigned, private, surrogate, controls, or line or paragraph
separators.</p>

<p>A splitter is a string in angle brackets such as <code>&lt;abc></code> which
represents a lookahead. It does not consume any input characters, but succeeds
if the remaining input, regarded as a string, is lexicographically less than or
equal to <code>"abc"</code>. For example:</p>

<pre>keyword = &lt;df> keyword1 / keyword2
keyword1 = "break" / "case" / "catch" / "continue" / "default"
keyword2 = "do" / "else" / "for" / "if" / "switch" / "while"
</pre>

<p>Here, some keywords are listed in alphabetical order, and a splitter is used
to speed up their recognition by separating the keywords up to
<code>"default"</code> from the keywords from <code>"do"</code> onwards. Note
that <code>&lt;default></code> should not be used as the splitter in this
example, because if <code>"default"</code> is next in the input, the input
continues after that and is therefore lexicographically greater. Nor should the
splitter be <code>&lt;do></code>, just in case <code>do</code> is at the end of
the input text.</p>

<p>The empty string <code>""</code> always succeeds, the empty set
<code>''</code> always fails, and the empty splitter succeeds only at the end of
the input:</p>

<pre>succeed = ""
fail = ''
end = &lt;>
</pre>

<p>These can be particularly useful during transformations.</p>

<h3 id="escapes">Escapes</h3>

<p>There are escape conventions within sets, strings, ranges, splitters and
literal names (see later), to include control characters, or awkward characters,
or to represent Unicode characters using plain text. A summary of the escape
conventions is:</p>

<table class="char">
<tr><th>Escape</th><th>Code</th><th>Character</th></tr>
<tr><td><code>\r</code></td><td>13</td><td>return</td></tr>
<tr><td><code>\n</code></td><td>10</td><td>newline</td></tr>
<tr><td><code>\q</code></td><td>39</td><td>single quote</td></tr>
<tr><td><code>\d</code></td><td>34</td><td>double quote</td></tr>
<tr><td><code>\g</code></td><td>96</td><td>grave/backquote</td></tr>
<tr><td><code>\b</code></td><td>92</td><td>backslash</td></tr>
</table>

<p></p>

<table>
<tr><th>Escape</th><th>Meaning</th></tr>
<tr><td><code>\ddd...;</code></td><td>character with decimal code</td></tr>
<tr><td><code>\0hhh...;</code></td><td>character with hexadecimal code</td></tr>
</table>

<p>Escape sequences such as <code>\a</code>, <code>\e</code>, <code>\f</code>,
<code>\t</code>, <code>\v</code> are not supported because they are, or should
be, obsolete. Escape sequences such or <code>\\</code>, <code>\'</code>,
<code>\"</code> are not supported because they complicate scanning and cause
visual confusion. A numerical escape is a backslash followed by digits, with an
optional semicolon terminator. It is used to represent a single character, using
its decimal character code. For example:</p>

<pre>pi = '\960'
any = '\0..\1114111'
</pre>

<p>If the first digit is zero, then the character code is in hexadecimal, using
<code>a</code> to <code>f</code> or <code>A</code> to <code>F</code>, e.g.</p>

<pre>pi = '\03C0'
any = '\0..\010ffff'
</pre>

<p>Numerical escape sequences are variable length. A decimal sequence ends when
a non-digit is encountered, and a hex sequence ends when a non-hex-digit is
encountered. If an escape sequence is to be followed by a digit or a semicolon,
then it should be terminated by a semicolon, e.g.</p>

<pre>pi3 = "\960;3"
pi-semicolon = "\960;;"
</pre>

<h3 id="errors">Errors</h3>

<p>By default, a parser produces an error message which points to the furthest
position reached in the input text, other than in lookaheads, but which gives no
details. For example, suppose this rule is being parsed:</p>

<pre>sum = number ("+" number / "-" number)
</pre>

<p>Then a message like this might be produced for an incorrect operator:</p>

<pre>Error on line 1:
40%2
  ^
</pre>

<p>Markers can be added to parser rules, to describe the items which would have
allowed parsing to continue. A marker is a symbol consisting of the
<code>#</code> character followed by a name. The name has the same form as an
identifier. In particular, it can be literal, as described in the literals
section. For example, suppose the rule above is changed to:</p>

<pre>sum = number (#plus "+" number / #minus "-" number)
</pre>

<p>Then, for an incorrect operator, the expressions <code>"+"</code>
and <code>"-"</code> both fail, so the error message produced becomes:</p>

<pre>Error on line 1: expecting minus, plus
40%2
  ^
</pre>

<p>When a marker is encountered, it is associated with the current position in
the input. It records something that the parser is expecting at that point. If
progress is made past that input position, the marker is cleared. When the
parser encounters an error, the set of things that the parser was expecting at
that point is reported. Duplicates are removed, for example suppose the rule
is changed to:</p>

<pre>sum = number (#operator "+" number / #operator "-" number)
</pre>

<p>Then the error message becomes:</p>

<pre>Error on line 1: expecting operator
40%2
  ^
</pre>

<p>During testing and development, markers are reported in alphabetical order.
When a grammar is compiled, the order, and the text produced, can be
customised.</p>

<p>One way to ensure that all the items which could possibly allow parsing to
continue are reported is to write separate rules to describe low level features
of a grammar involving primitive character matchers, i.e. strings, sets, etc.,
and begin each with a marker. For example, a parser for a programming language
might contain rules such as:</p>

<pre>plus = #operator "+" @
letter = #letter (Lu / Ll / Lt / Lm / Lo)
number = #number ('0'..'9')+ @read
newline = #newline '\r'? '\n' @
end = #end &lt;>
</pre>

<p>The <code>plus</code> rule specifies that the plus sign is to be described as
an operator in error messages. The <code>letter</code> rule applies an error
marker to a choice of Unicode categories, to avoid having to attach a marker to
each one individually.</p>

<h3 id="actions">Actions</h3>

<p>Actions allow a parser to operate on values or data structures, using a
stack, to produce an output. An action is a symbol which consists of the
<code>@</code> character followed by a number followed by a name. If there is no
number, it is assumed to be zero. The name follows the same rules as an
identifier. In particular, it can be a literal name, as discussed in the section
on literals. For example:</p>

<pre>sum = term (plus term @2add)*
</pre>

<p>Suppose that the <code>term</code> rule pushes a single item onto the stack,
and the <code>plus</code> rule doesn't affect the stack. The <code>@2add</code>
symbol in the <code>sum</code> rule indicates that two items should be popped
off the stack, the <code>add</code> action should be performed, which creates a
new item, and the new item should be pushed onto the stack. A parser as a whole
ends with a single item on the stack, which is the output from the parsing
process.</p>

<p>Defining an action as a stack-based operation allows it to be expressed as a
self-contained symbol at a specific point in a grammar. That in turn allows
actions to take part in grammar transformations which move actions away from
their arguments. For example, the above rule can be transformed to these rules,
where the two arguments to the <code>add</code> action are separated:</p>

<pre>sum = term more*
more = plus term @2add
</pre>

<p>The stack is provided and manipulated by external code when a parser is
generated from the grammar. An action symbol such as <code>@2add</code> is
translated into the execution of a fragment of external code. The parser could
be part of a calculator, in which case the <code>add</code> action might add two
numbers. Alternatively, the parser might become part of a compiler, in which
case the <code>add</code> action might combine two expression trees into a
larger tree. When executing a grammar symbolically for testing, the name of the
action is simply printed out.</p>

<p>An action has access to the characters or tokens from the input which have
been matched since the previous action. For example:</p>

<pre>number = digit+ @read
</pre>

<p>The action <code>@read</code> creates a new item from the digits which
have just been matched, and pushes it onto the stack. There is a further
convention which allows matched characters to be discarded. For example:</p>

<pre>spaces = ' '+ @
</pre>

<p>An <code>@</code> sign on its own causes any recently matched characters (or
tokens) to be discarded by the parser, without any external code being
executed.</p>

<p>Recently matched characters are available to an action, no matter what arity
it has. However, for an action like <code>@2add</code> which combines output
items, it is common to ignore them. If there are any such characters, and they
are ignored by an action, they are implicitly discarded. Also, a discard with
non-zero arity such as <code>@2</code> is allowed. This discards two output
items, as well as any outstanding matched characters.</p>

<p>There are severe consistency restrictions on actions. Every expression or
rule must produce or consume a fixed number of output items. Each alternative in
a choice must create or consume the same number of output items. Within a
repetition, i.e. <code>x*</code> or <code>x+</code> or <code>x?</code>, the
inner expression <code>x</code> must have no net effect on the number of output
items.</p>

<p>The compensation for these severe restrictions is that Pecan can carry out
strong consistency checks on grammars, ensuring that every expression produces a
fixed and known number of output items overall, and needs a known number of
items to be on the stack before it is executed.</p>

<p>The first rule in a grammar must produce a single output item overall, and
must not need any items on the stack before execution, so that it cannot cause
the output stack to underflow. However, if this is not the case, the error is
reported only when attempting to generate a parser from the grammar. That means,
during development and testing, a grammar with no actions is legal, and also any
self-contained fragment of a grammar is legal.</p>

<p>Scanners are normally thought of as producing a sequence of tokens. But in
Pecan, even a scanner must produce a fixed number of output items. A scanner
can be defined like this:</p>

<pre>scan = @tokens token+ end
token = number @1number / id @1id / ...
</pre>

<p>The <code>@tokens</code> action creates an output item representing the list
or array of tokens to be generated, initially empty. Each action such as
<code>@1number</code> takes the recently matched characters, creates a token
from them, and adds it to the list. The list is the only output from the
scanner.</p>

<p>In a token-based parser, there are often variable-length sequences, which
need to be dealt with in a similar way. For example, a comma-separated list of
identifiers can be expressed by:</p>

<pre>ids = @list id @2id ("," id @2id)* @1end
</pre>

<p>The <code>id</code> rule is assumed to push a single item onto the output
stack. The <code>@list</code> action creates an empty list. The
<code>@2id</code> action pops the list and most recent id, adds the id to the
list, and pushes the resulting list back on the stack. The <code>@1end</code>
action does anything necessary to finalize the list.</p>

<p>The external code in a generated parser may choose a different implementation
with the same overall effect. For example, <code>@list</code> may mark a
position in the output stack, <code>@2id</code> may do nothing, so that ids
accumulate on the stack, and <code>@1end</code> may use the marked stack
position to create an array out of the accumulated ids. Alternatively,
<code>@list</code> could create a linked list, each subsequent
<code>@2id</code> could chain the next id onto the end of the list, and
<code>@1end</code> could do nothing.</p>

<p>Techniques like this for handling variable-length lists can easily lead to a
left hand alternative which begins with an action, for example:</p>

<pre>@a x / y
</pre>

<p>The action <code>@a</code> is performed whether or not <code>x</code>
succeeds. This is not completely intuitive, and probably not what was intended
since <code>@a (x / y)</code> would express the intention better. This issue is
not reported during development, so that transformations remain valid, but is
reported when compilation is requested. A similar situation arises with error
markers:</p>

<pre>#m x / y
</pre>

<p>However, the fact that the marker takes effect even if <code>x</code> fails
is normal, so that if parsing as a whole fails without progressing beyond this
point, the marker is reported as one of the things expected.</p>

<h3 id="tokens">Tokens</h3>

<p>Support is provided for parsers where the input consists of tokens produced
by a separate scanner. The input is thought of as an array of tokens instead of
an array of characters.</p>

<p>A tag is represented as a symbol consisting of the <code>%</code> character
followed by a name. The name has the same form as an identifier. In particular,
it can be literal, as described in the next section. Each tag represents a
specific kind of token. For example, a token-based parser for a simple
calculator with no brackets might look like this:</p>

<pre>sum = term (%plus term @2add / %minus term @2subtract)* end
term = number (%times number @2multiply / %over number @2divide)*
number = %int @read
end = &lt;>
</pre>

<p>In this case, the input is an array of tokens with tags <code>%int</code>,
<code>%plus</code>, <code>%minus</code>, <code>%times</code> or
<code>%over</code>.</p>

<p>In token-based parsers, text matching notations are not allowed, except for
<code>''</code>, <code>""</code> and <code>&lt;></code>.</p>

<p>A tag represents a call to an external function to find the type of the
current token. This allows a limited form of context dependence while parsing.
For example, it is well known that parsing of the C language requires typedef
names to be recognised separately from other identifiers, and that typedef
constructs have to be parsed to provide that information. This can be achieved
by classifying both types of token as identifiers in the scanner. Then, in the
parser, the actions carry out sufficient symbol table construction to represent
typedef constructs. Then, when the external tag function is called, it uses
the symbol table to decide whether to return an identifier tag or a typedef
tag.</p>

<h3 id="literals">Literals</h3>

<p>The names used in identifiers, actions, markers and tags normally consist of
a letter followed by letters, digits, hyphens or underscores. Literal names can
be used as an alternative. A literal name consists of one or more characters
inside backquotes. The escape sequences described earlier are also available.
This helps to make grammars more readable when a separate scanner and parser are
being designed. For example, a scanner might contain:</p>

<pre>ge = ">=" @1`>=`
</pre>

<p>Each character in a literal name is automatically converted to an
alphanumeric form, e.g. <code>@1`>=`</code> is equivalent to
<code>@1GtEq</code>. Then, when the scanner is compiled, the action name
<code>GtEq</code> is a valid identifier or constant in the target programming
language. If action names are used as token tags, this notation avoids the need
to invent tag names for tokens with fixed spellings.</p>

<p>In the corresponding token-based parser, the tag name produced can be matched
by a tag with the same literal name. For example:</p>

<pre>ge = #op %`>=`
</pre>

<p>The same translation to alphanumeric form is used, so the tag
<code>%`>=`</code> is equivalent to <code>%GtEq</code> and the compiled parser
thus matches up with the compiled scanner.</p>

<p>To improve the readability of a token-based parser further, e.g. so that it
corresponds closely to a published grammar, literal names can also be used for
identifiers. For example:</p>

<pre>comparison = expression `>=` expression
...
`>=` = #op %`>=`
</pre>

<p>For an alphanumeric literal, the quotes have no effect, so <code>`int`</code>
is equivalent to <code>int</code>, making the quotes unnecessary, but using
<code>`int`</code> may still be desirable to emphasize that the identifier
stands for a keyword token with a fixed spelling. Whether backquotes are used or
not, hyphens are translated to <a
href="https://en.wikipedia.org/wiki/Camel_case">camel case</a> to make it more
likely that the result is a valid identifier in the target programming language.
For example, a tag <code>%string-literal</code> is translated to
<code>stringLiteral</code>.</p>

<p>When a grammar is compiled to produce a parser, custom adjustments can be
specified for each different type of name, to prevent name clashes. The same
adjustment should be specified for actions in the scanner as for tags in the
parser, so that the generated tag names correspond.</p>

<h2 id="testing">Testing</h2>

<p>During development of a grammar, testing can be carried out by symbolic
execution without having to generate a parser. This is done by typing a command
of the form:</p>

<pre>pecan [-t | -trace] [line] testfile
</pre>

<p>The test file contains the tests to be carried out. The <code>-trace</code>
option switches on tracing, so that the individual steps taken during parsing
are displayed. If a line number is given, only the single test that starts on
that line of the test file is executed.</p>

<p>A test file contains a number of sections separated by lines consisting of
ten or more equal signs. If a section contains a line of ten or more minus signs
as a separator, then it is a test with sample input and expected output. If a
section has no separator, it is a grammar or self-contained grammar fragment
which is used for subsequent tests, until another grammar is given. For
example:</p>

<pre>// Match one digit
number = ("0".."9") @read
==========
2
----------
read 2
==========
42
----------
read 4
==========
// Match any number of digits
number = ("0".."9") @read
==========
42
----------
read 42
</pre>

<p>The first section of this file sets up a grammar, then there are two tests
using that grammar, then a new grammar is given, then there is a final test
using the second grammar.</p>

<p>The output from running a test using a given grammar and sample input is a
list of the actions that would be performed by a parser generated from the
grammar. If the input is text, the characters matched since the previous action
or discard are displayed.</p>

<p>For a token-based grammar, the input consists of a sequence of tag names
separated by white space:</p>

<pre>// Match a list of numbers.
list = %number @read (%comma %number @read @2and)*
==========
number comma number comma number
----------
read
read
and
read
and
</pre>

<p>When a test fails, its line number is reported in the error message. That
line number can then be used to re-run the testing, but picking out only that
one test to be performed, perhaps with tracing:</p>

<pre>pecan tests.txt
Fail test on line 24 of tests.txt:
---------- Expected ----------
...
---------- Actual ----------
...

pecan -trace 24 tests.txt
...
</pre>

<p>A grammar in a test file can have an inclusion. For example, a file
<code>tests.txt</code> might start with:</p>

<pre>{grammar.txt}
==========
...
</pre>

<p>This is the usual way to arrange for  a grammar to be in one file,
<code>grammar.txt</code> in this case, and the tests in another. A test file
might also begin with something like:</p>

<pre>start = expression &lt;>
{expressions.txt}
statement = ...
==========
...
</pre>

<p>In this case, the file <code>expressions.txt</code> contains one module of a
multi-module grammar. The <code>start</code> rule specifies that it is the
<code>expression</code> rule that is under test, and <code>&lt;></code> is used
to ensure that the <code>expression</code> rule parses all of the input supplied
in each test. The <code>statement</code> rule provides a simplified version of a
rule from another module, which the file <code>expressions.txt</code> makes a
forward reference to.</p>

<p>If a grammar fragment consists of a single line which is an inclusion, then
the included file can be another test file, rather than just a grammar, allowing
tests to be grouped:</p>

<pre>{group1.txt}
==========
{group2.txt}
==========
...
</pre>

<p>There is no conflict between a filename representing a grammar and one
representing a subfile of tests. That is because a grammar file is equivalent to
a test file which sets up a grammar, but contains no tests.</p>

<p>Test files are assumed to use the UTF-8 encoding. They are normalized to
avoid common visual ambiguity problems, by changing all line endings to
<code>\n</code>, removing trailing spaces at the ends of lines, and removing
trailing blank lines at the very end of the test file. The escape sequences
described earlier are recognised anywhere in the test input, and can be used to
express control characters and Unicode characters beyond ASCII in the output. To
allow edge cases to be tested, there is a further convention that if an input
line ends in an escape sequence, the newline is cancelled. For example:</p>

<pre>==========
Line one\r
Line two \n
----------
...
</pre>

<p>The first input line ends in a carriage return instead of a line feed, and
the second input line has a trailing space.</p>

<h2 id="checks">Consistency checks</h2>

<p>A number of checks are performed on a grammar which help to ensure
consistency. Some obvious checks are done first, such as syntax checking of the
grammar, checking that each rule name is defined exactly once, and checking that
no rule name clashes with a category name.</p>

<p>A grammar is checked to see if it represents a text parser or a token parser.
A text parser must contain no tags. A token parser must not contain text
matchers, i.e. strings, splitters, sets, ranges or numbers, with the exception
of <code>""</code> or <code>''</code> or <code>&lt;></code>.</p>

<p>There are also checks on sets and ranges. Sets must contain distinct
characters, and a range must be non-empty.</p>

<p>Many parsing expressions are equivalent, which considerably reduces the
number of cases that need to be discussed. For example:</p>

<pre>.         &#8801;  '\0..\1114111'
'\32'     &#8801;  ' '
'a'       &#8801;  "a"
"ab"      &#8801;  ['a' 'b']
'ab'      &#8801;  'a' / 'b'
'a..z'    &#8801;  'a' / ... / 'z'
Ll        &#8801;  'a' / ... / 'z' / ...
x?        &#8801;  x / ""
x*        &#8801;  xs  where  xs = (x xs)?
x+        &#8801;  x x*
[x]       &#8801;  x&amp; x
x&amp;        &#8801;  x!!
''        &#8801;  ""!
&lt;b...>    &#8801;  &lt;> / '\0..a'&amp; / ('b' &lt;...>)&amp;
&lt;>        &#8801;  .!
</pre>

<p>The core features remaining are:</p>

<pre><code>id = x</code>      rules
<code>""</code>          the empty string (always succeeds)
<code>"x"</code>         single characters
<code>x/y</code>         choices
<code>x y</code>         sequences
<code>x!</code>          the 'not' lookahead
<code>%a</code>          tags
<code>@2a, @a, @</code>  actions
<code>#a</code>          markers
</pre>

<p>The main checks are to make sure that there is no left recursion, and that
output items are handled consistently.</p>

<h3 id="loop">Left recursion checks</h3>

<p>Pecan checks that the grammar contains no infinite loops caused by left
recursion. The simplest example is where a rule mentions its own name at the
start of its right hand side, or at the start of one of its alternatives:</p>

<pre>sum = sum "+" term / term
</pre>

<p>In a Pecan grammar, a rule of this form leads to an immediate infinite loop,
and so is reported as an error. Indirect left recursion is also detected. That
is where two or more rules mention each other at the beginning:</p>

<pre>expression1 = expression2 ...
expression2 = expression1 ...
</pre>

<p>Less obvious cases of left recursion are also detected, e.g.</p>

<pre>statement = label* statement
</pre>

<p>Although <code>statement</code> does not mention itself right at the
beginning, the expression <code>label*</code> may succeed without any input
being matched, and therefore an infinite loop ensues.</p>

<p>To implement the checks, four boolean properties of expressions
<code>SP</code>, <code>SN</code>, <code>FP</code>, <code>FN</code> are
calculated for each expression. The <code>SP</code>, <code>SN</code> properties
mean the expression can succeed with or without progress being made in the
input, and <code>FP</code>, <code>FN</code> mean that an expression can fail,
with or without progress. These are very similar to the properties used in
the analysis of PEG grammars, though there <code>FP</code> and <code>FN</code>
are not distinguished.</p>

<p>As well as the equivalences already mentioned, there are further parsing
expressions which are equivalent from the point of view of success or failure,
and progress or not:</p>

<pre>%a          &#8801;  "a"
@2a, @a, @  &#8801;  ""
#a          &#8801;  ""
</pre>

<p>The way the properties are calculated for the remaining features of grammars
(using <code>&amp;</code> for 'and' and <code>|</code> for 'or', with
<code>&amp;</code> binding tighter, and using <code>def(id)</code> for the right
hand expression of a rule for identifier <code>id</code> are:</p>

<pre>SN(id) = SN(def(id))
SP(id) = SP(def(id))
FN(id) = FN(def(id))
FP(id) = FP(def(id))

SN("") = true
SP("") = false
FP("") = false
FN("") = false

SP("a") = true
FN("a") = true
SN("a") = false
FP("a") = false

SN(x y) = SN(x) &amp; SN(y)
SP(x y) = SP(x) &amp; SP(y) | SP(x) &amp; SN(y) | SN(x) &amp; SP(y)
FN(x y) = FN(x) | SN(x) &amp; FN(y)
FP(x y) = FP(x) | SN(x) &amp; FP(y) | SP(x) &amp; FN(y) | SP(x) &amp; FP(y)

SN(x/y) = SN(x) | FN(x) &amp; SN(y)
SP(x/y) = SP(x) | FN(x) &amp; SP(y)
FN(x/y) = FN(x) &amp; FN(y)
FP(x/y) = FP(x) | FN(x) &amp; FP(y)

SN(x!) = FN(x) | FP(x)
SP(x!) = false
FN(x!) = SN(x) | SP(x)
FP(x!) = false
</pre>

<p>Because these rules are themselves recursive, fixed point iteration is used,
i.e. the values are calculated repeatedly until they don't change. If all the
values are set to <code>false</code> at the start, the only possible changes are
from <code>false</code> to <code>true</code>, so the iteration terminates.</p>

<p>Once these values are known, a further boolean property, <code>WF</code> is
calculated to check that the grammar is well formed. The <code>WF</code>
property is calculated (using <code>~</code> for 'not') by:</p>

<pre>WF(id) = WF(def(id))
WF("") = true
WF("a") = true
WF(x y) = WF(x) &amp; (~SN(x) | WF(y))
WF(x / y) = WF(x) &amp; WF(y)
WF(x!) = WF(x)
</pre>

<p>If <code>WF</code> turns out to be false for any expression, that expression
is reported as an error because it contains left recursion.</p>

<!--
<h3 id="token">Token checking</h3>


<p>For grammars which have text as input, a check is made that all tokens
produced are non-empty, so that continual progress is made through the
characters in the input. For example:</p>

<pre>id = letter+ @identifier
letter = 'a..z'
</pre>

<p>Here, it is clear that by the time the accept action
<code>@identifier</code> is reached, at least one letter has been matched from
the input. On the other hand, suppose the <code>id</code> rule was:</p>

<pre>id = letter* @identifier
</pre>

<p>This causes an error message, because <code>@identifer</code> can be reached
without matching any input characters. However, if this <code>id</code> rule
is always used in a context where at least one character has already been
matched, i.e. the <code>id</code> rule refers to the remainder of a token
rather than a whole token, then there is no error.</p>

<p>This check is implemented by making as many deductions as possible about
positions in the grammar at which input characters have definitely been matched
since the previous token. This is a conservative check - it is possible for a
pathological grammar to produce an error message even though no empty token
would ever be created in practice.</p>

<p>There is a further check that a scanner makes no attempt to read past the
end of the input. For example, suppose there is a scanner rule like
this:</p>

<pre>tokens = token+ UC! @end
token =  space / identifier / keyword / operator / punctuation
</pre>

<p>This is fine, because all that follows the end of text <code>''</code> is an
action, not any attempt to match any characters. However, suppose the
rule is:</p>

<pre>tokens = token+
token = space / identifier / keyword / operator / punctuation / end
end = '' @end
</pre>

<p>This does cause an error, because after recognising the end of text, the
scanner could continue to look for more tokens.</p>
-->

<h3 id="output">Output checks</h3>

<p>Actions are assumed to treat output items in a stack-like manner. Restrictive
checks are made to guarantee consistent handling of output items. The arity of
each action has to be specified, and has to be consistent each time the action
appears. For example if a grammar contains both <code>@1add</code> and
<code>@2add</code>, that is reported as an error. The arities are used to check
that each expression in the grammar produces a fixed, known number of output
items.</p>

<p>The net overall number of items added to the stack, possibly negative, is
calculated for each expression in the grammar.</p>

<p>Both alternatives in a choice expression must have the same net effect. For
example, this rule causes an error:</p>

<pre>token = ('0..9')+ @token / ' '+
</pre>

<p>The first alternative adds one item to the stack, but the second adds
nothing. On the other hand, this rule is legal:</p>

<pre>token = ('0..9')+ @1token / ' '+
</pre>

<p>The <code>@1token</code> action pops an item from the stack, presumably a
list of tokens, and pushes one item back on the stack, presumably the updated
list. It thus has zero net effect. Since both alternatives now have a zero net
effect, the <code>token</code> rule itself can be deduced as having a zero net
effect.</p>

<p>A repeated expression must have zero net effect. For example, suppose the
grammar contains:</p>

<pre>tokens = (('0..9')+ @token)*
</pre>

<p>The inner expression causes one output item to be pushed on the stack. This
is reported as an error, because the <code>tokens</code> rule as a whole pushes
an unknown number of items onto the stack. On the other hand, this definition is
allowed:</p>

<pre>tokens = (('0..9')+ @1token)*
</pre>

<p>The inner expression pops a previous list item, adds a token to it, and
pushes the updated list onto the stack. As a result, it has a zero net effect.
It can be repeated any number of times, still with a zero net effect, and so the
<code>tokens</code> rule can be deduced to have zero net effect.</p>

<p>As well as repeated expressions, recursion is also restricted so that the
number of output items produced is fixed. For example:</p>

<pre>x = 'a' x @a
</pre>

<p>Here, the number of items pushed onto the stack depends on the number of
times <code>x</code> calls itself recursively. So this is reported as an
error.</p>

<p>A further check is related to stack underflow. For each expression, the
number of items which need to be on the stack when the expression is executed is
calculated. For example, the expression <code>('0..9')+ @1token</code> needs one
item to be on the stack. There are situations where the needed number can't be
calculated, for example:</p>

<pre>x = 'a' / 'b' @2c x @d
</pre>

<p>Every time <code>x</code> calls itself recursively, one more item is needed
on the stack, even though the net effect of <code>x</code> is zero. Such a
situation is reported as an error.</p>

<h3 id="final">Final checks</h3>

<p>There are a few checks that are not made until a grammar is compiled. One is
that the first rule in the grammar produces exactly one output item. For
example:</p>

<pre>first = "a" @b @c
</pre>

<p>This produces two items, so is reported as an error. A second check is that
the first rule needs no items to be on the stack before it starts. For
example:</p>

<pre>first = "a" @1b @c
</pre>

<p>Although overall this produces one output item, it needs an output item to be
on the stack before parsing starts. The check ensures that parsing of the entire
grammar can never cause a stack underflow.</p>

<p>These two issues are not reported during development of a grammar, so that a
grammar with no actions, or a self-contained fragment of a grammar, are legal
and can be tested.</p>

<p>A further check is that any left hand alternative of a choice can fail with
no progress. For example:</p>

<pre>x = "" / "a"
</pre>

<p>The first alternative can't fail, so the second alternative is inaccessible,
i.e. parsing can never reach it. Another check is that a left hand alternative
doesn't start with an action. For example:</p>

<pre>x = @a "b" / y
</pre>

<p>This is to guard against ambiguity. The action <code>@a</code> is executed
whether or not the first alternative succeeds, which is probably not what is
intended. If it is what is intended, it should be rewritten as:</p>

<pre>x = @a ("b" / y)
</pre>

<p>These issues concerning choices are not reported during development of a
grammar, because they can temporarily arise naturally during
transformations.</p>

<h2 id="compile">Compilation</h2>

<p>A grammar can be compiled to a set of recursive functions, in almost any
desired target programming language. A grammar is compiled using a command of
the form:</p>

<pre>pecan grammar -c programfile
</pre>

<p>The option <code>-c programfile</code> specifies a template program file. The
program file must already exist, and it must contain a placeholder such as:</p>

<pre>// &lt;pecan ...
// >
...
// &lt;/pecan>
</pre>

<p>The placeholder begins with a commented out open tag <code>&lt;pecan></code>,
with attributes as described below, and ends with a commented out close tag
<code>&lt;/pecan></code>. Lines in between the two tags, if any, are removed,
and the result of compiling the grammar is inserted in their place. That means
compiling can be carried out repeatedly using the same program file.</p>

<p>An example template program in the C language, with two supporting data
files, is:</p>

<p class="indent"><a href="compilation/parse.c">parse.c</a><br/>
<a href="compilation/table1.bin">table1.bin</a><br/>
<a href="compilation/table2.bin">table2.bin</a></p>

<p>Very few restrictions are placed on the target programming language when
compiling. The main assumption is that the language has two binary and/or
operators which are guaranteed to use short-circuit evaluation, i.e. they do not
evaluate their right hand arguments unnecessarily. In many languages, the
symbols <code>&amp;&amp;</code> and <code>||</code> are suitable. The
<code>&amp;&amp;</code> operator does exactly what is required for a sequence
<code>x y</code>, evaluating <code>x</code> and then, only if <code>x</code>
succeeds, continuing with <code>y</code>. A choice <code>x / y</code> is
complicated by the need to test whether <code>x</code> has progressed or not
before deciding whether to try <code>y</code> instead. So, in general, <code>x /
y</code> is compiled into something like:</p>

<pre>alt((go() &amp;&amp; tx) || (ok() &amp;&amp; ty))
</pre>

<p>Here <code>tx</code>, <code>ty</code> represent the translations of
<code>x</code>, <code>y</code> into boolean expressions. The <code>go</code>
function pushes the current input position onto a stack before <code>tx</code>
is executed, the <code>ok</code> function checks for progress, and the
<code>alt</code> function pops the saved position off the stack after the choice
has been completed. The <code>go</code> function is also used in the compilation
of other Pecan features. For example, an expression <code>x&amp;</code> is
compiled to:</p>

<pre>has(go() &amp;&amp; tx)
</pre>

<p>The <code>has</code> function pops the position saved by <code>go</code> and
backtracks to it, before returning the result of <code>tx</code>.</p>

<p>This general approach, using a background stack for progress checking, allows
every parsing expression to be compiled into a boolean expression, with only the
<code>&amp;&amp;</code> and <code>||</code> operators being used to combine
expressions.</p>

<p>The open tag <code>&lt;pecan...></code> of the placeholder includes
attributes. The attributes specify details of how to generate functions in the
target language for the given application:</p>

<pre>// &lt;pecan
//     comment = "// %s"
//     declare = "bool %s(parser *p);"
//     define  = "bool %s(parser *p) { %n return %r; %n}"
//     call    = "%s(p)"
//     escape1 = "\%3o"
//     escape2 = "\u%4x"
//     escape4 = "\U%8x"
// >
...
// &lt;/pecan>
</pre>

<p>This example is suitable for C as a target language, where a pointer to a
parsing state is to be passed to every parsing function. Each attribute is on a
separate line, and consists of one of the attribute names described below,
followed by an equal sign followed by a string in single or double quotes. The
whole attribute may be preceded or followed by comment characters. Each
attribute string is a format string in a printf style specifying the text to be
generated for a specific Pecan feature.</p>

<p>In a format string, the percent character is the only special character, used
for specifiers. There are no backslash escape conventions. Each specifier
determines what to extract and print from the current construct.</p>

<p>The specifier <code>%s</code> indicates that a string or name should be
printed. Identifier names with hyphens are translated to <a
href="https://en.wikipedia.org/wiki/Camel_case">camel case</a> and literal names
are translated as described earlier. The specifiers <code>%l</code>,
<code>%r</code> indicate that a left or right subexpression is to be compiled
and printed. The specifier <code>%n</code> indicates that if an expression does
not fit on the current line, a newline and indent is printed. A space before
<code>%n</code> is deleted if the newline is printed. A space after
<code>%n</code> increases the indent temporarily if the newline is printed, or
is deleted otherwise. A character can be printed directly using <code>%c</code>,
or its integer code can be printed using <code>%d</code> for decimal,
<code>%o</code> for octal, or <code>%x</code> for hexadecimal. A fixed number of
digits can be specified for <code>%d</code>, <code>%o</code> or <code>%x</code>,
e.g. <code>%4x</code>, with leading zeros being added where necessary. When
printing a range, two character or numeric specifiers are used to refer to the
low and high characters, e.g. the format for a range might be
<code>"range('%c','%c')"</code>.</p>

<p>The attributes that can be specified are:</p>

<ul>

<li><p><code><b>declare</b>:</code> the format for generating a forward
declaration of a function. The format string might be <code
style="white-space:nowrap">"bool %s();"</code> for example. The default is
<code>""</code> so that no forward declarations are generated.</p></li>

<li><p><code><b>comment</b>:</code> the format for generating each line of a
comment before each function generated. The format string might be <code
style="white-space:nowrap">"// %s"</code> or <code
style="white-space:nowrap">"/* %s */"</code> for example. The <code>%s</code>
refers to the source text of the Pecan rule that the function corresponds to.
The default is <code>""</code> so that no comments are generated.</p></li>

<li><p><code><b>define</b>:</code> the format for a function definition
generated from a rule <code>id = e</code>, for example <code
style="white-space:pre" >"bool %s() { %n return %r; %n}"</code>. The specifier
<code>%s</code> refers to the identifier name, and <code>%r</code> to the right
hand side expression. There is no default.</p></li>

<li><p><code><b>tab</b></code>: the unit for indenting. The default is <code
style="white-space:pre">"  "</code> (two spaces).</p></li>

<li><p><code><b>and</b>, <b>or</b>, <b>true</b>, <b>false</b>:</code> the
formats for the boolean operators and constants. The defaults are <code
style="white-space:nowrap">"&amp;&amp;"</code>, <code
style="white-space:nowrap">"||"</code>, <code>"true"</code> and
<code>"false"</code>.</p></li>

<li><p><code><b>escape1</b>, <b>escape2</b>, <b>escape4</b>:</code> formats to
change the way string or character literals are printed in calls to
<code>text</code>, <code>set</code>, <code>split</code> or <code>range</code>
calls, by printing escape sequences instead of UTF-8. The <b>escape1</b> format
is for one-byte control characters, <b>escape2</b> is for two-byte Unicode
characters, and <b>escape4</b> is for four-byte Unicode characters. For example,
formats <code>"\%3o"</code>, <code>"\u%4x"</code>, <code>"\U%8x"</code> are
suitable for the C language. (Note that <code>\x%2x</code> in C is problematic
if a digit follows.) With these formats, a Pecan string
<code>"ab&#x03c0;"</code> is translated as <code>string("ab\u03c0")</code>. The
defaults are <code>""</code>, which means that all characters are written
verbatim into the program.</p></li>

<li><p><code><b>call</b>:</code> the format for making a call to any parsing
function. For example, <code>%s(p)</code> could be used if an argument
<code>p</code> is to be passed to every call. The default is
<code>%s()</code>.</p></li>

<li><p><code><b>id</b>:</code> the format for generating a call to represent the
occurrence of an identifier. This can be used to adjust identifier names
independently of other names. For example, an id format <code>"P%s(p)"</code>
would cause an occurrence of an identifier <code>term</code> to be compiled as
<code>Pterm(p)</code>. The default is to use the call format.</p></li>

<li><p><code><b>act</b>, <b>act0</b>, ...:</code> the format for printing
actions, and formats to override it for specific arities. The default for the
act format is <code>act%d(%s)</code>, adjusted according to the call format. The
specifier <code>%d</code> refers to the arity and <code>%s</code> refers to the
name of the action. The defaults for <code>act0</code>, <code>act1</code> ...
are to use <code>act</code>.</p></li>

<li><p><code><b>go</b>, <b>ok</b>, <b>alt</b>, <b>opt</b>, <b>see</b>,
<b>has</b>, <b>not</b>, <b>tag</b>, <b>eot</b>, <b>string</b>, <b>set</b>,
<b>split</b>, <b>range</b>, <b>cat</b>, <b>mark</b>, <b>drop</b>:</code> These
are supporting functions for the various Pecan features. Each can be changed
individually, if desired. The default in each case is to adapt the call format
appropriately. For example if the call format is <code>%s(p)</code>, then the
defaults for <code>go</code>, <code>opt</code>, <code>tag</code>,
<code>set</code> and <code>range</code> are <code>go(p)</code>,
<code>opt(p,%l)</code>, <code>tag(p,%s)</code>, <code>set(p,"%s")</code> and
<code>range(p,'%c','%c')</code>. These can be used to change individual function
names or their calls, or to adjust tag names or marker names independently of
other names, e.g. if <code>tag</code> is set to <code>tag(T%s)</code> then a
Pecan tag <code>%id</code> is compiled to <code>tag(Tid)</code>.</p></li>

</ul>

<p>These format strings allow compilation to be adapted to different languages
or applications. The default act format <code>"act%d(%s)"</code> treats action
names as enumerated constants. Instead, the act format could be specified
as:</p>

<pre>// &lt;pecan
//   ...
//   act = "%s()"
//   ...
// >
</pre>

<p>Then each action has its own function with implicit arity. Action functions
of this kind would need access to the parsing state and would be responsible for
stack handling, and for marking matched characters as used. An alternative is to
define:</p>

<pre>// &lt;pecan
//   ...
//   act = "push(%s(text(),pop(%d)))"
//   ...
// >
</pre>

<p>The <code>text()</code> call forms a string from the recently matched
characters and marks them as used, the <code>pop(n)</code> call pops
<code>n</code> output items from the stack and returns them as an array, and the
<code>push</code> call pushes the output item returned from the action function
onto the stack (returning <code>true</code>). This means that the action
functions no longer need access to the parsing state. To go further, the formats
for actions of each arity could be specified as:</p>

<pre>// &lt;pecan
//   ...
//   act0 = "push(0,%s(text()))"
//   act1 = "push(1,%s(top(0)))"
//   act2 = "push(2,%s(top(1),top(0)))"
//   ...
// >
</pre>

<p>Now each action function is passed only what it needs. The
<code>text()</code> call forms a string from the recently matched characters,
<code>top(n)</code> returns the n'th item from the top of the output stack, and
<code>push(n,x)</code> pushes <code>x</code> onto the output stack to replace
the top n items and marks any recently matched characters as used.</p>

<h2 id="bytecode">Bytecode</h2>

<p>Instead of compiling a grammar to recursive functions, a grammar can instead
be translated into an interpretive bytecode. This is suitable for dynamic
situations. For example, suppose that a programmer's editor or IDE needs a
scanner or parser for each of a large number of different programming languages.
It may be desirable to load up the scanner or parser on demand for any specific
language, by reading in a bytecode file and running a generic bytecode
interpreter.</p>

<p>A grammar is compiled into bytecode using a command of the form:</p>

<pre>pecan grammar -b file
</pre>

<p>The option <code>-b file</code> specifies the name of a binary file into
which to write the bytecode. As well as creating the file, the command prints
out the integer values used for opcodes, actions, markers, tags and/or Unicode
categories used in the bytecode. For example:</p>

<pre>pecan grammar.txt -b out.bin
Opcodes: {ACT=0, AND=1, ARITY=2, BACK=3, BOTH=4, CAT=5, DO=6, DROP=7, EITHER=8,
EOT=9, GO=10, HAS=11, HIGH=12, LOOK=13, LOW=14, MANY=15, MARK=16, MAYBE=17,
NOT=18, ONE=19, OR=20, POINT=21, SEE=22, SET=23, SPLIT=24, START=25, STOP=26,
STRING=27, TAG=28}
Actions: {add=0, divide=1, multiply=2, read=3, subtract=4}
Markers: {bracket=0, integer=1, newline=2, operator=3}
Categories: {Cc=0, Cf=1, Cn=2, Co=3, Cs=4, Ll=5, Lm=6, Lo=7, Lt=8, Lu=9, Mc=10,
Me=11, Mn=12, Nd=13, Nl=14, No=15, Pc=16, Pd=17, Pe=18, Pf=19, Pi=20, Po=21,
Ps=22, Sc=23, Sk=24, Sm=25, So=26, Zl=27, Zp=28, Zs=29}
Bytecode file sum.bin written.
</pre>

<p>The names of each type are put into alphabetical order and sequence numbers
are assigned. The information printed out can be used to set up or confirm the
values of enumerated constants in the interpreter. An example interpreter in the
C language is:</p>

<p class="indent"><a href="translation/interpret.c">interpret.c</a></p>

<p>An interpreter can be constructed by taking the example interpreter provided,
translating it into the desired programming language, and adapting it to a
particular application by customising constants and functions as
appropriate.</p>

<p>The bytecode produced from a grammar is a fairly simple flattening of the
parse tree for the grammar. A rule is translated into a bytecode sequence of the
form:</p>

<pre>{id = x}    =   START +nx {x} STOP
</pre>

<p>In these descriptions, the notation <code>{x}</code> means "the bytecode
sequence generated for expression x" and <code>nx</code> stands for the number
of bytes in <code>{x}</code>. The instruction <code>START +nx</code> is a
sequence of one or more bytes with opcode <code>START</code> and operand
<code>nx</code>. For small values of <code>nx</code>, the operand may be
included in the opcode byte. For larger values, one or more extension bytes may
be needed. The <code>STOP</code> opcode needs no operand.</p>

<p>The <code>START</code> opcode creates a call to <code>{x}</code>, setting up
the address of <code>STOP</code> as the return address. The <code>STOP</code>
instruction ends parsing. The operand <code>nx</code> to <code>START</code> can
be thought of as a relative offset in the code to the <code>STOP</code>
instruction.</p>

<p><code>START</code> and <code>STOP</code> opcodes are generated for every
rule, even though they are only executed once for the overall call to the
parser. This is so that any rule can be used as an entry point, if desired. The
bytecode can be scanned, skipping the body <code>{x}</code> of each rule using
the number <code>nx</code>, to find the start of the next rule.</p>

<pre>{id}        =   GO +px
{id}        =   BACK -px
</pre>

<p>When the name <code>id</code> of a rule such as <code>id = x</code> is used
elsewhere in the grammar, it is translated using <code>GO</code> or
<code>BACK</code>. The operand of <code>GO</code> is a relative offset to the
address <code>px</code> in the code of the body <code>{x}</code> of the relevant
rule. The <code>BACK</code> opcode is used, with a positive argument, when the
offset is negative.</p>

<pre>{"a"}       =   STRING 1 97
{97}        =   STRING 1 97
{128}       =   STRING 2 194 128
{"ab"}      =   STRING 2 97 98
{""}        =   STRING 0
{"&#960;"}       =   STRING 2 207 128
{"a&#960;"}      =   STRING 3 97 207 128
{'&#960;'}       =   STRING 2 207 128
{&lt;a>}       =   SPLIT 1 97
{&lt;ab>}      =   SPLIT 2 97 98
{'a..z'}    =   LOW 1 97 HIGH 1 122
{'&#945;..&#969;'}    =   LOW 2 206 177 HIGH 2 207 137
{''}        =   SET 0
{'a'}       =   SET 1 97
{'ab'}      =   SET 2 97 98
{'&#945;&#946;'}      =   SET 4 206 177 206 178</pre>

<p>A character matching opcode has a count as an operand, and is followed by
that number of bytes in UTF-8 format. For opcodes other than <code>SET</code>, a
byte sequence containing characters of mixed UTF-8 lengths causes no problem,
because UTF-8 text can be compared byte by byte, without taking account of
character boundaries. With the <code>SET</code> opcode, a sequence with mixed
UTF-8 byte lengths cannot be handled byte by byte, but the first byte of each
character can be used to find the character's length.</p>

<pre>{@a}        =   ACT a
{@2a}       =   ARITY 2 ACT a
{@}         =   DROP 0
{@2}        =   DROP 2
</pre>

<p>An action is translated using the <code>ACT</code> opcode. Actions and error
markers are switched off during has <code>x&amp;</code> or not <code>x!</code>
expressions. An integer in the interpreter keeps track of the depth of nesting
of lookahead constructs, and actions are only performed if the integer is zero.
For see <code>[x]</code> expressions, <code>x</code> is executed once with
actions and markers switched off, then again with them switched back on, in line
with the identity <code>[x] &#8801; x&amp; x</code>.</p>

<pre>{#e}        =   MARK e
{%id}       =   TAG id
</pre>

<p>Error markers, signalled by the <code>MARK</code> opcode, are collected as a
set, and cleared whenever a new marker is found further on in the input. Tags
are used only in token-based parsers. They cause a call to external code to find
the tag of a particular token.</p>

<pre>{Nd}        =   CAT Nd
</pre>

<p>A category is translated using the <code>CAT</code> opcode. The target
programming language may not have a facility for finding the category of a
character. Even if it does, the category information may vary according to the
version of the language. For stable category information, Pecan provides a
two-stage lookup table in the two files <code>table1.bin</code> and
<code>table2.bin</code> which may be read into memory by the target
language.</p>

<pre>{x/y}       =   EITHER +nx {x} OR {y}
{x y}       =   BOTH +nx {x} AND {y}
</pre>

<p>The <code>EITHER</code> opcode initializes a choice, and <code>OR</code>
checks what happens after <code>{x}</code> to decide whether or not to continue
with <code>{y}</code>. Similarly, the <code>BOTH</code> and <code>AND</code>
opcodes handle a sequence. The <code>EITHER</code> or <code>BOTH</code> opcode
can be thought of as causing a call to <code>{x}</code> returning to
<code>OR</code> or <code>AND</code>, which may cause a tail-call to
<code>{y}</code>.</p>

<pre>{x?}        =   MAYBE ONE {x}
{x*}        =   MAYBE MANY {x}
{x+}        =   DO AND MAYBE MANY {x}
{[x]}       =   LOOK SEE {x}
{x&amp;}        =   LOOK HAS {x}
{x!}        =   LOOK NOT {x}
</pre>

<p>The <code>MAYBE</code> opcode initializes a repetition, then causes a call to
<code>{x}</code>, returning to <code>ONE</code> or <code>MANY</code>. The
<code>ONE</code> opcode converts the result of <code>{x}</code> into the result
of <code>x?</code>. The <code>MANY</code> opcode is similarly executed after
<code>{x}</code> and checks the result of <code>{x}</code> to decide whether or
not to call it again. The opcode sequence used here, with the termination check
before the code for <code>{x}</code>, avoids the need for an <code>nx</code>
operand. The code for <code>x+</code> is equivalent to the code for <code>x
x*</code>, except that the <code>DO</code> opcode avoids the need for a second
copy of <code>{x}</code> by jumping forwards to <code>{x}</code>, and arranging
for the call to return to <code>AND</code>. The <code>LOOK</code> opcode
initializes any of the lookahead constructs, arranging to return to
<code>SEE</code> or <code>HAS</code> or <code>NOT</code> which sorts out the
result.</p>

<p>To give a concrete example, suppose a grammar consists of the rule:</p>

<pre>digit = '0..9' @read
</pre>

<p>The bytecode sequence generated from this has the form:</p>

<pre>START +5 LOW 1 '0' HIGH 1 '9' ACT 0 STOP
</pre>

<p>The sequence might also be represented in a form resembling an assembly
language:</p>

<pre>0: START 7
2: LOW 1 '0'
4: HIGH 1 '9'
6: ACT 0
7: STOP
</pre>

<p>In this form, each line represents one instruction, preceded by its address
in the bytecode. The offset operand <code>+5</code> to the <code>START</code>
instruction is displayed as an actual bytecode address <code>7</code>. The
opcodes <code>LOW</code>, <code>HIGH</code>, <code>ACT</code> have operands
small enough to be included in the opcode byte.</p>

<p>Further details of how instructions are encoded and what each opcode does can
be gleaned from an interpreter program and its comments.</p>

<h2 id="transforms">Transforms</h2>

<p>The Pecan grammar language is intended to be sufficiently simple and precise
to support equational transforms. At present, such transforms are carried out
manually and informally on grammars, but it is possible to imagine a theory of
transforms being developed more formally and used to develop and justify
automatic optimisations, or to build an assistant which would suggest and check
user-driven transforms while developing grammars. Equations such as these can be
used:</p>

<pre>(x y) z == x (y z)
(x / y) / z == x / (y / z)
x+ == x x*
x* = (x+)?
x? = x / ""
[[x] y] z == [x y] z
[x y] z / [x u] v == [x] ([y] z / [u] v)
(x / y) z = x z / y z
</pre>

<p>Care has to be taken, because not all 'obvious' equations hold. For example,
<code>x (y / z)</code> is not equivalent to <code>x y / x z</code> because if
<code>x</code> succeeds, in the first case the parser is free to make the choice
between <code>y</code> and <code>z</code>, but in the second case it is already
committed to <code>y</code>. Also <code>x / y</code> and <code>y / x</code> are
not equivalent. However, they are equivalent if it can be established that
<code>x</code> and <code>y</code> begin differently. In these equations, actions
and error markers are included, and the transformed expression has precisely the
same output effect and error handling properties as the original.</p>

<h2 id="changes">Recent changes</h2>

<p>The previous version of Pecan was 0.4. Changes in version 1.0 are:</p>

<ul>
<li>error markers are no longer postfix</li>
<li>the splitter notation <code>&lt;abc></code> and end notation
    <code>&lt;></code> have been added</li>
<li>backquoted tags have been generalized to literal names</li>
<li>separate grammar and test files are supported</li>
<li>one test file can be called from within another</li>
<li>compilation to recursive functions is supported</li>
</ul>

</body>
</html>
