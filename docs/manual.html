<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-gb" xml:lang="en-gb">
<head>
<title>Pecan Manual</title>
<style>
  body { font-size: 120%; }
  pre { margin-left:40px; }
</style>
</head>
<body>

<img src="pecan.png" width="300" height="65" />
<hr/>

<h1>Pecan Reference Manual</h1>

<ul>
<li><a href="#intro">Introduction</a></li>
<li><a href="#install">Installation</a></li>
<li><a href="#notation">Notation</a>
<ul>
<li><a href="#rules">Rules</a></li>
<li><a href="#comments">Comments</a></li>
<li><a href="#parentheses">Parentheses</a></li>
<li><a href="#continuations">Continuations</a></li>
<li><a href="#choices">Choices</a></li>
<li><a href="#sequences">Sequences</a></li>
<li><a href="#repetition">Repetition</a></li>
<li><a href="#lookahead">Lookahead</a></li>
<li><a href="#text">Text</a></li>
<li><a href="#tokens">Tokens</a></li>
<li><a href="#actions">Actions</a></li>
<li><a href="#errors">Errors</a></li>
</ul>
</li>
<li><a href="#testing">Testing</a></li>
<li><a href="#checks">Consistency checks</a>
<ul>
<li><a href="#type">Type checking</a></li>
<li><a href="#loop">Loop checking</a></li>
<li><a href="#token">Token checking</a></li>
<li><a href="#output">Output checking</a></li>
</ul>
<li><a href="#java">Generating code</a>
<ul>
<li><a href="#code">Bytecode</a></li>
</ul>
</li>
</li>
<li><a href="#transforms">Transforms</a></li>
<li><a href="#changes">Recent changes</a></li>
<li><a href="#pecan">The Pecan grammar</a></li>
</ul>

<h2 id="intro">Introduction</h2>

<p>Pecan is a tool for developing and checking grammars, and generating scanners
and parsers. It is aimed at parsers for programming languages, <a
href="https://en.wikipedia.org/wiki/Domain-specific_language">domain specific
languages</a>, and other unambiguous computer languages. It provides a precise
grammar notation, which is independent of implementation language, based on
recursive descent with lookahead. This manual describes Pecan version 1.0 which
has these features:</p>

<ul>

<li>a grammar is an executable prototype parser</li>

<li>output actions and error markers are included</li>

<li>transformations preserve actions and errors</li>

<li>many consistency checks are applied</li>

<li>there is explicit support for development and testing</li>

<li>scanner and parser generation is via bytecode</li>

<li>an interpreter for the bytecode can be written in any language</li>

</ul>

<p>Other approaches to developing parsers are usually based on the <a
href="http://en.wikipedia.org/wiki/Context-free_grammar">context free
grammar</a> (CFG) formalism, the <a
href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing
expression grammar</a> (PEG) notation, using <a
href="http://en.wikipedia.org/wiki/Parser_combinator">parser combinators</a> or
writing <a
href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive
descent</a> parsers manually.</p>

<h3>CFG grammars</h3>

<p>The CFG notation (in the form of BNF and many variations) has been the main
formalism for grammars for a long time, and it has been well studied. However,
it has been argued quite strongly that it is not an ideal formalism
to use for unambiguous languages. According to <a
href="http://dl.acm.org/citation.cfm?id=964001.964011">Bryan Ford</a>:</p>

<blockquote>The power of generative grammars to express ambiguity is crucial to
their original purpose of modelling natural languages, but this very power makes
it unnecessarily difficult both to express and to parse machine-oriented
languages using CFGs.</blockquote>

<p>One fundamental theoretical problem is that CFG grammars can contain
ambiguities, and there is no computable algorithm to detect whether or not a
grammar is unambiguous. There is also the associated practical problem that many
published CFG grammars contain ambiguities. Some of these are local, i.e. a
particular rule allows two possible parses, but there is a surrounding, more
global, rule that resolves the ambiguity by only accepting one of the
possibilities. But many ambiguities in published grammars are inherent, the
ambiguity being resolved only by accompanying descriptive text or particular
approaches to generating parsers.</p>

<p>As well as ambiguity, there is also the problem that a CFG grammar describes
a language in a generative way, which is not directly and intuitively linked to
the recognition problem faced in parsing. Indeed the meaning of a grammar is
often different from the parser generated from it. There is an awkward semantic
gap.</p>

<p>Conventional CFG-based parser generators have a variety of other flaws,
partly due to the difficulties of the CFG formalism, and partly due to the age
of their designs. They often have arbitrary heuristic rules for disambiguation.
They often support a subset of CFG grammars which is not at all intuitive. They
often use bottom-up parsing techniques to make parsers near-linear, which makes
the way they operate impenetrable. And they often support actions and error
reporting using embedded code fragments which are not part of the grammar. This
is a very fragile and language-dependent approach.</p>

<p>These problems with the CFG formalism might be worth putting up with, if the
formalism had excellent theoretical or practical properties. But it doesn't.
For example, CFG grammars have poor composability properties, and poor closure
properties. And, in general, parsing CFG grammars takes O(n<sup>3</sup>) time in
the worst case.</p>

<h3>PEG grammars</h3>

<p>The main difference with PEG grammars is that the symmetrical choice operator
<code>|</code> is replaced by an ordered choice operator <code>/</code> which
has a more operational meaning. The expressive power of PEG grammars is
extremely close to that of CFG grammars. Examples such as palindromes which are
a problem for PEG grammars are typically also a problem for the efficient LR or
LALR subsets of CFG grammars.</p>

<p>The theoretical and practical properties of the PEG formalism are superior to
the CFG formalism in almost every measurable way. PEG grammars never contain any
ambiguity, they have a direct operational meaning as parsers, they are
composable, they are closed under a variety of operations, and they can be
parsed in linear time using the packrat algorithm. This makes the PEG grammar
formalism a much better starting point for studying grammars and parsers.</p>

<p>Unfortunately, there are practical problems with PEG parsers. Although the
packrat algorithm is linear, it is slower and more space hungry than one would
like for efficient large scale parsing. Also, because of its relatively
uncontrolled backtracking, it is difficult to produce accurate error messages,
and difficult to express actions. Published PEG grammars can also often be
rather unreadable, in the same way that regular expressions tend to be. As a
result, PEG grammars are typically only used for search expressions, or for
small domain specific languages, and not for larger applications such as full
programming languages.</p>

<p>There is also a relatively minor problem with PEG grammars, which is that
they don't support left recursion. There have been attempts to add it, but the
results are not compelling. It is worth noting, though, that left recursion is
arguably unintuitive, that it would probably never have become common if it
weren't for the prevalence of CFG grammars, and that it is well known how to
transform it away. Most uses of left recursion are very simple, of the kind
<code>a = x | a y</code> which can be translated easily into <code>a = x
y*</code>.</p>

<h3>Recursive descent parsing and combinators</h3>

<p>Recursive descent parsers have the advantage of being efficient, intuitive,
and capable of being hand-written. They can also be embedded in programming
languages, e.g. in the form of parser combinators.</p>

<p>Perhaps the main problem with recursive descent is that a simple approach is
hardly ever enough. In order to deal with the difficult cases which arise in
practice, there have to be some extra features such as lookahead. These extra
features are often added in an ad hoc fashion on practical grounds. That often
leads to a situation where it is difficult to tell exactly what range of
grammars or languages are supported by any given recursive descent system.</p>

<p>Embedding a parsing system into a language, e.g. in the form of combinators,
can be very convenient, especially for small domain specific languages where the
grammar is known in advance. A system like that has a natural feel for
programmers, often with good control over backtracking.</p>

<p>If, however, an approach is needed which is not tied to a particular
programming language, or if a grammar needs an extended development effort, or
if it needs to be translated from the CFG formalism, or checked for consistency,
or optimized to produce a fast parser, then there is a case for a separate
formalism such as Pecan.</p>

<h3>Pecan grammars</h3>

<p>Pecan uses a language which is based on the PEG notation. However, the
semantics is that of simple recursive descent, with explicitly controlled
lookahead and backtracking.</p>

<p>The language is independent of any host programming language. Nevertheless,
grammars can express actions and error reporting, and can be executed
symbolically for development and testing. Once developed, a grammar can be
converted into a parser in any desired language, either by hand or
automatically.</p>

<p>The Pecan system explicitly provides support for the process of developing
grammars, in the form of consistency checks on grammars, features for automated
testing, and a context in which manual transformations can be carried out.
Having a separate notation for grammars helps to focus attention on the various
issues that have to be addressed, separately from the programming details.
However, that also makes grammars rather dense. If a grammar is not given in
advance, creating it or translating it accurately can be difficult. In addition,
programmers typically use parser generators only rarely, and are often not
grammar experts. As a result, support for test-driven grammar development is an
important feature of Pecan.</p>

<h2 id="install">Installation</h2>

<p>Pecan is a tool for developing grammars and generating parsers in a variety
of programming languages. The Pecan system is written in Java, so the first
step is to make sure a reasonably up-to-date version of Java is properly
installed. This can be tested by typing:</p>

<pre>javac -version
java -version
</pre>

<p>Pecan is provided as an executable jar file <code>pecan.jar</code>. The jar
file contains both the compiled program and also the source code. If
this jar file is downloaded, it can be run with:</p>

<pre>java -jar pecan.jar ...
</pre>

<p>However, it is more convenient to create a batch file or shell script, or use
an alias or equivalent, so that it can be run just by typing:</p>

<pre>pecan ...
</pre>

<p>The way to do this differs from system to system.</p>

<h2 id="notation">Notation</h2>

<p>The Pecan language is a grammar language for writing parsers, based
on the <a href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">PEG</a>
notation. Pecan uses the sequential choice operator <code>x/y</code> but, unlike
the PEG notation, the operator does not automatically involve backtracking.
There are separate lookahead operators, for the controlled use of backtracking,
which provide greater control over the progress of parsing. It is much easier
to generate accurate error messages, and parsers can be kept reasonably
efficient by the programmer, without the space overhead of such techniques as
the PEG packrat algorithm.</p>

<p>As with PEG grammars, any parsing expression within a grammar represents a
matching operation which succeeds or fails when applied at a particular position
in the input, and which may cause progress, i.e. may cause the current position
to move forwards in the input, according to how much of it is matched. Unlike
PEG grammars, there is only a single possible outcome for this operation.</p>

<h3 id="rules">Rules</h3>

<p>A parser consists of a sequence of rules, each of which gives a name to a
parsing expression. By default, the first rule specifies the output of the
whole parsing process. For example, a parser might start with:</p>

<pre>module = function+ end

function = id arguments body

end = Uc!
...
</pre>

<p>Apart from being the starting point of the parser, the first rule is not
treated in any special way. In particular, it may succeed without consuming all
the input. So an explicit test is often included, as here, to check that the
end of the input has been reached. In the <code>end</code> rule,
<code>Uc!</code> means no Unicode character can be matched.</p>

<p>The text of a grammar is assumed to be encoded using UTF-8, so Unicode
characters can be included. A rule name starts with any Unicode letter and
continues with Unicode letters or decimal digits or underscores or hyphens.</p>

<p>If a parser fails, only the first failure is reported. There is no attempt to
recover. If error recovery is required, this can be accomplished by writing a
separate rule to be tried on the remaining input.</p>

<h3 id="comments">Comments</h3>

<p>Comments start with <code>//</code> and extend to the end of the line. For
example:</p>

<pre>// A number is a sequence of one or more digits.
number = '0123456789'+
</pre>

<p>There is no multi-line comment convention.</p>

<h3 id="parentheses">Parentheses</h3>

<p>Parentheses, i.e. round brackets, have their usual meaning, indicating
grouping of operations. For example:</p>

<pre>(x / y) z
</pre>

<p>means parse <code>x</code> or <code>y</code>, then parse <code>z</code>, as
opposed to:</p>

<pre>x / y z
</pre>

<p>which means either parse <code>x</code>, or else parse <code>y</code> and
<code>z</code>.</p>

<h3 id="continuations">Continuations</h3>

<p>No explicit symbol is used to terminate a rule. A rule is terminated at the
end of a line, unless it is continued. A rule is continued on the next line if
the last token on the current line is an infix symbol or open bracket, i.e. one
of <code>=/([</code>. Here is an example rule where each line except the last
ends with <code>=</code> or the <code>/</code> operator:</p>

<pre>atom =
  id /
  number /
  bracket
</pre>

<p>Also, a rule is continued on the next line if the first token of the next
line is an infix symbol or close bracket, i.e. one of <code>=/)]</code>. This
allows an alternative style for a multi-line rule:</p>

<pre>atom
= id
/ number
/ bracket
</pre>

<p>In this example, each line that starts with <code>=</code> or <code>/</code>
is a continuation of the previous line.</p>

<h3 id="choices">Choices</h3>

<p>The choice operator <code>/</code> separates alternatives, which are tried
one after the other. For example:</p>

<pre>atom = id / number / bracket
</pre>

<p>If parsing of an alternative succeeds, then the parsing of the whole
expression succeeds. Otherwise, if no progress was made, the next alternative is
tried.</p>

<p>The choice operator does not directly involve backtracking. If any progress
is made while trying an alternative, then the parser is committed to that
alternative, and further alternatives are not tried. Progress is made on an
alternative if at least one input character or token is matched.</p>

<p>There are separate lookahead operators which allow speculative parsing of an
alternative.</p>

<h3 id="sequences">Sequences</h3>

<p>When items follow each other with no visible operator in between, this
indicates "followed by". For example:</p>

<pre>assignment = identifier "=" expression
</pre>

<p>This means that an assignment is an identifier followed by an equals sign
followed by an expression. The items are parsed one by one and, if parsing of
any item fails, parsing of the sequence is abandoned. Sequencing binds tighter
than the choice operator.</p>

<h3 id="repetition">Repetition</h3>

<p>The three postfix repetition operators are <code>*</code> to indicate that
an item is to be repeated any number of times, i.e. zero or more
times, <code>+</code> to indicate that an item is to be repeated one or more
times, and <code>?</code>  to indicate that an item is optional (i.e. repeated
zero times or once). For example:</p>

<pre>string = '"' stringchar* '"'
number = digit+
call = function "(" arguments? ")"
</pre>

<p>The <code>string</code> rule specifies that a string consists of a double
quote followed by any number of allowable characters followed by a closing
double quote. The <code>number</code> rule specifies that a number consists of
one or more digits. The <code>call</code> rule specifies that a call consists of
a function name followed by brackets, and the brackets may optionally contain
arguments.</p>

<p>The three expressions <code>x*</code>, <code>x+</code>, <code>x?</code> act
in exactly the same way as the three rules <code>xs</code>, <code>xp</code>,
<code>xq</code> defined by:</p>

<pre>xs = x xs / ""
xp = x xs
xq = x / ""
</pre>

<p>This means that <code>x*</code> or <code>x+</code> will accept as
many <code>x</code>'s as are present in the input. In all three cases, in line
with the fact that the choice operator does no backtracking by default, if
progress is made on a final <code>x</code> without success, the whole
expression fails. Postfix operators bind tighter than sequencing.</p>

<h3 id="lookahead">Lookahead</h3>

<p>There are three lookahead operators, the try operator <code>[...]</code>, the
has operator <code>&amp;</code> and the not operator <code>!</code>.</p>

<p>The try operator is specified using square brackets. In an expression
<code>[x]</code>, the subexpression <code>x</code> is parsed speculatively. If
it succeeds, parsing continues as normal. If it fails, the parser backtracks to
the point just before <code>x</code>. The try operator is usually used to
indicate the point at which the parser should commit to an alternative. For
example:</p>

<pre>statement = [identifier "="] expression / ...
</pre>

<p>This specifies that the parser should commit to the first alternative only
after matching the equal sign. If an error occurs before that, e.g. an
identifier has been matched but there is no equal sign, backtracking is done by
resetting the parser to the point before the identifier, and the next
alternative is tried.</p>

<p>The has <code>&amp;</code> and not <code>!</code> operators represent
positive and negative lookahead. In the PEG notation, <code>&amp;</code> and
<code>!</code> are prefix operators, but in Pecan, they are postfix, to make the
syntax of rules simpler and more uniform and, in particular, to avoid precedence
issues which would arise if there were both prefix and postfix operators.</p>

<p>With <code>x&amp;</code> or <code>x!</code>, the expression <code>x</code> is
parsed speculatively to check whether it appears next in the input or not.
Whether the expression <code>x</code> succeeds or fails, the parser backtracks
to the beginning. Then <code>x&amp;</code> succeeds if the parsing of
<code>x</code> succeeded, whereas <code>x!</code> succeeds if the parsing of
<code>x</code> failed. For example:</p>

<pre>statement = (type identifier)&amp; declaration / assignment
</pre>

<p>The parser looks ahead to see if there is a type and identifier next in the
input. If there is, the parser backtracks to the point before the type, but
continues with the same alternative and parses a declaration. If the lookahead
fails, an assignment is parsed. A negative example is:</p>

<pre>string = '"' ('"'! visible)* '"'
</pre>

<p>This says that a string contains any visible character other than a double
quote. The bracketed expression only tries to match a visible character if a
double quote does not appear next in the input.</p>

<p>The postfix <code>x&amp;</code> and <code>x!</code> operators bind more
tightly than sequencing.</p>

<p>During a try operation <code>[x]</code>, actions are delayed by storing them
symbolically. If <code>x</code> succeeds, the delayed actions are performed. If
<code>x</code> fails, the delayed actions are discarded. During
has and not operations <code>x&amp;</code> or <code>x!</code>, actions
are always discarded.</p>

<p>The fact that actions are not performed during speculative parsing restricts
the possible context sensitive aspects of a language, which can only depend on
actions outside of lookahead constructs. Lookahead is regarded only as a way of
deciding which alternative to take.</p>

<h3 id="text">Text</h3>

<p>Text notations are used to match input characters. Single quotes indicate
individual characters, e.g. <code>'x'</code> matches the letter <code>x</code>.
Several characters in single quotes indicate a set of alternatives, any one of
which can be matched. For example:</p>

<pre>op = '+-*/'
digit = '0123456789'
</pre>

<p>The expression <code>'+-*/'</code> matches any one of the four arithmetic
operator characters, and is equivalent to <code>'+' / '-' / '*' / '/'</code>.
The expression <code>'0123456789'</code> matches any digit.</p>

<p>Double quotes indicate a string of characters, which are matched in sequence.
For example:</p>

<pre>keyword = "int" / "if" / "while" / ...
pi = "&#960;"
</pre>

<p>The string <code>"int"</code> only matches if all three characters appear in
the input in sequence, i.e. it is equivalent to <code>['i' 'n' 't']</code>. The
square brackets indicate that if a string matches only partially, the input
position returns to the beginning of the string, and other alternatives can be
tried. Any Unicode characters can be used in a string, using the UTF-8 encoding
in the grammar file.</p>

<p>Single characters can be represented using either single or double
quotes. For example:</p>

<pre>double_quote = '"'
single_quote = "'"
</pre>

<p>Although Unicode characters may be used, each code point is treated as a
separate character. Where graphemes might be involved, care needs to be taken.
For example, <code>'é'</code> is visually ambiguous because it could contain one
or two code points, depending on whether a combiner is used. Writing it instead
as <code>"é"</code> reduces the potential ambiguity. Similarly,
<code>'éè'</code> is better written as:</p>

<pre>"é" / "è"
</pre>

<p>There is no escape convention within single or double quotes. To represent
control characters, or to represent Unicode characters using plain text,
integers are used. An integer on its own represents a single character, using
its decimal character code. For example:</p>

<pre>pi = 960
newline = 13? 10
</pre>

<p>If an integer is used which starts with a zero digit, then the character
code is in hexadecimal, using <code>a</code> to <code>f</code> or
<code>A</code> to <code>F</code>, e.g.</p>

<pre>pi = 03C0
newline = 0d? 0a
</pre>

<p>Common sets of characters can be specified using Unicode general categories.
The names <code>Uc, Cc, Cf, Cn, Co, Cs, Ll, Lm, Lo, Lt, Lu, Mc, Me, Mn, Nd, Nl,
No, Pc, Pd, Pe, Pf, Pi, Po, Ps, Sc, Sk, Sm, So, Zl, Zp, Zs</code> are provided.
The name <code>Uc</code> represents all Unicode characters (code points
<code>0..1114111</code>), and the others are the standard two-letter
abbreviations for the Unicode general categories which partition all the code
points. For example:</p>

<pre>letter = Lu / Ll / Lt / Lm / Lo
digit = Nd
connector = '_'! Pc
visible = (Cc/Cn/Co/Cs/Zl/Zp)! Uc
</pre>

<p>The Unicode categories starting with <code>L</code> are letters. The letter
rule allows any kind of letters: upper case, lower case, title case, modifier
and other. Categories starting with <code>N</code> are number characters, of
which <code>Nd</code> is the set of decimal digits. The connector rule uses the
<code>Pc</code> connector punctuation category, but excludes the underscore
character. The rule for <code>visible</code> excludes character code points
which are unassigned, private, surrogate, controls, or line or paragraph
separators.</p>

<p>A set of characters can be specified using a range. For
example:</p>

<pre>digit = '0'..'9'
letter = 'a'..'z' / 'A'..'Z'
visible = ' '..'~'
ascii = 0..127
</pre>

<p>Each argument to the range operator must be a single character (code point),
specified using an integer or single quotes or double quotes.</p>

<p>A divider is a string in angle brackets instead of double quotes
<code>&lt;...></code> which represents a two-way check. An expression such as
<code>&lt;abc></code> does not match any input characters, but is a lookahead
construct which succeeds if the remaining input, regarded as a string, is
lexicographically less than <code>"abc"</code>. For example:</p>

<pre>keyword = &lt;do> keyword1 / keyword2
keyword1 = "break" / "case" / "catch" / "continue" / "default"
keyword2 = "do" / "else" / "for" / "if" / "switch" / "while"
</pre>

<p>Here, some keywords are listed in alphabetical order, and a divider is used
to speed up their recognition by separating the keywords before
<code>"do"</code> from the keywords from <code>"do"</code> onwards. The less and
greater than signs used as angle brackets are also mnemonics for the two-way
decision which a divider represents.</p>

<p>The empty string <code>""</code> always succeeds, and the empty set
<code>''</code> always fails:</p>

<pre>succeed = ""
fail = ''
</pre>

<p>They can occasionally be useful, e.g. in transformations.</p>

<h3 id="tags">Tokens</h3>

<p>Support is needed for parsers where the input consists of tokens produced by
a separate scanner. The input is thought of as an array of tokens instead of an
array of characters.</p>

<p>A tag is represented as a symbol consisting of the <code>%</code> character
followed by a name. Each tag represents a specific kind of token. For example, a
token-based parser for a simple calculator with no brackets might look like
this:</p>

<pre>sum = term (%plus term @2add / %minus term @2subtract)* end
term = number (%times number @2multiply / %over number @2divide)*
number = %number @number
end = %
</pre>

<p>In this case, the input is an array of tokens with tags <code>%number</code>,
<code>%plus</code>, <code>%minus</code>, <code>%times</code> or
<code>%over</code>. The tag <code>%</code> with no name is matched only at the
end of the input. This is equivalent to using <code>Uc!</code> in a scanner.</p>

<p>For greater readability, tags can be represented as strings. The simple
calculator can be rewritten as:</p>

<pre>sum = term ("+" term @2add / "-" term @2subtract)* end
term = number ("*" number @2multiply / "/" number @2divide)*
number = %number @number
end = %
"+" = %plus
"-" = %minus
"*" = %times
"/" = %over
</pre>

<p>When a string is used, it must be given a definition which relates it to a
named tag. This allows all tags to be associated with an enumerated type in the
external code when a parser is generated.</p>

<h3 id="actions">Actions</h3>

<p>Actions allow a parser to operate on values or data structures, using a
stack, to produce an output. An action is a symbol which consists of
the <code>@</code> character followed by a number followed by a name. If there
is no number, it is assumed to be zero. For example:</p>

<pre>sum = term (plus term @2add)*
</pre>

<p>Suppose that the <code>term</code> rule pushes a single item onto the stack,
and the <code>plus</code> rule doesn't affect the stack. The <code>@2add</code>
symbol in the <code>sum</code> rule indicates that two items should be popped
off the stack, the <code>add</code> action should be performed, which creates a
new item, and the new item should be pushed onto the stack. A parser as a whole
ends with a single item on the stack, which is the output from the parsing
process.</p>

<p>The stack is provided and manipulated by external code when a parser is
generated from the grammar. An action symbol such as <code>@2add</code> is
translated into the execution of a fragment of external code. The parser could
be part of a calculator, in which case the <code>add</code> action might add two
numbers. Alternatively, the parser might become part of a compiler, in which
case the <code>add</code> action might combine two expression trees into a
larger tree. When executing a grammar symbolically for testing, the name of the
action is simply printed out.</p>

<p>An action has access to the characters or tokens from the input which have
been matched since the previous action. For example:</p>

<pre>number = digit+ @number
</pre>

<p>The action <code>@number</code> creates a new item from the digits which
have just been matched, and pushes it onto the stack. There is a further
convention which allows matched characters to be discarded. For example:</p>

<pre>spaces = ' '+ @
</pre>

<p>An <code>@</code> sign on its own causes any recently matched characters to
be discarded by the parser, without any external code being executed.</p>

<p>There are severe consistency restrictions on actions. For example, each
alternative in a choice must create or consume the same number of output items.
Within a repetition, i.e. <code>x*</code> or <code>x+</code> or <code>x?</code>,
the inner expression <code>x</code> must have no net effect on the number of
output items. A rule must produce a fixed number of output items. The first
rule normally produces a single item, but this is not enforced, so that any
self-contained fragment of a grammar is legal, for testing.</p>

<p>The compensation for these severe restrictions is that Pecan can carry out
strong consistency checks on grammars, ensuring that every expression has the
right effect on the output stack, that the stack never underflows, and that a
fixed number of output items is produced overall. There is also the advantage
that actions are an integral part of the grammar, and are preserved during
transformations.</p>

<p>Scanners are normally thought of as producing a sequence of tokens. But in
Pecan, even a scanner must produce a fixed number of output items. A scanner
can be defined like this:</p>

<pre>tokens = @tokens token+ end
token = id @1id / number @1number / ...
</pre>

<p>The <code>@tokens</code> action creates an output item representing the list
or array of tokens to be generated, initially empty. Each action such as
<code>@1id</code> takes the recently matched characters, creates a token from
them, and adds it to the list.</p>

<p>In a token-based parser, there are often variable-length sequences, which
need to be dealt with in a similar way. For example, a comma-separated list of
identifiers can be expressed by:</p>

<pre>ids = @list id @2add ("," id @2add)* @1end
</pre>

<p>The <code>id</code> rule is assumed to push a single item onto the output
stack. The <code>@list</code> action creates an empty list. The
<code>@2add</code> action pops the list and most recent id, adds the id to the
list, and pushes the resulting list back on the stack. The <code>@1end</code>
action does anything necessary to finalize the list.</p>

<p>The external code in a generated parser may choose a different implementation
with the same overall effect. For example, <code>@list</code> may mark a
position in the output stack, <code>@add</code> may do nothing so that ids
accumulate on the stack, and <code>@1end</code> may use the marked stack
position to create an array out of the accumulated ids. Alternatively,
<code>@list</code> could create a linked list, and each subsequent
<code>@2add</code> could chain the next id onto the end of the list.</p>

<p>Techniques like this for handling variable-length lists can easily lead to a
left hand alternative which begins with an action, for example:</p>

<pre>@a x / y
</pre>

<p>The action <code>@a</code> is only performed if <code>x</code> succeeds, or
if it progresses before failing. If <code>x</code> fails without progressing in
the input, the action <code>@a</code> is not performed, and the next choice
<code>y</code> is tried. In the external code, to avoid the need to undo
actions, it is normal to delay the action <code>@a</code> and perform it when
<code>x</code> progresses, or discard it if <code>x</code> fails without
progressing.</p>

<h3 id="errors">Errors</h3>

<p>By default, a parser produces an error message which points to the furthest
position reached in the input text, other than in lookaheads, but which gives no
details. For example, suppose this rule is being parsed:</p>

<pre>sum = number ("+" number / "-" number)
</pre>

<p>Then a message like this might be produced for an incorrect operator:</p>

<pre>Error on line 1:
40~2
  ^
</pre>

<p>Markers can be added to parser rules, to describe the items which would have
allowed parsing to continue. A marker is a symbol consisting of
the <code>#</code> character followed by a name. For
example, suppose the rule above is changed to:</p>

<pre>sum = number (#plus "+" number / #minus "-" number)
</pre>

<p>Then, for an incorrect operator, the expressions <code>"+"</code>
and <code>"-"</code> both fail, so the error message produced becomes:</p>

<pre>Error on line 1: expecting minus, plus
40~2
  ^
</pre>

<p>When a marker is encountered, it is associated with the current position in
the input. It records something that the parser is expecting at that point. If
progress is made past that input position, the markers are cleared. When the
parser encounters an error, the set of things that the parser was expecting at
that point can be reported. Duplicates are removed, for example suppose the rule
is changed to:</p>

<pre>sum = number (#operator "+" number / #operator "-" number)
</pre>

<p>Then the error message becomes:</p>

<pre>Error on line 1: expecting operator
40~2
  ^
</pre>

<p>One way to ensure that all the items which could possibly allow parsing to
continue are reported is to write separate rules to describe low level features
of a grammar involving primitive character matchers, i.e. strings, sets,
character codes, or Unicode identifiers, and begin each with a marker. For
example, a parser for a programming language might contain rules such as:</p>

<pre>plus = #operator "+" " "* @
letter = #letter (Lu / Ll / Lt / Lm / Lo)
number = #number ('0'..'9')+ @number " "* @
newline = #newline 13? 10 @
end = #end Uc!
</pre>

<p>The <code>plus</code> rule specifies that the plus sign is to be described as
an operator in error messages, that it may be followed by optional spaces, and
that the plus sign and spaces are discarded. The <code>letter</code> rule
applies an error marker to a choice of Unicode categories, to avoid having to
attach a marker to each one individually.</p>

<p>With these rules, an incorrect operator might lead to an error message which
says that an operator is expected. The fact that an extra digit on the preceding
number, or a space, could also have allowed parsing to continue is not reported.
That is because individual digits and spaces in the rules haven't been given
markers.</p>

<h2 id="testing">Testing</h2>

<p>During development of a grammar, testing can be carried out by symbolic
execution without having to generate a parser. This is done by typing a command
of the form:</p>

<pre>pecan [-trace] [line] testfile
</pre>

<p>The test file contains the tests to be carried out. The <code>-trace</code>
option switches on tracing, so that the individual steps taken during parsing
are displayed. If a line number is given, only the single test that starts on
that line of the test file is executed.</p>

<p>A test file contains a number of sections separated by lines consisting of
three or more equal signs. If a section contains a line of minus signs as a
separator, then it is a test with sample input and expected output. If a section
has no minus sign separator, it is a grammar which is used for subsequent tests,
until another grammar is given. For example:</p>

<pre>// Recognise one digit
number = ("0".."9") @number
==========
2
----------
number 2
==========
42
----------
number 4
==========
// Recognise any number of digits
number = ("0".."9") @number
==========
42
----------
number 42
</pre>

<p>The first section of this file sets up a grammar, then there are two tests
using that grammar, then a new grammar is given, then there is a final test
using the second grammar.</p>

<p>The output from running a test using a given grammar and sample input is a
list of the actions that would be performed by a parser generated from the
grammar. If the input is text rather than tokens, the characters matched since
the previous action or discard are displayed.</p>

<p>When a test fails, its line number is reported in the error message. That
line number can then be used to re-run the testing, but picking out only that
one test to be performed, perhaps with tracing:</p>

<pre>pecan tests.txt
Fail test on line 24 of tests.txt:
---------- Expected ----------
...
---------- Actual ----------
...

pecan -trace 24 tests.txt
</pre>

<p>A section of the test file can have some other special forms. Examples of
each possibility are:</p>

<pre>grammar.pecan
==========
tests.txt
==========
number
==========
// Comment
</pre>

<p>Each of these cases can be distinguished from a grammar, because there is no
rule which contains an equal sign. In the first example, a section consists of a
single line which is the name of a file containing a grammar to be used for
subsequent tests. This supports the common case where the grammar is in one file
and its tests are in another. The second example is the name of a secondary test
file to execute, allowing a suite of tests to be split across several files.
There is no conflict between these first two examples, because a grammar file is
equivalent to a test file which sets up a grammar but contains no tests. The
third example is the name of a rule in the current grammar, to be used as an
entry point for subsequent tests. It can be recognized by the lack of a dot
character. This allows a grammar to be developed rule by rule, with old tests on
particular rules being kept as regression tests. In the final example, a section
consists entirely of comment lines. The section has no effect, but can be used
to explain tests.</p>

<p>Test files can use the UTF-8 encoding, but there is also an escape convention
which allows control characters or Unicode characters to be included as plain
text. A backslash followed by digits represents a character by its decimal code,
or by its hex code if the code starts with zero. Two backslashes are used to
represent a single backslash. A backslash followed by any other character
removes that character. In particular, a backslash followed by a space can be
used as a separator, and a backslash followed by a newline can be used to cancel
the newline. For example, given that <code>960</code> is the decimal code for
the character &#960;, then:</p>

<ul style="list-style-type:none;">
<li><code style="display:inline-block;width:5em;">\960x</code>
is &#960; followed by x</li>
<li><code style="display:inline-block;width:5em;">\960\ 5</code>
is &#960; followed by the digit <code>5</code></li>
<li><code style="display:inline-block;width:5em;">\\960x</code>
is the five characters <code>\960x</code></li>
<li><code style="display:inline-block;width:5em;">...\13\</code>
is a line ending in CR instead of LF</li>
</ul>

<h2 id="checks">Consistency checks</h2>

<p>A number of checks are performed on a grammar which help to ensure
consistency. For some features of grammars, namely numerical characters,
non-empty strings and sets, ranges, categories, options, one-or-more repetitions
and try, the results of the checks are clear from these example
equivalences:</p>

<pre>32        &#8801;  ' '
"ab"      &#8801;  ['a' 'b']
'ab'      &#8801;  'a' / 'b'
'a'..'z'  &#8801;  'a' / ... / 'z'
Ll        &#8801;  'a' / ... / 'z' / ...
x?        &#8801;  x / ""
x+        &#8801;  x x*
[x]       &#8801;  x&amp; x
</pre>

<p>This reduces the number of features of grammars that need to be dealt with
separately. The core features remaining are:</p>

<pre><code>''</code>     the empty set
<code>""</code>     the empty string
<code>@x</code>     an action (or drop)
<code>#x</code>     an error marker
<code>'x'</code>    a single character
<code>#x</code>     a token tag
<code>&lt;x></code>    a divider
<code>x/y</code>    a choice
<code>x y</code>    a sequence
<code>x*</code>     a repetition
<code>x&amp;</code>     a 'has' lookahead
<code>x!</code>     a 'not' lookahead
</pre>

<p>The checks can be described under a number of headings.</p>

<h3 id="type">Input checking</h3>

<p>Some obvious checks are done first, such as syntax checking of the grammar,
and checking that each rule name is defined exactly once.</p>

<p>A grammar is then checked to see if it represents a text parser or a token
parser. A text parser must contain no tags. A token parser must not contain
numerical character codes or character sets or character ranges or dividers. If
it contains a string, there must be a definition of that string as a synonym for
a tag:</p>

<pre>assign = id "=" expression
...
"=" = %eq
</pre>

<p>There are also checks on the range operator:</p>

<pre>digit = "0" .. "9"
letter = 'a' .. 'z' / 'A' .. 'Z'
control = NUL .. US
NUL = 0
US = 31
</pre>

<p>There is a check that each operand is a character (code point), i.e. a
numerical character code or a one-character string or a one-character set, or a
name which refers to one of those.</p>

<h3 id="loop">Left recursion checking</h3>

<p>Pecan checks that the grammar contains no infinite loops caused by left
recursion. The simplest example is where a rule mentions its own name at the
start of its right hand side, or at the start of one of its alternatives:</p>

<pre>sum = sum "+" term / term
</pre>

<p>In a Pecan grammar, a rule of this form leads to an immediate infinite loop,
and so is reported as an error. Indirect left recursion is also detected. That
is where two or more rules mention each other at the beginning:</p>

<pre>expression1 = expression2 ...
expression2 = expression1 ...
</pre>

<p>Less obvious cases of left recursion are also detected, e.g.</p>

<pre>statement = label* statement
</pre>

<p>Although <code>statement</code> does not mention itself right at the
beginning, the expression <code>label*</code> may succeed without any input
being matched, and therefore an infinite loop ensues.</p>

<p>Four boolean properties of expressions <code>SP</code>, <code>SN</code>,
<code>FP</code>, <code>FN</code> are calculated for each expression, in a very
similar way to PEG grammars. The <code>SP</code>, <code>SN</code> properties
mean the expression can succeed with or without progress being made in the
input, and <code>FP</code>, <code>FN</code> mean that an expression can fail,
with or without progress. The way these are calculated for the core features of
grammars (using <code>&amp;</code> for 'and' and <code>|</code> for 'or', with
<code>&amp;</code> binding tighter) are:</p>

<pre>SN("") = true;  SP("") = FP("") = FN("") = false
SN(@a) = true;  SP(@a) = FP(@a) = FN(@a) = false
SN(#a) = true;  SP(#a) = FP(#a) = FN(#a) = false

FN('') = true;  SP('') = SN('') = FP('') = false

SP('a') = FN('a') = true;  SN('a') = FP('a') = false
SP(%a) = FN(%a) = true;  SN(%a) = FP(%a) = false
SN(&lt;a>) = FN(&lt;a>) = true;  SP(&lt;a>) = FP(&lt;a>) = false

SN(x y) = SN(x) &amp; SN(y);
SP(x y) = SP(x) &amp; SP(y) | SP(x) &amp; SN(y) | SN(x) &amp; SP(y);
FN(x y) = FN(x) | SN(x) &amp; FN(y);
FP(x y) = FP(x) | SN(x) &amp; FP(y) | SP(x) &amp; FN(y) | SP(x) &amp; FP(y);

SN(x/y) = SN(x) | FN(x) &amp; SN(y);
SP(x/y) = SP(x) | FN(x) &amp; SP(y);
FN(x/y) = FN(x) &amp; FN(y);
FP(x/y) = FP(x) | FN(x) &amp; FP(y);

SN(x*) = FN(x)
SP(x*) = SP(x) &amp; FN(x)
FP(x*) = FP(x)
FN(x*) = false

SN(x&amp;) = SN(x) | SP(x);  SP(x&amp;) = false
FN(x&amp;) = FN(x) | FP(x);  FP(x&amp;) = false

SN(x!) = FN(x) | FP(x);  SP(x!) = false
FN(x!) = SN(x) | SP(x);  FP(x!) = false
</pre>

<p>Because the rules include recursion, fixed point iteration is used, i.e. the
values are calculated repeatedly until they don't change. If all the values are
set to <code>false</code> at the start, the only possible changes are from
<code>false</code> to <code>true</code>, so the iteration terminates.</p>

<p>Once these values are known, a further boolean property, <code>WF</code> is
calculated to check that the grammar is well formed. If <code>WF</code> turns
out to be false for any expression, that is reported as an error because it
contains left recursion. The <code>WF</code> property is calculated (using
<code>~</code> for 'not') by:</p>

<pre>WF("") = WF(@a) = WF(#a) = WF('') = WF('a') = WF(%a) = WF(&lt;a>) = true
WF(x y) = WF(x) &amp; (~SN(x) | WF(y))
WF(x/y) = WF(x) &amp; WF(y)
WF(x&amp;) = WF(x)
WF(x!) = WF(x)
</pre>

<p>This check is implemented by finding out for each expression in the grammar
whether or not it is optional, i.e. whether it can succeed without making any
progress by matching some input. Then, for each rule, the rule names which it
starts with are recorded, taking account of initial optional expressions.
Finally, any loops within these recorded names are detected.</p>

<h3 id="token">Token checking</h3>

<hr/>

<p>For grammars which have text as input, a check is made that all tokens
produced are non-empty, so that continual progress is made through the
characters in the input. For example:</p>

<pre>id = letter+ @identifier
letter = 'a' .. 'z'
</pre>

<p>Here, it is clear that by the time the accept action
<code>@identifier</code> is reached, at least one letter has been matched from
the input. On the other hand, suppose the <code>id</code> rule was:</p>

<pre>id = letter* @identifier
</pre>

<p>This causes an error message, because <code>@identifer</code> can be reached
without matching any input characters. However, if this <code>id</code> rule
is always used in a context where at least one character has already been
matched, i.e. the <code>id</code> rule refers to the remainder of a token
rather than a whole token, then there is no error.</p>

<p>This check is implemented by making as many deductions as possible about
positions in the grammar at which input characters have definitely been matched
since the previous token. This is a conservative check - it is possible for a
pathological grammar to produce an error message even though no empty token
would ever be created in practice.</p>

<p>There is a further check that a scanner makes no attempt to read past the
end of the input. For example, suppose there is a scanner rule like
this:</p>

<pre>tokens = token+ UC! @end
token =  space / identifier / keyword / operator / punctuation
</pre>

<p>This is fine, because all that follows the end of text <code>''</code> is an
action, not any attempt to match any characters. However, suppose the
rule is:</p>

<pre>tokens = token+
token = space / identifier / keyword / operator / punctuation / end
end = '' @end
</pre>

<p>This does cause an error, because after recognising the end of text, the
scanner could continue to look for more tokens.</p>

<h3 id="output">Output checking</h3>

<p>Actions are assumed to treat output items in a stack-like manner. Restrictive
checks are made to guarantee consistent handling of output items. The arity of
each action has to be specified, and has to be consistent each time the action
appears. For example if a grammar contains both <code>@1add</code> and
<code>@2add</code>, that is reported as an error. The arities are used to check
that each expression in the grammar produces a fixed, known number of output
items.</p>

<p>Both alternatives in a choice expression must have the same net effect on the
size of the stack. For example, this rule causes an error:</p>

<pre>token = ('0'..'9')+ @token / ' '+
</pre>

<p>The first alternative adds one item to the stack, but the second adds
nothing. On the other hand, this rule is legal:</p>

<pre>token =  ('0'..'9')+ @1token / ' '+
</pre>

<p>The <code>@1token</code> action pops an item from the stack, presumably a
list of tokens, and pushes one item back on the stack, presumably the updated
list. It thus has zero net effect on the stack. Since both alternatives now have
a net zero effect, the <code>token</code> rule itself can be deduced as having a
net zero effect.</p>

<p>A repeated expression must have zero net effect on the stack. For example,
suppose the grammar contains:</p>

<pre>tokens = (('0'..'9')+ @token)*
</pre>

<p>The inner expression causes one output item to be pushed on the stack. This
is reported as an error, because <code>tokens</code> as a whole pushes an
unknown number of items onto the stack. On the other hand, this definition is
allowed:</p>

<pre>tokens = @list (('0'..'9')+ @1token)*
</pre>

<p>The <code>@list</code> action pushes one item, an empty list, onto the stack.
The inner expression pops the list, adds a token to it, and pushes the updated
list onto the stack. As a result, it has a zero net effect on the stack. It can
be repeated any number of times, still with a zero net effect, and so the
<code>tokens</code> rule can be deduced to push one item onto the stack.</p>

<p>A second check is that the stack never underflows. For example:</p>

<pre>example = "1" @n @2add
</pre>

<p>Here, when the <code>add</code>action is reached, there is only one output
item on the stack, whereas two previous output items are supposed to be passed
to <code>add</code>, so an error is reported.</p>

<p>To implement these checks, Pecan calculates the overall number of items added
to the stack, possibly negative, for each expression in the grammar. It also
calculates a low water mark value for every expression in the grammar,
representing the number of items that are needed on the stack during processing
of the expression. It then checks that for the first rule in the grammar, which
represents the final result, one item is added, and the low water mark isn't
negative.</p>

<p>In order to carry out these checks, a very uniform approach to actions has
to be taken. For example, Pecan checks that each alternative in a choice adds
the same number of items to the stack, and that where there is a repetition
operator, e.g. <code>x?</code> or <code>x*</code> or <code>x+</code>, the
subexpression <code>x</code> has no overall effect on the number of items on
the stack, so that the number of times <code>x</code> is repeated doesn't
have any overall effect on the stack size.</p>

<p>These checks are conservative, i.e. there could be pathological grammars
which always correctly produce one output item in practice, but which don't
pass the checks.</p>

<h2 id="java">Generating code</h2>
<!--
TODO: Have multiple entry points. (Don't generate rules?)
TODO: Insist on all names distinct. (Or what? Prefix?)

Have opcodes, actions, errors, tags, rules, bytes.
-->

<!--
Instead of the generated code being given an array of tokens, calls are made to
an external function which provides the next tag. This can be used to cope with
non-context-free features of languages. For example, take the infamous situation
with the C language where parsing depends on recognizing identifiers which have
been defined as type names using <code>typedef</code>. A C scanner which is
independent of parsing may emit tokens with an identifier tag, which may or may
not turn out later to be type names. The external functions for a C parser
would include symbol table construction, and could change the tags of tokens
given to the parser, according to those symbol tables.</p>
-->


<p>Code is generated as a bytecode with an interpreter. This is somewhat similar
to the table-driven techniques used in bottom-up CFG-based parser generators.
Advantages of using the bytecode approach are:</p>

<ul>

<li>it supports any target programming language</li>

<li>it avoids the repetition in hand-written parsers</li>

<li>it allows calls, which are very frequent, to be implemented in a simple
and efficient way using a custom stack</li>

<li>it makes various optimisations such as tail calls easier to implement</li>

</ul>

<h3>Interpreters</h3>

<p>A bytecode sequence is generated using a command of the form:</p>

<pre>pecan [-i interpreter] -o output grammar
</pre>

<p>The option <code>-i interpreter</code> specifies an interpreter source file,
written in any desired programming language, containing a placeholder:</p>

<pre>&lt;pecan>
</pre>

<p>This must be on a line on its own, possibly preceded by spaces to specify an
indent. The command inserts the bytecode into the interpreter, in place of the
placeholder, to form the output file. The result is a parser which matches the
grammar.</p>

<p>The bytecode sequence is printed as text, as a comma-separated list of
unsigned byte values. Those values which are opcodes, categories, tags, actions
or error markers are represented symbolically. In addition, if multiple entry
points are requested, rules names are also represented symbolically. Suppose the
grammar file contains:</p>

<pre>digit = "0".."9" @number
</pre>

<p>Then the bytecode sequence generated might be:</p>

<pre>START, 8, LOW, 1, 48, HIGH, 1, 57, ACT, number, STOP
</pre>

<p>The values of the symbols are specified by the surrounding interpreter, eg.
using enumerations to define each symbol as a number in the range <code>0</code>
to <code>255</code>. By default, the same names are used as in the grammar,
after removing the prefix character. That means the names of actions, error
markers and tags must normally all be distinct.</p>

<p>An interpreter can be constructed by taking one of the example interpreters
provided with Pecan, translating it into the desired programming language if
necessary, and adapting it to a particular application by customising tags,
actions and error handling as appropriate.</p>

<h3>The bytecode</h3>

<p>A grammar is converted into an array of unsigned bytes. The notation
<code>{x}</code> means "the bytecode sequence generated for expression x" and
<code>nx</code> stands for the number of bytes in <code>{x}</code>. For example,
the normal translation of a rule is:</p>

<pre>{id = x}   =   START nx {x} STOP
</pre>

<p>In these descriptions, the commas which separate the bytes in the printed
code are omitted. Some opcodes such as <code>STOP</code> take no argument.
Others, like <code>START</code> are followed by a one-byte argument. The number
<code>nx</code> can be thought of as a relative offset in the code,
from the byte after <code>nx</code> to the <code>STOP</code>
instruction. If the number <code>nx</code> exceeds <code>255</code>,
then the translation becomes:</p>

<pre>{id = x}   =   EXTEND+START nx1 nx2 {x} STOP
</pre>

<p>Here <code>EXTEND+START</code> is a single bytecode. The number
<code>EXTEND</code> can be added to any opcode which normally takes a one-byte
argument, to indicate that it instead takes a two-byte argument. The two bytes
<code>nx1 = nx/256</code> and <code>nx2 = nx%256</code> represent
<code>nx</code> in big-endian unsigned format. If multiple entry points are
requested when generating the bytecode, then the rules which are to be used as
entry points are labelled by generating them as:</p>

<pre>{id = x}   =   RULE id START nx {x} STOP
</pre>

<p>The names of the entry point rules must be distinct from the other symbols
generated. The entry point rules are generated one after the other from
the start of the bytecode sequence. That allows the interpreter to scan the
bytes, skipping the body <code>{x}</code> of each rule using the number
<code>nx</code>, to find the entry points. When the name of a rule
such as <code>id = x</code> is used elsewhere in the grammar, it is translated
by one of:</p>

<pre>{id}       =   GO n
{id}       =   BACK n
</pre>

<p>The number <code>n</code> is an offset in the code to the body
<code>{x}</code> of the relevant rule, relative to the next byte after
<code>n</code>. The <code>GO</code> opcode is used when the offset is positive,
and <code>BACK</code> is used, with a positive argument, when the offset is
negative. For simple input:</p>

<pre>{'a'}       =   CHAR 97
{"a"}       =   CHAR 97
{97}        =   CHAR 97
{%id}       =   TAG id
</pre>

<p>The <code>CHAR</code> opcode is used for any notation which represents a
single character which takes up one byte in UTF-8, i.e. is in the range
<code>0</code> to <code>127</code>. A tag is translated using the
<code>TAG</code> opcode. For strings:</p>

<pre>{128}       =   STRING 2 194 128
{"ab"}      =   STRING 2 97 98
{""}        =   STRING 0
{"&#960;"}       =   STRING 2 207 128
{"a&#960;"}      =   STRING 3 97 207 128
{'&#960;'}       =   STRING 2 207 128
{&lt;ab>}      =   LESS 2 97 98
</pre>

<p>If a single Unicode characters is greater than <code>127</code> or a string
has more than one character, the <code>STRING</code> opcode is used, followed by
the number of bytes of text, followed by the text in UTF-8 format. A string
containing characters of mixed UTF-8 lengths causes no problem, because a UTF-8
string can be matched byte by byte, without taking account of character
boundaries. A divider is translated using the <code>LESS</code> opcode. The
comparison between UTF-8 strings which it represents can similarly be done byte
by byte. For sets:</p>

<pre>{''}        =   SET 0
{'ab'}      =   SET 2 97 98
{'&#945;&#946;'}      =   SET2 4 206 177 206 178
{'a'..'z'}  =   LOW 1 97 HIGH 1 122
{'&#945;'..'&#969;'}  =   LOW 2 206 177 HIGH 2 207 137
</pre>

<p>The <code>SET</code> opcode is used for sets of one-byte characters, the
<code>SET2</code> opcode for sets of two-byte characters and so on. A mixed set
such as <code>'a&#960;'</code> is treated as <code>'a' / '&#960;'</code> so that
each set opcode takes UTF-8 characters of a fixed length. A range is translated
into the two opcodes <code>LOW</code> and <code>HIGH</code>. For categories:</p>

<pre>{Nd}        =   CAT Nd
</pre>

<p>A category is translated using the <code>CAT</code> opcode. This may be the
most difficult opcode to implement, if the chosen programming language doesn't
have a facility for finding the category of a character. In that case, a
two-stage lookup table is needed. A two-stage table is included among the
example interpreters provided.</p>

<pre>{x/y}       =   EITHER nx {x} OR {y}
{x y}       =   BOTH nx {x} AND {y}
</pre>

<p>The <code>EITHER</code> or <code>BOTH</code> opcode initializes a choice or
sequence, and <code>OR</code> or <code>AND</code> checks what happens after
<code>{x}</code> to decide whether or not to continue with <code>{y}</code>. If
the interpreter implements each opcode separately using a switch, then
<code>EITHER</code> or <code>BOTH</code> can be thought of as causing a call to
<code>{x}</code>, and <code>OR</code> or <code>AND</code> as causing a tail-call
to <code>{y}</code>. If the interpreter uses functions, then a single function
can deal with the two calls, but the call to <code>{y}</code> can't be a tail
call unless the interpreter's language supports it.</p>

<pre>{x?}        =   MAYBE OPT {x}
{x*}        =   MAYBE MANY {x}
{x+}        =   DO AND MAYBE MANY {x}
{[x]}       =   LOOK TRY {x}
{x&amp;}        =   LOOK HAS {x}
{x!}        =   LOOK NOT {x}
</pre>

<p>The <code>MAYBE</code> opcode initializes, then causes a call to
<code>{x}</code>, returning to <code>OPT</code>. The <code>OPT</code> which
converts the result of <code>{x}</code> into the result of <code>x?</code>. The
<code>MANY</code> opcode is similarly executed after <code>{x}</code>. It checks
the result of <code>{x}</code> to decide whether or not to call it again. The
code <code>MAYBE OPT {x}</code> might be a little more readable if written as
<code>MAYBE nx {x} OPT</code>, but the format shown above avoids the need for
the argument <code>nx</code>. In the case of <code>MANY</code>, there is the
added advantage that <code>{x}</code> is easily called again. The code for
<code>x+</code> is equivalent to the code for <code>x x*</code>, except that the
<code>DO</code> opcode avoids the need for a second copy of <code>{x}</code> by
jumping forwards, and arranging for the call to return to <code>AND</code>. The
<code>LOOK</code> opcode initializes any of the lookahead constructs, arranging
to return to <code>TRY</code> or <code>HAS</code> or <code>NOT</code> which
sorts out the result.</p>

<pre>{@a}        =   ACT a
{@}         =   ACT 0
{#e}        =   MARK e
</pre>

<p>An action is translated using the <code>ACT</code> opcode. In enumerating the
action symbols, the interpreter must reserve zero, which is generated for the
drop action <code>@</code>. Actions need to be delayed, either because they are
inside a try construct <code>[x]</code>, or because they are at the start of a
left hand choice <code>@a x / y</code>. If the grammar is entirely context free,
then all the actions can be delayed until the end of parsing. In the example
interpreters provided, actions are delayed by a minimal amount, so that they can
affect later parsing by adjusting the input to get context sensitive effects.
Actions are delayed by being recorded symbolically, then either performed or
discarded at the end of any lookahead construct, or whenever progress is made in
the input. Error markers, signalled by the <code>MARK</code> opcode, are
collected as a set, perhaps implemented as a bitmap, and cleared whenever a new
marker is found further on in the input.</p>

<p>Accurate details of what each opcode does can be gleaned from the provided
interpreters and their comments.</p>

<h2 id="interpreters">Example interpreters</h2>

<p>There are some things that the example interpreters have in common. There is
an array <code>input</code> of characters or tokens, and two indexes
<code>start</code> and <code>in</code> into it. The items up to
<code>start</code> have been processed, and <code>in</code> is the current
position. So when a zero-arity action is performed, the items between
<code>start</code> and <code>in</code> are processed, and <code>start</code> is
updated to be equal to <code>in</code>.</p>

<p>There is a list <code>output</code> of delayed actions. The variable
<code>out</code> represents the current position in the list, i.e. the number of
delayed actions.</p>

<p>Actions must be delayed during lookaheads, and discarded on backtracking. The
left hand expression <code>x</code> in a choice <code>x / y</code> also involves
an implicit one-item lookahead. Since <code>x</code> may involve actions before
matching anything, actions need to be delayed in this case too, and discarded if
<code>x</code> fails.</p>

<p>An approach is taken which delays actions whenever needed for correctness,
yet delays them as little as possible to allow maximum context sensitivity.
Every action is delayed when encountered by adding to the <code>output</code>
list, and the current value of <code>in</code> is stored with it. For left hand
choices and lookaheads, <code>out</code> is saved. If the construct fails or
backtracks, accumulated actions are discarded by setting <code>out</code> to the
saved value. Whenever progress is made in the input, other than in a lookahead
construct, all the delayed actions are performed. (If a number of nested left
hand choices are under way, and there is progress, all the left choices become
committed, so it is correct to perform all the delayed actions at that point.)
If a try <code>[x]</code> succeeds, any accumulated actions are kept, and if
progress was made during <code>[x]</code>, all the delayed actions are
performed.</p>

<h2 id="transforms">Transforms</h2>

<p>The Pecan grammar language is intended to be sufficiently simple and precise
to support equational transforms. At present, such transforms are carried out
manually and informally on grammars, but it is possible to imagine a theory of
transforms being developed more formally and used to develop and justify
automatic optimisations, or to build an assistant which would suggest and check
user-driven transforms while developing grammars. Equations such as these can be
used:</p>

<pre>(x y) z == x (y z)
(x / y) / z == x / (y / z)
x+ == x x*
x* = (x+)?
x? = x / ""
[[x] y] z == [x y] z
[x y] z / [x u] v == [x] ([y] z / [u] v)
(x / y) z = x z / y z
</pre>

<p>Care has to be taken, because not all 'obvious' equations hold. For example,
<code>x (y / z)</code> is not equivalent to <code>x y / x z</code> because if
<code>x</code> succeeds, in the first case the parser is free to make the choice
between <code>y</code> and <code>z</code>, but in the second case it is already
committed to <code>y</code>. Also <code>x / y</code> and <code>y / x</code> are
not equivalent. However, they are equivalent if it can be established that
<code>x</code> and <code>y</code> begin differently. In these equations, actions
and error markers are included, and the transformed expression has precisely the
same output effect and error handling properties as the original.</p>

<h2 id="changes">Recent changes</h2>

<p>The previous version of Pecan was 0.4. Changes in version 1.0 are:</p>

<ul>
<li>actions are now allowed at the start of a left hand choice</li>
<li>actions are delayed in case they need to be discarded</li>
<li>error markers are no longer postfix</li>
<li>the divider notation <code>&lt;abc></code> has been added</li>
<li>string tags use double quotes instead of backquotes</li>
<li>string tags have definitions to give them names</li>
<li>separate grammar and test files are supported</li>
<li>individual rules within a grammar can be tested</li>
<li>one test file can be called from within another</li>
<li>parser generation is via bytecode</li>
</ul>

<h2 id="pecan">The Pecan grammar</h2>

<p>Here is a Pecan parser for the Pecan language itself. It includes scanning,
actions, and error markers. The <code>gap</code> rule deals with the
continuation line convention. It follows a token which can end a rule, and looks
ahead for a possible continuation to see if the next newline should be skipped.
Brackets are treated as tokens so that the extent in the source text of
bracketed expressions can be calculated accurately.</p>

<pre>pecan = skip rules end
rules = rule (rules @2add)?
rule = definition / synonym
definition = id equals expression newline skip @2rule
synonym = string equals tag @2rule

expression = term (slash expression @2or)?
term = factor (term @2and)?
factor = atom postop*
postop = opt @1opt / any @1any / some @1some / has @1has / not @1not
atom = id / action / marker / tag / range / divider / try / bracket
range = text (dots text @2range)?
text = number / string / set
try = sb expression se @3back
bracket = rb expression re @3bracket

id = #id letter alpha* @id gap
action = #action '@' (digit* #letter letter alpha* @act / @drop) gap
tag = #tag "%" letter alpha* @tag gap
marker = #marker "#" #letter letter alpha* @mark gap
number = #number (("1".."9") digit* / "0" hex*) @number gap
set = #set "'" ("'"! visible)* #quote "'" @set gap
string = #string '"' ('"'! visible)* #quote '"' @string gap
divider = #divider '&lt;' ('>'! visible)* '>' @divider gap

dots = '.' #dot '.' skip @
equals = #equals "=" skip @
slash = #slash "/" skip @
rb = "(" @token skip @
sb = "[" @token skip @
has = #look "&amp;" @token gap @
not = #look "!" @token gap @
opt = #query "?" @token gap @
any = #many "*" @token gap @
some = #some "+" @token gap @
re = #bracket ")" @token gap @
se = #bracket "]" @token gap @

skip = (space / comment / newline)*
gap = space* comment? continuation @
continuation = [nl skip '=/)]'&amp;]?
newline = #newline 13? 10 @
comment = ["//"] visible* newline
visible = (Cc/Cn/Co/Cs/Zl/Zp)! Uc
alpha = letter / digit / '_' / '-'
letter = Lu / Ll / Lt / Lm / Lo
digit = Nd
hex = digit / 'ABCDEFabcdef'
end = #end Uc!
</pre>

<p>The Unicode standard defines many different newline conventions which should
be recognised by software handling arbitrary text files. However, for text files
in computer languages, it seems better to promote uniformity. In fact, there is
a lot to be said for insisting that all such text files be stored using LF
newlines, even on Windows now that Notepad accepts LF. However, as a temporary
practical concession, Pecan supports CR+LF newlines.</p>

<!--
<h2>Tutorial Topics</h2>

<p>Topics: grammar operators, left recursion, right recursion, iteration.
Stack-based actions. Actions not done and undone if backtrack. Actions can do
stuff or build trees. Built-in scanning and drawbacks. Separate scanner. How
to join then up.</p>
-->

</body>
</html>
