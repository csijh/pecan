<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-gb" xml:lang="en-gb">
<head>
<title>Pecan Manual</title>
<style>
  body { font-size: 120%; }
  pre, .indent { margin-left:40px; }
</style>
</head>
<body>

<img src="pecan.png" width="300" height="65" />
<hr/>

<h1>Pecan Reference Manual</h1>

<ul>
<li><a href="#use">Using Pecan</a></li>
<li><a href="#intro">Background</a></li>
<ul>
<li><a href="#rd">Recursive descent</a></li>
<li><a href="#cfg">CFG grammars</a></li>
<li><a href="#peg">PEG grammars</a></li>
<li><a href="#pecan">Pecan grammars</a></li>
</ul>
<li><a href="#notation">Notation</a>
<ul>
<li><a href="#rules">Rules</a></li>
<li><a href="#comments">Comments</a></li>
<li><a href="#parentheses">Parentheses</a></li>
<li><a href="#continuations">Continuations</a></li>
<li><a href="#choices">Choices</a></li>
<li><a href="#sequences">Sequences</a></li>
<li><a href="#repetition">Repetition</a></li>
<li><a href="#lookahead">Lookahead</a></li>
<li><a href="#text">Text</a></li>
<li><a href="#actions">Actions</a></li>
<li><a href="#tokens">Tokens</a></li>
<li><a href="#literals">Literals</a></li>
<li><a href="#errors">Errors</a></li>
</ul>
</li>
<li><a href="#testing">Testing</a></li>
<li><a href="#checks">Consistency checks</a>
<ul>
<li><a href="#loop">Left recursion checking</a></li>
<!--<li><a href="#token">Token checking</a></li>-->
<li><a href="#output">Output checking</a></li>
</ul>
<li><a href="#compile">Compilation</a>
<ul>
<li><a href="#functions">Recursive functions</a></li>
<li><a href="#code">Bytecode</a></li>
</ul>
</li>
</li>
<li><a href="#transforms">Transforms</a></li>
<li><a href="#changes">Recent changes</a></li>
</ul>

<h2 id="use">Using Pecan</h2>

<p>Pecan is a tool for developing and checking grammars, and generating scanners
and parsers. It is aimed at parsers for programming languages, <a
href="https://en.wikipedia.org/wiki/Domain-specific_language">domain specific
languages</a>, and other unambiguous computer languages. It provides a precise
grammar notation, which is independent of implementation language, based on
recursive descent with lookahead. This manual describes Pecan version 1.0 which
has these features:</p>

<ul>

<li>a grammar is an executable prototype parser</li>

<li>output actions and error markers are included</li>

<li>transformations on grammars preserve actions and errors</li>

<li>many consistency checks are applied to grammars</li>

<li>there is support for development and testing of grammars</li>

<li>compilation can be direct or via bytecode</li>

<li>compilation can be to almost any target languages</li>

</ul>

<p>Having a separate notation for grammars helps to focus attention on the
various issues that have to be addressed, separately from the programming
details. However, that also makes grammars rather dense. Creating or translating
a grammar accurately can be difficult. In addition, programmers typically use
parser generators only rarely, and are often not grammar experts. That's why
Pecan has explicit support for test-driven grammar development.</p>

<p>The Pecan system is written in Java, so the first step is to make sure that
version 8 or better of Java is available. Pecan is provided as an executable jar
file <code>pecan.jar</code>. The jar file contains both the compiled program and
also the source code. If this jar file is downloaded, it can be run with:</p>

<pre>java -jar pecan.jar ...
</pre>

<p>However, it is more convenient to create a batch file or shell script, or use
an alias or equivalent, so that the program can be run just by typing:</p>

<pre>pecan ...
</pre>

<p>The way to do this differs from system to system.</p>

<p>To run tests on a grammar, type a command of the form:</p>

<pre>pecan [-t | -trace] [line] testfile
</pre>

<p>To generate a bytecode version of a grammar, type a command with one of the
forms:</p>

<pre>pecan grammar -c program
pecan grammar -b program
</pre>

<p>The option <code>-c program</code> indicates that the grammar is to be
compiled to a set of recursive descent functions. The option <code>-b
program</code> indicates that the grammar is to be compiled into a bytecode
array. Either way, the file is a template program in the desired target
programming language, into which the result of the compilation is embedded, to
form a parser or application program.</p>

<h2 id="intro">Background</h2>

<p>Other approaches to developing parsers are usually based on writing them
manually in the <a
href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive
descent</a> style, or using a parser generator based on the <a
href="http://en.wikipedia.org/wiki/Context-free_grammar">context free
grammar</a> (CFG) formalism, or the <a
href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">parsing
expression grammar</a> (PEG) notation.</p>

<h3 id="rd">Recursive descent</h3>

<p>Recursive descent parsers have the advantage of being efficient, intuitive,
and capable of being hand-written. However, for large projects, parsers tend to
become repetitive and error prone. One of the main problems is that a simple
approach is hardly ever enough. In order to deal with the difficult cases which
arise in practice, extra features such as lookahead or backtracking are needed.
These extra features are often added in an ad hoc fashion on practical grounds,
which typically makes parsers complex, obscure and error-prone.</p>

<p>A library of <a href="http://en.wikipedia.org/wiki/Parser_combinator">parser
combinators</a> can ease the process of writing a parser in the recursive
descent style, by providing components which reduce verbosity and automate
features such as lookahead.  However, a combinator library typically still has
two problems. The first is that parsers have to be written in a specific
language in which the library is written, or to which the library has been
ported. The second is that there is typically no separate and independent
grammar, and so there is a shortage of analysis and development tools to help
with the development of parsers.</p>

<h3 id="cfg">CFG grammars</h3>

<p>The CFG notation (in the form of BNF and many variations) has been the main
formalism for grammars for a long time, and it has been well studied. However,
it has been argued quite strongly that it is not an ideal formalism
to use for unambiguous languages. According to <a
href="http://dl.acm.org/citation.cfm?id=964001.964011">Bryan Ford</a>:</p>

<blockquote>The power of generative grammars to express ambiguity is crucial to
their original purpose of modelling natural languages, but this very power makes
it unnecessarily difficult both to express and to parse machine-oriented
languages using CFGs.</blockquote>

<p>One fundamental theoretical problem is that CFG grammars can contain
ambiguities, and there is no computable algorithm to detect whether or not a
grammar is unambiguous. There is also the associated practical problem that many
published CFG grammars contain ambiguities. Some of these are local, i.e. a
particular rule allows two possible parses, but there is a surrounding, more
global, rule that resolves the ambiguity by only accepting one of the
possibilities. But many ambiguities in published grammars are inherent, the
ambiguity being resolved only by accompanying descriptive text or particular
approaches to generating parsers.</p>

<p>As well as ambiguity, there is also the problem that a CFG grammar describes
a language in a generative way, which is not directly and intuitively linked to
the recognition problem faced in parsing. Indeed the meaning of a grammar is
often different from the parser generated from it. There is an awkward semantic
gap.</p>

<p>Conventional CFG-based parser generators have a variety of other flaws,
partly due to the difficulties of the CFG formalism, and partly due to the age
of their designs. They often have arbitrary heuristic rules for disambiguation.
They often support a subset of CFG grammars which is not at all intuitive. They
often use bottom-up parsing techniques to make parsers near-linear, which makes
the way they operate impenetrable. And they often support actions and error
reporting using embedded code fragments which are not part of the grammar. The
code fragments are often restricted to a particular implementation language, and
the approach is any case very fragile.</p>

<p>These problems with the CFG formalism might be worth putting up with, if the
formalism had excellent theoretical or practical properties. But it doesn't.
For example, CFG grammars have poor composability properties, and poor closure
properties. And, in general, parsing CFG grammars takes O(n<sup>3</sup>) time in
the worst case.</p>

<h3 id="peg">PEG grammars</h3>

<p>The main difference with PEG grammars compared to CFG grammars is that the
symmetrical choice operator <code>|</code> is replaced by an ordered choice
operator <code>/</code> which has a more operational meaning. The expressive
power of PEG grammars is extremely close to that of CFG grammars, certainly
grammars for all practical everyday languages can be expressed in either
notation.</p>

<p>The theoretical and practical properties of the PEG formalism are far
superior to the CFG formalism. PEG grammars never contain any ambiguity, they
have a direct operational meaning as parsers, they are composable, they are
closed under many operations, and they can be parsed in linear time
using the packrat algorithm. This makes the PEG grammar formalism a much better
starting point for studying grammars and parsers.</p>

<p>Unfortunately, there are practical problems with PEG parsers. Although the
packrat algorithm is linear, it is slower and more space hungry than one would
like for efficient large scale parsing. Also, because of the implicit unlimited
backtracking, it can be difficult to understand or predict the operation of
PEGs, it is difficult to produce accurate error messages, and difficult to
express actions. As a result, PEG grammars are typically only used for search
expressions, or for small domain specific languages, and not for larger
applications such as full programming languages.</p>

<p>There is also a relatively minor problem with PEG grammars, which is that
they don't support left recursion. There have been attempts to add it, but the
results are not compelling. It is worth noting, though, that left recursion is
arguably unintuitive, that it would probably never have become common if it
weren't for the prevalence of CFG grammars, and that it is well known how to
transform it away. Most uses of left recursion are very simple, of the kind
<code>a = x | a y</code> which can be translated easily into <code>a = x
y*</code>.</p>

<h3 id="pecan">Pecan grammars</h3>

<p>Pecan provides a notation for grammars which is an adaptation of the PEG
notation to remove the implicit backtracking. Actions and markers for error
handling are easily embedded as symbols, independently of any target programming
language. Explicit lookahead features are provided to help in making choices,
but they don't involve actions or error handling, so a grammar closely
corresponds to conventional simple recursive descent.</p>

<p>Pecan provides direct support for parser development. Tools are provided to
aid in development and testing, including consistency checks on grammars,
features for automated testing, and the ability to execute grammars as symbolic
parsers.</p>

<p>Manual transformations can be carried out on grammars, e.g. to convert CFG
grammars into Pecan grammars or improve efficiency, and these preserve the
actions and error handling properties of generated parsers.</p>

<p>Once a grammar has been developed, it can either be used to guide the manual
construction of a parser, or to generate a parser automatically. A grammar can
be compiled into a collection of recursive descent functions, with very few
restrictions on the target language. Support for a new target language can be
constructed easily. A parser can also be generated as bytecode, with even fewer
restrictions on the target language. An interpreter for a new language can be
constructed fairly easily by translating one of the example interpreters
provided.</p>

<h2 id="notation">Notation</h2>

<p>The Pecan language is a grammar language for writing parsers, loosely based
on the <a href="http://en.wikipedia.org/wiki/Parsing_expression_grammar">PEG</a>
notation. Pecan has a sequential choice operator <code>x/y</code> but, unlike
the PEG notation, the operator does not automatically involve backtracking.
There are separate lookahead operators, for the controlled use of backtracking,
which provide greater control over the progress of parsing. It is much easier to
generate accurate error messages, and parsers can be kept reasonably efficient
by the programmer, without the space overhead of such techniques as the PEG
packrat algorithm. The syntax of Pecan grammars is explained below, and there is
a Pecan grammar for the Pecan language, with tests, in the file:</p>

<p class="indent"><a href="pecan.txt">pecan.txt</a></p>

<p>As with PEG grammars, any parsing expression within a grammar represents a
matching operation which succeeds or fails when applied at a particular position
in the input, and which may cause progress, i.e. may cause the current position
to move forwards in the input, according to how much of it is matched.</p>

<h3 id="rules">Rules</h3>

<p>A parser consists of a sequence of rules, each of which gives a name to a
parsing expression. By default, the first rule specifies the output of the
whole parsing process. For example, a parser might start with:</p>

<pre>module = function+ &lt;>

function = id arguments body

...
</pre>

<p>Apart from being the starting point of the parser, the first rule is not
treated in any special way. In particular, it may succeed without consuming all
the input. So an explicit test is often included, as here, to check that the end
of the input has been reached. The notation <code>&lt;></code> which is a less
than sign followed by a greater than sign, matches the end of the input.</p>

<p>An identifier introduced by a rule starts with a letter and continues with
letters, digits, hyphens or underscores. The text of a grammar is assumed to be
encoded using UTF-8, so Unicode letter and digit characters can be
included.</p>

<p>There is also a literal form of identifier, consisting of characters in
single or double quotes, which is allowed only in token-based parsers and which
is described further in the section on literals below.</p>

<p>In place of a rule, an inclusion may be used:</p>

<pre>{expressions.txt}
</pre>

<p>This is a string giving a file name or path to another file of grammar rules
to be included at this point. This can help in presenting and testing large
grammars in a modular way.</p>

<p>If a parser fails, only the first failure is reported. There is no attempt to
recover. If error recovery is required, this can be accomplished by writing a
separate rule to be tried on the remaining input.</p>

<h3 id="comments">Comments</h3>

<p>Comments start with <code>--</code> and extend to the end of the line. For
example:</p>

<pre>-- A number is a sequence of one or more digits.
number = '0123456789'+
</pre>

<p>There is no multi-line comment convention.</p>

<h3 id="parentheses">Parentheses</h3>

<p>Parentheses, i.e. round brackets, have their usual meaning, indicating
grouping of operations. For example:</p>

<pre>(x / y) z
</pre>

<p>means parse <code>x</code> or <code>y</code>, then parse <code>z</code>, as
opposed to:</p>

<pre>x / y z
</pre>

<p>which means either parse <code>x</code>, or else parse <code>y</code> and
<code>z</code>.</p>

<h3 id="continuations">Continuations</h3>

<p>No explicit symbol is used to terminate a rule. A rule is terminated at the
end of a line, unless it is continued. A rule is continued on the next line if
the last token on the current line is an infix symbol or open bracket, i.e. one
of <code>=/([</code>. Here is an example rule where each line except the last
ends with <code>=</code> or the <code>/</code> operator:</p>

<pre>atom =
  id /
  number /
  bracket
</pre>

<p>Also, a rule is continued on the next line if the first token of the next
line is an infix symbol or close bracket, i.e. one of <code>=/)]</code>. This
allows an alternative style for a multi-line rule:</p>

<pre>atom
= id
/ number
/ bracket
</pre>

<p>In this example, each line that starts with <code>=</code> or <code>/</code>
is a continuation of the previous line.</p>

<h3 id="choices">Choices</h3>

<p>The choice operator <code>/</code> separates alternatives, which are tried
one after the other. For example:</p>

<pre>atom = id / number / bracket
</pre>

<p>If parsing of an alternative succeeds, then the parsing of the whole
expression succeeds. Otherwise, if no progress was made, the next alternative is
tried.</p>

<p>The choice operator involves a single item lookahead. If progress is made on
an alternative, i.e. at least one input character or token is matched, then the
parser is committed to that alternative, and further alternatives are not
tried.</p>

<p>There are separate lookahead operators which allow speculative parsing of an
alternative with backtracking.</p>

<h3 id="sequences">Sequences</h3>

<p>When items follow each other with no visible operator in between, this
indicates "followed by". For example:</p>

<pre>assignment = identifier "=" expression
</pre>

<p>This means that an assignment is an identifier followed by an equals sign
followed by an expression. The items are parsed one by one and, if parsing of
any item fails, parsing of the sequence is abandoned. Sequencing binds tighter
than the choice operator.</p>

<h3 id="repetition">Repetition</h3>

<p>There are three postfix repetition operators. The <code>*</code> operator
indicates that an item is to be repeated any number of times, i.e. zero or more
times. The <code>+</code> operator indicates that an item is to be repeated one
or more times. The <code>?</code> operator indicates that an item is optional,
i.e. repeated zero times or once. Postfix operators bind tighter than
sequencing, so <code>x y*</code> means <code>x (y*)</code>. Examples are:</p>

<pre>string = '"' stringchar* '"'
number = digit+
call = function "(" arguments? ")"
</pre>

<p>The <code>string</code> rule specifies that a string consists of a double
quote followed by any number of allowable characters followed by a closing
double quote. The <code>number</code> rule specifies that a number consists of
one or more digits. The <code>call</code> rule specifies that a call consists of
a function name followed by brackets, and the brackets may optionally contain
arguments.</p>

<p>The three expressions <code>x*</code>, <code>x+</code>, <code>x?</code> act
in exactly the same way as the three rules <code>xs</code>, <code>xp</code>,
<code>xq</code> defined by:</p>

<pre>xs = x xs / ""
xp = x xs
xq = x / ""
</pre>

<p>This means that <code>x*</code> or <code>x+</code> will accept as
many <code>x</code>'s as are present in the input. In all three cases, in line
with the fact that the choice operator does no backtracking by default, if
progress is made on a final <code>x</code> without success, the whole
expression fails.</p>

<h3 id="lookahead">Lookahead</h3>

<p>There are three lookahead constructs, the <dfn>see</dfn> operator
<code>[...]</code>, the <dfn>has</dfn> operator <code>&amp;</code> and the
<dfn>not</dfn> operator <code>!</code>.</p>

<p>The see operator (also called the try or commit operator) is specified using
square brackets. In an expression <code>[x]</code>, the subexpression
<code>x</code> is parsed speculatively. If it succeeds, parsing continues as
normal. If it fails, the parser backtracks to the point just before
<code>x</code>. The see operator is usually used to indicate the point at
which the parser should accept an alternative. For example:</p>

<pre>statement = [identifier "="] expression / ...
</pre>

<p>This specifies that if the parser sees an identifier and equal sign, then it
should commit to the first alternative. If an error occurs before that, e.g. an
identifier has been matched but there is no equal sign, backtracking is done by
resetting the parser to the point before the identifier, and the next
alternative is tried.</p>

<p>The has <code>&amp;</code> and not <code>!</code> operators represent
positive and negative lookahead. In the PEG notation, <code>&amp;</code> and
<code>!</code> are prefix operators, but in Pecan, they are postfix, to make the
syntax of rules simpler and more uniform and, in particular, to avoid precedence
issues which would arise if there were both prefix and postfix operators. The
<code>&amp;</code> and <code>!</code> operators bind more tightly than
sequencing.</p>

<p>With <code>x&amp;</code> or <code>x!</code>, the expression <code>x</code> is
parsed speculatively to check whether it appears next in the input or not.
Whether the expression <code>x</code> succeeds or fails, the parser backtracks
to the beginning. Then <code>x&amp;</code> succeeds if the parsing of
<code>x</code> succeeded, whereas <code>x!</code> succeeds if the parsing of
<code>x</code> failed. For example:</p>

<pre>statement = (type identifier)&amp; declaration / assignment
</pre>

<p>The parser looks ahead to see if there is a type and identifier next in the
input. If there is, the parser backtracks to the point before the type, but
continues with the same alternative and parses a declaration. If the lookahead
fails, an assignment is parsed. A negative example is:</p>

<pre>string = '"' ('"'! visible)* '"'
</pre>

<p>This says that a string contains any visible character other than a double
quote. The bracketed expression only matches a visible character if a double
quote does not appear next in the input.</p>

<p>Lookahead expressions are regarded only as ways to decide which alternative
to take, so actions and error reporting are suspended. During has and not
operations <code>x&amp;</code> or <code>x!</code>, actions and error markers are
ignored. A see operation <code>[x]</code> is equivalent to <code>x&amp;
x</code>, so actions and error reporting are only performed if <code>x</code>
succeeds.</p>

<p>The fact that actions are not performed during speculative parsing restricts
the possible context sensitive aspects of a language, which can only depend on
actions outside of lookahead constructs. Lookahead is regarded only as a way of
deciding which alternative to take.</p>

<h3 id="text">Text</h3>

<p>Text notations are used to match input characters. Single quotes indicate
individual characters, e.g. <code>'x'</code> matches the letter <code>x</code>.
Several characters in single quotes indicate a set of distinct alternatives, any
one of which can be matched.  For example:</p>

<pre>op = '+-*/'
digit = '0123456789'
</pre>

<p>The expression <code>'+-*/'</code> matches any one of the four arithmetic
operator characters, and is equivalent to <code>'+' / '-' / '*' / '/'</code>.
The expression <code>'0123456789'</code> matches any digit.</p>

<p>Double quotes indicate a string of characters, which are matched in sequence.
For example:</p>

<pre>keyword = "int" / "if" / "while" / ...
pi = "&#960;"
</pre>

<p>The string <code>"int"</code> only matches if all three characters appear in
the input in sequence, i.e. it is equivalent to <code>['i' 'n' 't']</code>. The
square brackets indicate that if a string matches only partially, the input
position returns to the beginning of the string, and other alternatives can be
tried.</p>

<p>Single characters can be represented using either single or double
quotes. For example:</p>

<pre>double_quote = '"'
single_quote = "'"
</pre>

<p>Grammar files are assumed to use the UTF-8 encoding, and any Unicode
characters can be used in set or string quotes. However, in sets, each code
point is treated as a separate character. Where graphemes might be involved,
care needs to be taken. For example, <code>'é'</code> is visually ambiguous
because it could contain one or two code points, depending on whether a combiner
is used. If it contains two code points, writing it as <code>"é"</code> is more
likely to convey the intended meaning. Similarly, <code>'éè'</code> is probably
better written as <code>"é" / "è"</code>.

<p>There is no escape convention within single or double quotes, because common
escape conventions, apart from being complicated and error prone, don't support
decimal or variable-length character codes. Instead, to represent control
characters, or to represent Unicode characters using plain text, integers are
used. An integer on its own represents a single character, using its decimal
character code. For example:</p>

<pre>pi = 960
newline = 13? 10
</pre>

<p>If an integer is used which starts with a zero digit, then the character
code is in hexadecimal, using <code>a</code> to <code>f</code> or
<code>A</code> to <code>F</code>, e.g.</p>

<pre>pi = 03C0
newline = 0d? 0a
</pre>

<p>There are two ways to form a range of characters:</p>

<pre>letter = 'a..z'
ascii = 0..127
</pre>

<p>The first is a variation of the set notation, with a single character either
side of two dots. The second is a dot-dot operator between two numerical
character codes. These are both atomic tokens, with no spaces either side of the
dots.</p>

<p>Common sets of characters can be specified using Unicode general categories.
The names <code>Uc, Cc, Cf, Cn, Co, Cs, Ll, Lm, Lo, Lt, Lu, Mc, Me, Mn, Nd, Nl,
No, Pc, Pd, Pe, Pf, Pi, Po, Ps, Sc, Sk, Sm, So, Zl, Zp, Zs</code> are provided.
The name <code>Uc</code> represents all Unicode code points (equivalent to
<code>0..1114111</code>), and the others are the standard two-letter
abbreviations for the Unicode general categories which partition all the code
points. For example:</p>

<pre>letter = Lu / Ll / Lt / Lm / Lo
digit = Nd
connector = '_'! Pc
visible = (Cc/Cn/Co/Cs/Zl/Zp)! Uc
</pre>

<p>The Unicode categories starting with <code>L</code> are letters. The letter
rule allows any kind of letters: upper case, lower case, title case, modifier
and other. Categories starting with <code>N</code> are number characters, of
which <code>Nd</code> is the set of decimal digits. The connector rule uses the
<code>Pc</code> connector punctuation category, but excludes the underscore
character. The rule for <code>visible</code> excludes character code points
which are unassigned, private, surrogate, controls, or line or paragraph
separators.</p>

<p>A splitter is a string in angle brackets such as <code>&lt;abc></code> which
represents a lookahead. It does not match any input characters, but succeeds if
the remaining input, regarded as a string, is lexicographically less than or
equal to <code>"abc"</code>. For example:</p>

<pre>keyword = &lt;df> keyword1 / keyword2
keyword1 = "break" / "case" / "catch" / "continue" / "default"
keyword2 = "do" / "else" / "for" / "if" / "switch" / "while"
</pre>

<p>Here, some keywords are listed in alphabetical order, and a splitter is used
to speed up their recognition by separating the keywords up to
<code>"default"</code> from the keywords from <code>"do"</code> onwards. Note
that <code>&lt;default></code> should not be used as the splitter in this
example, because if <code>"default"</code> is next in the input, the input
continues after that and is therefore lexicographically greater. Nor should the
splitter be <code>&lt;do></code>, just in case <code>do</code> is at the end of
the input text.</p>

<p>The empty string <code>""</code> always succeeds, the empty set
<code>''</code> always fails, and the empty splitter succeeds only at the end of
the input:</p>

<pre>succeed = ""
fail = ''
end = &lt;>
</pre>

<h3 id="actions">Actions</h3>

<p>Actions allow a parser to operate on values or data structures, using a
stack, to produce an output. An action is a symbol which consists of the
<code>@</code> character followed by a number followed by a name. If there is no
number, it is assumed to be zero. The name follows the same rules as an
identifier. In particular, it can be a literal name, as discussed in the section
on literals. For example:</p>

<pre>sum = term (plus term @2add)*
</pre>

<p>Suppose that the <code>term</code> rule pushes a single item onto the stack,
and the <code>plus</code> rule doesn't affect the stack. The <code>@2add</code>
symbol in the <code>sum</code> rule indicates that two items should be popped
off the stack, the <code>add</code> action should be performed, which creates a
new item, and the new item should be pushed onto the stack. A parser as a whole
ends with a single item on the stack, which is the output from the parsing
process.</p>

<p>Defining an action as a stack-based operation allows it to be expressed as a
self-contained symbol at a specific point in a grammar. That in turn allows
actions to take part in grammar transformations which move actions away from
their arguments. For example, the above rule can be transformed to these rules,
where the two arguments to the <code>add</code> action are separated:</p>

<pre>sum = term more*
more = plus term @2add
</pre>

<p>The stack is provided and manipulated by external code when a parser is
generated from the grammar. An action symbol such as <code>@2add</code> is
translated into the execution of a fragment of external code. The parser could
be part of a calculator, in which case the <code>add</code> action might add two
numbers. Alternatively, the parser might become part of a compiler, in which
case the <code>add</code> action might combine two expression trees into a
larger tree. When executing a grammar symbolically for testing, the name of the
action is simply printed out.</p>

<p>An action has access to the characters or tokens from the input which have
been matched since the previous action. For example:</p>

<pre>number = digit+ @number
</pre>

<p>The action <code>@number</code> creates a new item from the digits which
have just been matched, and pushes it onto the stack. There is a further
convention which allows matched characters to be discarded. For example:</p>

<pre>spaces = ' '+ @
</pre>

<p>An <code>@</code> sign on its own causes any recently matched characters (or
tokens) to be discarded by the parser, without any external code being
executed.</p>

<!--
<p>Although tokens can be explicitly discarded in this way, it is normal for
actions to use only the most recent token, in which case tokens are effectively
discarded implicitly when they are matched but not acted on.</p>
-->

<p>There are severe consistency restrictions on actions. Every expression or
rule must produce or consume a fixed number of output items. Each alternative in
a choice must create or consume the same number of output items. Within a
repetition, i.e. <code>x*</code> or <code>x+</code> or <code>x?</code>, the
inner expression <code>x</code> must have no net effect on the number of output
items.</p>

<p>The first rule in a grammar must produce a single output item overall.
However, if it doesn't, the error is reported only when attempting to generate a
parser from the grammar. That means, during development and testing, a grammar
with no actions is legal, and also any self-contained fragment of a grammar is
legal.</p>

<p>The compensation for these severe restrictions is that Pecan can carry out
strong consistency checks on grammars, ensuring that there can be no stack
handling errors such as underflow during parsing, and that a fixed number of
output items is produced overall.</p>

<p>Scanners are normally thought of as producing a sequence of tokens. But in
Pecan, even a scanner must produce a fixed number of output items. A scanner
can be defined like this:</p>

<pre>tokens = @tokens token+ end
token = id @1id / number @1number / ...
</pre>

<p>The <code>@tokens</code> action creates an output item representing the list
or array of tokens to be generated, initially empty. Each action such as
<code>@1id</code> takes the recently matched characters, creates a token from
them, and adds it to the list. The list is the only output from the scanner.</p>

<p>In a token-based parser, there are often variable-length sequences, which
need to be dealt with in a similar way. For example, a comma-separated list of
identifiers can be expressed by:</p>

<pre>ids = @list id @2id ("," id @2id)* @1end
</pre>

<p>The <code>id</code> rule is assumed to push a single item onto the output
stack. The <code>@list</code> action creates an empty list. The
<code>@2id</code> action pops the list and most recent id, adds the id to the
list, and pushes the resulting list back on the stack. The <code>@1end</code>
action does anything necessary to finalize the list.</p>

<p>The external code in a generated parser may choose a different implementation
with the same overall effect. For example, <code>@list</code> may mark a
position in the output stack, <code>@2id</code> may do nothing, so that ids
accumulate on the stack, and <code>@1end</code> may use the marked stack
position to create an array out of the accumulated ids. Alternatively,
<code>@list</code> could create a linked list, each subsequent
<code>@2id</code> could chain the next id onto the end of the list, and
<code>@1end</code> could do nothing.</p>

<p>Techniques like this for handling variable-length lists can easily lead to a
left hand alternative which begins with an action, for example:</p>

<pre>@a x / y
</pre>

<p>The action <code>@a</code> is performed whether or not <code>x</code>
succeeds. This is not completely intuitive, and probably not what was intended.
It is not reported during development, so that transformations remain valid, but
is reported as a warning when compilation is requested. A similar situation
arises with error markers:</p>

<pre>#m x / y
</pre>

<p>However, the fact that the marker takes effect even if <code>x</code> fails
is normal, so that if parsing as a whole fails without progressing beyond this
point, the marker is reported as one of the things expected.</p>

<h3 id="errors">Errors</h3>

<p>By default, a parser produces an error message which points to the furthest
position reached in the input text, other than in lookaheads, but which gives no
details. For example, suppose this rule is being parsed:</p>

<pre>sum = number ("+" number / "-" number)
</pre>

<p>Then a message like this might be produced for an incorrect operator:</p>

<pre>Error on line 1:
40%2
  ^
</pre>

<p>Markers can be added to parser rules, to describe the items which would have
allowed parsing to continue. A marker is a symbol consisting of the
<code>#</code> character followed by a name. The name has the same form as an
identifier. In particular, it can be literal, as described in the literals
section. For example, suppose the rule above is changed to:</p>

<pre>sum = number (#plus "+" number / #minus "-" number)
</pre>

<p>Then, for an incorrect operator, the expressions <code>"+"</code>
and <code>"-"</code> both fail, so the error message produced becomes:</p>

<pre>Error on line 1: expecting minus, plus
40%2
  ^
</pre>

<p>When a marker is encountered, it is associated with the current position in
the input. It records something that the parser is expecting at that point. If
progress is made past that input position, the markers are cleared. When the
parser encounters an error, the set of things that the parser was expecting at
that point can be reported. Duplicates are removed, for example suppose the rule
is changed to:</p>

<pre>sum = number (#operator "+" number / #operator "-" number)
</pre>

<p>Then the error message becomes:</p>

<pre>Error on line 1: expecting operator
40%2
  ^
</pre>

<p>During testing, the order in which markers are reported is alphabetical. When
a grammar is compiled, the order is determined by the external code.</p>

<p>One way to ensure that all the items which could possibly allow parsing to
continue are reported is to write separate rules to describe low level features
of a grammar involving primitive character matchers, i.e. strings, sets,
character codes, or Unicode identifiers, and begin each with a marker. For
example, a parser for a programming language might contain rules such as:</p>

<pre>plus = #operator "+" @
letter = #letter (Lu / Ll / Lt / Lm / Lo)
number = #number ('0'..'9')+ @number
newline = #newline 13? 10 @
end = #end &lt;>
</pre>

<p>The <code>plus</code> rule specifies that the plus sign is to be described as
an operator in error messages, that it may be followed by optional spaces, and
that the plus sign and spaces are discarded. The <code>letter</code> rule
applies an error marker to a choice of Unicode categories, to avoid having to
attach a marker to each one individually.</p>

<p>With these rules, an incorrect operator might lead to an error message which
says that an operator is expected. The fact that an extra digit on the preceding
number, or a space, could also have allowed parsing to continue is not reported.
That is because individual digits and spaces in the rules haven't been given
markers.</p>

<h3 id="tokens">Tokens</h3>

<p>Support is provided for parsers where the input consists of tokens produced
by a separate scanner. The input is thought of as an array of tokens instead of
an array of characters.</p>

<p>A tag is represented as a symbol consisting of the <code>%</code> character
followed by a name. The name has the same form as an identifier. In particular,
it can be literal, as described in the next section. Each tag represents a
specific kind of token. For example, a token-based parser for a simple
calculator with no brackets might look like this:</p>

<pre>sum = term (%plus term @2add / %minus term @2subtract)* end
term = number (%times number @2multiply / %over number @2divide)*
number = %number @number
end = &lt;>
</pre>

<p>In this case, the input is an array of tokens with tags <code>%number</code>,
<code>%plus</code>, <code>%minus</code>, <code>%times</code> or
<code>%over</code>.</p>

<p>In token-based parsers, text matching notations are not allowed, except for
<code>''</code>, <code>""</code> and <code>&lt;></code>. However, the set and
string notations are reused for literal identifiers.</p>

<h3 id="literals">Literals</h3>

<p>The names used in identifiers, actions, markers and tags normally consist of
a letter followed by letters, digits, hyphens or underscores. Literal names can
be used as an alternative. A literal name consists of one or more characters
inside double quotes, or inside single quotes, as with the string and set
notations. This helps to make grammars more readable when a separate scanner and
parser are being designed. For example, a scanner might contain:</p>

<pre>ge = ">=" @1">="
</pre>

<p>The names of the actions are being used as token tags, so <code>@1">="</code>
creates a token and sets its tag to <code>>=</code>. When compiling the scanner,
each character in the literal name is converted to an alphanumeric form, e.g.
<code>>=</code> becomes <code>GtEq</code>, so that it forms a valid identifier
in the target programming language. The literal notation avoids the need to
invent an identifier name for the tag for each token with a fixed spelling.</p>

<p>In the corresponding token-based parser, the tag name produced can be matched
by a tag with the same literal name. For example:</p>

<pre>ge = #op %">="
</pre>

<p>The same translation to alphanumeric form is used so, in the compiled parser,
the tag <code>%">="</code> becomes identifier <code>GtEq</code> and the parser
matches up with the scanner.</p>

<p>To improve the readability of a token-based parser further, e.g. so that it
corresponds closely to a published grammar, literal names can also be used for
identifiers. For example:</p>

<pre>comparison = expression ">=" expression
...
">=" = #op %">="
</pre>

<p>For an alphanumeric literal, the quotes have no effect, so <code>"int"</code>
is equivalent to <code>int</code>, making the quotes unnecessary, but using
<code>"int"</code> may still be desirable to emphasize that the identifier
stands for a keyword token with a fixed spelling.</p>

<p>When a grammar is compiled to produce a parser, custom adjustments can be
specified for each different type of name, to prevent name clashes. The same
adjustment should be specified for actions in the scanner and for tags in the
parser, so that the generated tag names correspond.</p>

<h2 id="testing">Testing</h2>

<p>During development of a grammar, testing can be carried out by symbolic
execution without having to generate a parser. This is done by typing a command
of the form:</p>

<pre>pecan [-t | -trace] [line] testfile
</pre>

<p>The test file contains the tests to be carried out. The <code>-trace</code>
option switches on tracing, so that the individual steps taken during parsing
are displayed. If a line number is given, only the single test that starts on
that line of the test file is executed.</p>

<p>A test file contains a number of sections separated by lines consisting of
three or more equal signs. If a section contains a line of three or more minus
signs as a separator, then it is a test with sample input and expected output.
If a section has no minus sign separator, it is a grammar or grammar fragment
which is used for subsequent tests, until another grammar is given. For
example:</p>

<pre>// Match one digit
number = ("0".."9") @number
==========
2
..........
number 2
==========
42
----------
number 4
==========
// Match any number of digits
number = ("0".."9") @number
==========
42
----------
number 42
</pre>

<p>The first section of this file sets up a grammar, then there are two tests
using that grammar, then a new grammar is given, then there is a final test
using the second grammar.</p>

<p>The output from running a test using a given grammar and sample input is a
list of the actions that would be performed by a parser generated from the
grammar. If the input is text, the characters matched since the previous action
or discard are displayed.</p>

<p>For a token-based grammar, the input consists of a sequence of tag names
separated by white space:</p>

<pre>// Match a list of numbers.
list = %number @value (%comma %number @value @2and)*
==========
number comma number comma number
----------
value
value
and
value
and
</pre>

<p>When a test fails, its line number is reported in the error message. That
line number can then be used to re-run the testing, but picking out only that
one test to be performed, perhaps with tracing:</p>

<pre>pecan tests.txt
Fail test on line 24 of tests.txt:
---------- Expected ----------
...
---------- Actual ----------
...

pecan -trace 24 tests.txt
...
</pre>

<p>A section of the test file can consist of a single line. If the line starts
with <code>//</code>, the section is ignored as a comment. Otherwise, if the
line doesn't contain an equal sign, it has a special meaning. It is the name of
a file containing a grammar to be used for subsequent tests. This supports the
common case where the grammar is in one file and its tests are in another:</p>

<pre>// The next section imports the grammar file.
==========
grammar.txt
==========
// First test
...
</pre>

<p>A single-line section can alternatively be the name of a secondary test file
to execute, allowing a suite of tests to be split across several files:</p>

<pre>// Do testing in stages.
==========
stage1.txt
==========
stage2.txt
==========
...
</pre>

<p>There is no conflict between a filename representing a grammar and one
representing a subfile of tests. That is because a grammar file is equivalent to
a test file which sets up a grammar, but contains no tests.</p>

<p>Test files can use the UTF-8 encoding, but there is also an escape convention
which allows control characters or Unicode characters to be included as plain
text. A backslash followed by digits represents a character by its decimal code,
or by its hex code if the code starts with zero. Two backslashes are used to
represent a single backslash. A backslash followed by any other character
removes that character. In particular, a backslash followed by a space can be
used as a separator, and a backslash followed by a newline can be used to cancel
the newline. For example, given that <code>960</code> is the decimal code for
the character &#960;, then:</p>

<ul style="list-style-type:none;">
<li><code style="display:inline-block;width:5em;">\960x</code>
is &#960; followed by x</li>
<li><code style="display:inline-block;width:5em;">\960\ 5</code>
is &#960; followed by the digit <code>5</code></li>
<li><code style="display:inline-block;width:5em;">\\960x</code>
is the five characters <code>\960x</code></li>
<li><code style="display:inline-block;width:5em;">...\13\</code>
is a line ending in CR instead of LF</li>
</ul>

<h2 id="checks">Consistency checks</h2>

<p>A number of checks are performed on a grammar which help to ensure
consistency. Some obvious checks are done first, such as syntax checking of the
grammar, checking that each rule name is defined exactly once, and checking that
no rule name clashes with a category name.</p>

<p>A grammar is checked to see if it represents a text parser or a token parser.
A text parser must contain no tags. A token parser must not contain text
matchers, i.e. strings, splitters, sets, ranges or numbers, with the exception
of <code>""</code> or <code>''</code> or <code>&lt;></code>. However, a token
parser may reuse the string or set notations to form literal identifiers, but
there must be a rule defining each such identifier.</p>

<p>There are also checks on ranges. For a range of the form <code>'a..z'</code>
there is a check that there is a single code point either side of the
<code>..</code> and that the range is non-empty. A range of the form
<code>0..31</code> must also be non-empty.</p>

<p>Many parsing expressions are
equivalent, which considerably reduces the number of cases that need be
discussed. For example:</p>

<pre>32        &#8801;  ' '
'a'       &#8801;  "a"
"ab"      &#8801;  ['a' 'b']
'ab'      &#8801;  'a' / 'b'
'a..z'    &#8801;  'a' / ... / 'z'
Ll        &#8801;  'a' / ... / 'z' / ...
x?        &#8801;  x / ""
x*        &#8801;  xs  where  xs = (x xs)?
x+        &#8801;  x x*
[x]       &#8801;  x&amp; x
x&        &#8801;  x!!
''        &#8801;  ""!
&lt;ab>      &#8801;  (&lt;> / 0..96 / 97 &lt;> / 97 0..97)&
</pre>

<p>The core features remaining are:</p>

<pre><code>id = x</code>      rules
<code>""</code>          the empty string (always succeeds)
<code>"x"</code>         single characters
<code>x/y</code>         choices
<code>x y</code>         sequences
<code>x!</code>          the 'not' lookahead
<code>%a</code>          tags
<code>@2a, @a, @</code>  actions
<code>#a</code>          markers
</pre>

<p>The main remaining checks are making sure that there is no left recursion,
and that output items are handled consistently.</p>

<h3 id="loop">Left recursion checking</h3>

<p>Pecan checks that the grammar contains no infinite loops caused by left
recursion. The simplest example is where a rule mentions its own name at the
start of its right hand side, or at the start of one of its alternatives:</p>

<pre>sum = sum "+" term / term
</pre>

<p>In a Pecan grammar, a rule of this form leads to an immediate infinite loop,
and so is reported as an error. Indirect left recursion is also detected. That
is where two or more rules mention each other at the beginning:</p>

<pre>expression1 = expression2 ...
expression2 = expression1 ...
</pre>

<p>Less obvious cases of left recursion are also detected, e.g.</p>

<pre>statement = label* statement
</pre>

<p>Although <code>statement</code> does not mention itself right at the
beginning, the expression <code>label*</code> may succeed without any input
being matched, and therefore an infinite loop ensues.</p>

<p>To implement the checks, four boolean properties of expressions
<code>SP</code>, <code>SN</code>, <code>FP</code>, <code>FN</code> are
calculated for each expression. The <code>SP</code>, <code>SN</code> properties
mean the expression can succeed with or without progress being made in the
input, and <code>FP</code>, <code>FN</code> mean that an expression can fail,
with or without progress. These are very similar way to the properties used in
the analysis of PEG grammars, though there <code>FP</code> and <code>FN</code>
are not distinguished.</p>

<p>As well as the equivalences already mentioned, there are further parsing
expressions which are equivalent from the point of view of success or failure,
and progress or not:</p>

<pre>%a          &#8801;  "a"
@2a, @a, @  &#8801;  ""
#a          &#8801;  ""
</pre>

<p>The way the properties are calculated for the remaining features of grammars
(using <code>&amp;</code> for 'and' and <code>|</code> for 'or', with
<code>&amp;</code> binding tighter, and using <code>def(id)</code> for the right
hand expression of a rule for identifier <code>id</code>) are:</p>

<pre>SN(id) = SN(def(id))
SP(id) = SP(def(id))
FN(id) = FN(def(id))
FP(id) = FP(def(id))

SN("") = true
SP("") = false
FP("") = false
FN("") = false

SP("a") = true
FN("a") = true
SN("a") = false
FP("a") = false

SN(x y) = SN(x) &amp; SN(y)
SP(x y) = SP(x) &amp; SP(y) | SP(x) &amp; SN(y) | SN(x) &amp; SP(y)
FN(x y) = FN(x) | SN(x) &amp; FN(y)
FP(x y) = FP(x) | SN(x) &amp; FP(y) | SP(x) &amp; FN(y) | SP(x) &amp; FP(y)

SN(x/y) = SN(x) | FN(x) &amp; SN(y)
SP(x/y) = SP(x) | FN(x) &amp; SP(y)
FN(x/y) = FN(x) &amp; FN(y)
FP(x/y) = FP(x) | FN(x) &amp; FP(y)

SN(x!) = FN(x) | FP(x)
SP(x!) = false
FN(x!) = SN(x) | SP(x)
FP(x!) = false
</pre>

<p>Because the rules are themselves recursive, fixed point iteration is used,
i.e. the values are calculated repeatedly until they don't change. If all the
values are set to <code>false</code> at the start, the only possible changes are
from <code>false</code> to <code>true</code>, so the iteration terminates.</p>

<p>Once these values are known, a further boolean property, <code>WF</code> is
calculated to check that the grammar is well formed. The <code>WF</code>
property is calculated (using <code>~</code> for 'not') by:</p>

<pre>WF(id) = WF(def(id))
WF("") = true
WF("a") = true
WF(x y) = WF(x) &amp; (~SN(x) | WF(y))
WF(x / y) = WF(x) &amp; WF(y)
WF(x!) = WF(x)
</pre>

<p>If <code>WF</code> turns out to be false for any expression, that expression
is reported as an error because it contains left recursion.</p>

<!--
<h3 id="token">Token checking</h3>


<p>For grammars which have text as input, a check is made that all tokens
produced are non-empty, so that continual progress is made through the
characters in the input. For example:</p>

<pre>id = letter+ @identifier
letter = 'a' .. 'z'
</pre>

<p>Here, it is clear that by the time the accept action
<code>@identifier</code> is reached, at least one letter has been matched from
the input. On the other hand, suppose the <code>id</code> rule was:</p>

<pre>id = letter* @identifier
</pre>

<p>This causes an error message, because <code>@identifer</code> can be reached
without matching any input characters. However, if this <code>id</code> rule
is always used in a context where at least one character has already been
matched, i.e. the <code>id</code> rule refers to the remainder of a token
rather than a whole token, then there is no error.</p>

<p>This check is implemented by making as many deductions as possible about
positions in the grammar at which input characters have definitely been matched
since the previous token. This is a conservative check - it is possible for a
pathological grammar to produce an error message even though no empty token
would ever be created in practice.</p>

<p>There is a further check that a scanner makes no attempt to read past the
end of the input. For example, suppose there is a scanner rule like
this:</p>

<pre>tokens = token+ UC! @end
token =  space / identifier / keyword / operator / punctuation
</pre>

<p>This is fine, because all that follows the end of text <code>''</code> is an
action, not any attempt to match any characters. However, suppose the
rule is:</p>

<pre>tokens = token+
token = space / identifier / keyword / operator / punctuation / end
end = '' @end
</pre>

<p>This does cause an error, because after recognising the end of text, the
scanner could continue to look for more tokens.</p>
-->
<h3 id="output">Output checking</h3>

<p>Actions are assumed to treat output items in a stack-like manner. Restrictive
checks are made to guarantee consistent handling of output items. The arity of
each action has to be specified, and has to be consistent each time the action
appears. For example if a grammar contains both <code>@1add</code> and
<code>@2add</code>, that is reported as an error. The arities are used to check
that each expression in the grammar produces a fixed, known number of output
items.</p>

<p>The net overall number of items added to the stack, possibly negative, is
calculated for each expression in the grammar.</p>

<p>Both alternatives in a choice expression must have the same net effect. For
example, this rule causes an error:</p>

<pre>token = ('0'..'9')+ @token / ' '+
</pre>

<p>The first alternative adds one item to the stack, but the second adds
nothing. On the other hand, this rule is legal:</p>

<pre>token = ('0'..'9')+ @1token / ' '+
</pre>

<p>The <code>@1token</code> action pops an item from the stack, presumably a
list of tokens, and pushes one item back on the stack, presumably the updated
list. It thus has zero net effect. Since both alternatives now have a zero net
effect, the <code>token</code> rule itself can be deduced as having a zero net
effect.</p>

<p>A repeated expression must have zero net effect. For example, suppose the
grammar contains:</p>

<pre>tokens = (('0'..'9')+ @token)*
</pre>

<p>The inner expression causes one output item to be pushed on the stack. This
is reported as an error, because <code>tokens</code> as a whole pushes an
unknown number of items onto the stack. On the other hand, this definition is
allowed:</p>

<pre>tokens = (('0'..'9')+ @1token)*
</pre>

<p>The inner expression pops a previous list item, adds a token to it, and
pushes the updated list onto the stack. As a result, it has a zero net effect.
It can be repeated any number of times, still with a zero net effect, and so the
<code>tokens</code> rule can be deduced to have zero net effect.</p>

<p>As well as repeated expressions, recursion is also restricted so that the
number of output items produced is fixed. For example:</p>

<pre>x = 'a' x @a
</pre>

<p>Here, the number of items pushed onto the stack depends on the number of
times <code>x</code> calls itself recursively. So this is reported as an
error.</p>

<p>A second check is that the stack never underflows. To check this, for each
expression, the number of items which need to be on the stack when the
expression is executed is calculated. For example, the expression
<code>('0'..'9')+ @1token</code> needs one item to be on the stack. There are
situations where the needed number can't be calculated, for example:</p>

<pre>x = 'a' / 'b' @2c x @d
</pre>

<p>Every time <code>x</code> calls itself recursively, one more item is needed
on the stack, even though the net effect of <code>x</code> is zero. Such a
situation is reported as an error.</p>

<p>Any situation where the net effect or the needed number can't be calculated
as a fixed integer is reported. For a complete grammar which is about to be
compiled, the first rule is checked to make sure its net effect is one, and its
needed number is zero, so that stack underflow is impossible.</p>

<p>These checks are conservative, i.e. there could be pathological grammars
which always work correctly in practice, but which don't pass the checks.</p>

<h2 id="compile">Compilation</h2>

<p>A grammar can be compiled either to a set of recursive functions, or to a
bytecode array, in almost any desired target programming language. Compilation
to recursive functions is usually preferred, but compilation to bytecode has
greater language independence, and can be used in more dynamic situations, e.g.
where Pecan is used as a library and grammars need to be compiled without
involving files.</p>

<h3 id="functions">Recursive functions</h3>

<p>Very few restrictions are placed on the target programming language when
compiling to recursive functions. The main assumption is that the language has
two binary and/or operators which are guaranteed to use short-circuit
evaluation, i.e. they do not evaluate their right hand arguments
unnecessarily. In many languages, the symbols <code>&amp;&amp;</code> and
<code>||</code> are suitable. The <code>&amp;&amp;</code> operator does exactly
what is required for a sequence <code>x y</code>, evaluating <code>x</code> and
then, only if <code>x</code> succeeds, continuing with <code>y</code>. A choice
<code>x / y</code> is complicated by the need to test whether <code>x</code> has
progressed or not before deciding whether to try <code>y</code> instead. So, in
general, <code>x / y</code> is compiled into something like:</p>

<pre>alt((go() &amp;&amp; x()) || (ok() &amp;&amp; y()))
</pre>

<p>The <code>go</code> function pushes the current input position on a stack
before <code>x</code> is executed, the <code>ok</code> function checks for
progress, and the <code>alt</code> function pops the saved position off the
stack after the choice has been completed.</p>

<p>The <code>go</code> function is also used in the compilation of other Pecan
features. For example, an expression <code>x&amp;</code> is compiled to:</p>

<pre>has(go() &amp;&amp; x())
</pre>

<p>The <code>has</code> function pops the position saved by <code>go</code> and
backtracks to it, before returning the result of <code>x()</code>.</p>

<p>This general approach, using a background stack for progress checking, allows
every parsing expression to be compiled into a boolean expression, with only the
<code>&amp;&amp;</code> and <code>||</code> operators being used to combine
expressions.</p>

<p>A grammar is compiled into recursive functions using a command of the
form:</p>

<pre>pecan grammar -c program
</pre>

<p>The option <code>-c program</code> specifies a template program file. The
file must already exist, and can be written in any desired target programming
language. It must contain a placeholder such as:</p>

<pre>// &lt;pecan
//     comment = "// %s"
//     rule    = "bool %s(parser *p) {%n  return %e;%n}"
//     call    = "%s(p)"
// >
...
// &lt;/pecan>
</pre>

<p>The placeholder begins with a commented out open tag <code>&lt;pecan></code>
with attributes, and ends with a commented out close tag
<code>&lt;/pecan></code>. Lines in between the two tags, if any, are removed,
and the result of compiling the grammar is inserted in their place.</p>

<p>The attributes in the <code>&lt;pecan></code> start tag specify details of
how to generate functions in the target language. The above example would be
suitable for C as a target language. Each attribute must be on a separate line,
and consists of one of the attribute names described below, followed by an equal
sign followed by a string in single or double quotes. The whole attribute may be
preceded or followed by comment characters. Each attribute string is a format
string in a printf style specifying the text to be generated for a specific
Pecan feature.</p>

<p>In a format string, there are no backslash escape conventions. The percent
character is used for specifiers. The specifier <code>%n</code> indicates that a
newline is to be printed. The specifier <code>%e</code> indicates that a parsing
expression is to be compiled and printed. A string can be printed with
<code>%s</code> to copy it verbatim, or <code>%t</code> to translate underscores
or hyphens in non-literal names to <a
href="https://en.wikipedia.org/wiki/Camel_case">camel case</a>, or
<code>%f</code> to additionally capitalize the first letter. A character can be
printed directly using <code>%c</code>, or its integer code can be printed using
<code>%d</code> for decimal, <code>%o</code> for octal, or <code>%x</code> for
hexadecimal. A fixed number of digits can be specified for <code>%d</code>,
<code>%o</code> or <code>%x</code>, e.g. <code>%4x</code>.</p>

<p>Unlike printf format strings, items to be printed are primarily matched up by
type rather than by sequence. For example, in the format string for a rule, a
specifier <code>%s</code> indicates that the name of the identifier is to be
printed, and <code>%e</code> indicates that the right hand expression of the
rule is to be printed, regardless of the order the specifiers appear in, or how
many times they appear, or whether they appear at all. An exception to this is
where two characters are available in the format for a range. In that case,
sequencing is used, i.e. the first specifier encountered relates to the low end
of the range, and the second to the upper end.</p>

<p>Spaces at the beginning of a line represent an indent to be applied to
anything generated from that line. For example, the spaces before
<code>return</code> above represent an indent applied to the entire body of the
function generated by the <code>%e</code> specifier. The number of spaces in the
first indent encountered is used as the amount for any further indenting which
may be added during compilation and pretty printing.</p>

<p>The attributes that can be specified are:</p>

<ul>

<li><p><code><b>comment</b>:</code> the format for generating each line of a
comment before each function generated. The format string might be <code
style="white-space:nowrap">"// %s"</code> or <code
style="white-space:nowrap">"/* %s */"</code> for example. The comment generated
contains the text of the Pecan rule that the function corresponds to. The
default is to have no comments.</p></li>

<li><p><code><b>rule</b>:</code> the format for a function generated from a
rule <code>id = e</code>. The two items available as parameters are the name
of the identifier as a string, and the right hand side as an expression. There
is no default.</p></li>

<li><p><code><b>rule1</b>:</code> an alternative format for a rule, if it fits
on one line. The default is to use the <code>rule</code> format
exclusively.</p></li>

<li><p><code><b>and</b>, <b>or</b>, <b>true</b>, <b>false</b>:</code> the
formats for the boolean operators and constants. The defaults are <code
style="white-space:nowrap">" &amp;&amp; "</code>, <code
style="white-space:nowrap">" || "</code>, <code>"true"</code> and
<code>"false"</code>.</p></li>

<li><p><code><b>call</b>:</code> the format for making a call to a parsing
function. An example where an argument is to be passed to every function to
provide the parsing state might be <code>"%s(p)"</code> whereas if the state is
implicit, <code>"%s()"</code> might be suitable instead. The call format (along
with the <code>rule</code> format) can be used to add a prefix or suffix to
identifier names. For example, a call format <code>"p%f()"</code> would cause an
occurrence of an identifier <code>term</code> to be compiled as
<code>pTerm()</code>. There is no default for the call format.</p></li>

<li><p><code><b>support</b>:</code> the format for generating defaults for calls
to the support functions below. The default for the <code>support</code> format
is to use the <code>call</code> format.</p></li>

<li><p><code><b>go</b>, <b>ok</b>, <b>alt</b>, <b>opt</b>, <b>see</b>,
<b>has</b>, <b>not</b>, <b>tag</b>, <b>end</b>:</code> the formats for simple
support functions. The <code>go</code>, <code>ok</code> and <code>alt</code>
functions are for choices as explained above. The function <code>opt</code> is
for <code>x?</code>, <code>see</code> is for <code>[x]</code>, <code>has</code>
is for <code>x&amp;</code>, <code>not</code> is for <code>x!</code>,
<code>tag</code> is for <code>%x</code>, and <code>end</code> is for
<code>&lt;></code>. Explicit definitions of these formats can be given to change
the case or spelling of the function names generated, or to produce different
inline code. The default format for each of the functions is to specialize the
support format by filling in the function name. For example, if the support
format is <code>"%s(p)"</code> then the default go format is
<code>"go(p)"</code> and the default alt format is
<code>"alt(p,%e)"</code>.</p></li>

<li><p><code><b>text</b>, <b>set</b>, <b>split</b>:</code> the formats for the
main text matchers. The defaults are obtained from the support format by adding
an extra double-quoted string argument to the call. For example, if the support
format is <code>"%s(p)"</code> then the default set format is
<code>'set(p,"%s")'</code>. For example, a Pecan set <code>'+-*/'</code> would
cause <code>set(p,"+-*/")</code> to be printed.</p></li>

<li><p><code><b>range</b>:</code> the format for printing a range of the form
<code>'a..z'</code> or <code>0..127</code>. The two characters can be printed
using <code>%c</code>, or their codes can be printed using a numerical specifier
such as <code>%d</code>. The default adds two character arguments in single
quotes to the support format, e.g. <code>"range(p,'%c','%c')"</code>.</p></li>

<li><p><code><b>cat</b>, <b>mark</b>:</code> the formats for printing a category
such as <code>Nd</code> or an error marker such as <code>#id</code>. The name is
available as a string. The default format strings add a string argument to the
support format, e.g. <code>"cat(p,%s)"</code> and
<code>"mark(p,%s)"</code>.</p></li>

<li><p><code><b>drop</b>:</code> the format for printing a drop symbol such as
<code>@</code> or <code>@2</code>. The default is to add a numerical argument
representing the arity to the support format, e.g.
<code>"drop(p,%d)"</code>.</p></li>

<li><p><code><b>act</b>, <b>act0</b>, ...:</code> the formats for printing
actions generally, and for specific overrides for given arities. The default for
the act format depends on the call format, e.g. <code>"act%d(p,%s)"</code> where
the numerical parameter is the arity and the string parameter is the name of the
action, in this case acting as an enumerated constant. By default, there are no
overrides.</p></li>

<li><p><code><b>escape1</b>, <b>escape2</b>, <b>escape4</b>:</code> formats to
change the way <code>%c</code> and <code>%s</code> work by printing escape
sequences instead of UTF-8. The escape1 format is for control characters in the
ASCII range, the escape2 format for characters beyond ASCII up to hex FFFF, and
escape4 for the remainder of the Unicode character set. The defaults are
<code>"\%3o"</code>, <code>"\u%4x"</code>, and <code>"\U%8x"</code>. These
work in C and several other languages. (In C, these escape sequences have a
length limit. Using <code>"\%2o"</code> or <code>"\x%2x"</code> for example,
would not be safe because digits could follow.)</p></li>

</ul>

<p>These format strings provide considerable flexibility. For example,
compilation to Java could be specified by:</p>

<pre>// &lt;pecan
//     comment = "// %s"
//     rule    = "  boolean %s() {%n    return %e;%n  }"
//     call    = "%s()"
// >
</pre>

<p>This establishes an indent for all the methods generated, and passes no
arguments to parsing functions because the state is implicitly made available by
the surrounding object.</p>

<p>For <code>go</code>, <code>ok</code>, <code>alt</code>, the format
can be the empty string <code>""</code> to switch off the special treatment of
choices. That would suit a functional language such as Haskell, for example,
where custom operators can be defined with lazy evaluation, so the resulting
code would be equivalent to using a parser combinator library.</p>

<p>The default act format treats action names as enumerated constants. Instead,
the act format could be specified as <code>"%s()"</code> so that each action has
its own function with implicit arity. Alternatively, the act0 format could be
specified as <code>"push(0,%s(string()))"</code>, the act1 format as
<code>"push(1,%s(top(0)))"</code>, the act2 format as
<code>"push(2,%s(top(1),top(0)))"</code> and so on as necessary, so that the
handling of the output stack is covered by the generated code and only pure
external functions need to be provided. Here <code>string()</code> forms a
string from the recently matched characters, <code>top(n)</code> returns the
n'th item from the top of the output stack and <code>push(n,x)</code> pops n
items from the output stack before pushing its argument.</p>

<h3 id="bytecode">Bytecode</h3>

<p>Compilation of a grammar into bytecode is provided, along similar lines to
compilation into recursive functions. An interpreted bytecode is somewhat
similar to the table-driven techniques used in bottom-up CFG-based parser
generators.</p>

<p>This bytecode facility is provided mainly for demonstration purposes. The
real advantage of a bytecode approach would be in a library setting. For
example, one could imagine an editor or IDE which uses a variant of Pecan as a
library. It could dynamically load a Pecan language description file, according
to the language of the source file it is editing, convert the description to a
bytecode, and interpret the bytecode to parse the source file. This would be
preferable to writing out a parser program, compiling it, then dynamically
loading it on the fly. The process of loading a language description and
compiling it to bytecode could bypass much of the processing currently built
into Pecan, assuming that the description was previously developed and tested
offline.</p>

<p>A grammar is compiled into bytecode using a command of the form:</p>

<pre>pecan grammar -b program
</pre>

<p>The option <code>-b program</code> specifies a template program file
containing an interpreter for the bytecode. The file must already exist, as a
source file template, written in any desired target programming language. It
must contain a placeholder such as:</p>

<pre>// &lt;pecan>
    ...
// &lt;/pecan>
</pre>

<p>The placeholder begins with an open tag <code>&lt;pecan></code> in a
target-language comment and ends with a close tag <code>&lt;/pecan></code>, also
embedded in a comment. Lines in between, if any, are removed, and the result of
compiling the grammar is inserted.</p>

<p>The bytecode sequence is printed as text, as a comma-separated list of
unsigned byte values. Those values which are opcodes, categories, tags, actions
or error markers are represented symbolically. Suppose the grammar file
contains:</p>

<pre>digit = '0..9' @number
</pre>

<p>Then the bytecode sequence generated might be:</p>

<pre>START, 6, LOW, 1, 48, HIGH, 1, 57, ACT, number, STOP
</pre>

<p>The values of the symbols are specified by the surrounding interpreter, eg.
using enumerations to define each symbol as a number in the range <code>0</code>
to <code>255</code>. By default, the same names are used as in the grammar,
after removing the prefix character. That means the names of actions, error
markers and tags must normally all be distinct.</p>

<p>In a library setting, values for opcodes and names in the grammar would be
passed to the Pecan compiler, and an array of bytes returned.</p>

<p>An interpreter can be constructed by taking the example interpreter provided,
translating it into the desired programming language, and adapting it to a
particular application by customising tags, actions and error handling as
appropriate.</p>

<p>The bytecode produced from a grammar is a fairly simple flattening of the
parse tree for the grammar. Examples are given of how every construct is
translated into bytecode:</p>

<pre>{id = x}    =   START, nx, {x}, STOP
</pre>

<p>A rule is translated using the <code>START</code> and <code>STOP</code>
opcodes. The notation <code>{x}</code> means "the bytecode sequence generated
for expression x" and <code>nx</code> stands for the number of bytes in
<code>{x}</code>. The <code>START</code> opcode takes a one-byte operand in the
range 0..255, whereas <code>STOP</code> needs no operand.</p>

<p>If any instruction needs an operand which is greater than 255, a variant of
the opcode can be used which takes a two-byte operand. There may also be
variants which allows a one-byte operand to be omitted for some small
values.</p>

<p>The <code>START</code> opcode creates a call to <code>{x}</code>, setting up
the address of <code>STOP</code> as the return address. The <code>STOP</code>
instruction ends parsing. The operand <code>nx</code> to <code>START</code> can
be thought of as a relative offset in the code, from the position after the
<code>START</code> instruction to the <code>STOP</code> instruction.</p>

<p><code>START</code> and <code>STOP</code> opcodes are generated for every
rule, even though they are only executed once for the overall call to the
parser. This is so that any rule can be used as an entry point, if desired. The
bytecode can be scanned, skipping the body <code>{x}</code> of each rule using
the number <code>nx</code>, to find the start of the next rule.</p>

<pre>{id}        =   GO, px
{id}        =   BACK, px
</pre>

<p>When the name <code>id</code> of a rule such as <code>id = x</code> is used
elsewhere in the grammar, it is translated using <code>GO</code> or
<code>BACK</code>. The number <code>px</code> is an offset in the code to the
body <code>{x}</code> of the relevant rule, relative to the end of the
instruction. The <code>GO</code> opcode is used when the offset is positive, and
<code>BACK</code> is used, with a positive operand, when the offset is
negative.</p>

<pre>{"a"}       =   STRING, 1, 97
{97}        =   STRING, 1, 97
{128}       =   STRING, 2, 194, 128
{"ab"}      =   STRING, 2, 97, 98
{""}        =   STRING, 0
{"&#960;"}       =   STRING, 2, 207, 128
{"a&#960;"}      =   STRING, 3, 97, 207, 128
{'&#960;'}       =   STRING, 2, 207, 128
{&lt;a>}       =   LESS, 1, 97
{&lt;ab>}      =   LESS, 2, 97, 98
{'a..z'}    =   LOW, 1, 97, HIGH, 1, 122
{'&#945;..&#969;'}    =   LOW, 2, 206, 177, HIGH, 2, 207, 137
{''}        =   SET, 0
{'a'}       =   SET, 1, 97
{'ab'}      =   SET, 2, 97, 98
{'&#945;&#946;'}      =   SET, 4, 206, 177, 206, 178</pre>

<p>A character matching opcode is followed by a one-byte count, and then that
number of bytes in UTF-8 format. For opcodes other than <code>SET</code>, a byte
sequence containing characters of mixed UTF-8 lengths causes no problem, because
UTF-8 text can be compared byte by byte, without taking account of character
boundaries. With the <code>SET</code> opcode, a sequence with mixed UTF-8 byte
lengths cannot be handled byte by byte, but the first byte of each character can
be used to find the character's length.</p>

<pre>{@a}        =   ACT, a
{@}         =   DROP
{#e}        =   MARK, e
{%id}       =   TAG, id
{Nd}        =   CAT, Nd
</pre>

<p>An action is translated using the <code>ACT</code> opcode. Actions need to be
switched off during has <code>x&amp;</code> or not <code>x!</code> expressions.
An integer keeps track of the depth of nesting of lookahead constructs, and
actions are only performed if the integer is zero. For see <code>[x]</code>
expressions, if <code>x</code> contains actions, it is transformed to
<code>(x&amp; x)</code> before compiling.</p>

<p>Error markers, signalled by the <code>MARK</code> opcode, are collected as a
set, and cleared whenever a new marker is found further on in the input. Tags
are used only in token-based parsers. They cause a call to external code to find
the tag of a particular token. Currently, there is a limit of 256 different
action names, 256 marker names, and 256 tag names, so that only one-byte
operands are needed. If the interpreter uses a 64-bit integer as a bitset of
markers, then there is a limit of 64 marker names.</p>

<p>A category is translated using the <code>CAT</code> opcode. The target
programming language may not have a facility for finding the category of a
character. Even if it does, the category information may vary according to the
version of the language. For stable category information, Pecan provides a
two-stage lookup table in the two files <code>table1.bin</code> and
<code>table2.bin</code> which may be read into memory by the target
language.</p>

<pre>{x/y}       =   EITHER, nx, {x}, OR, {y}
{x y}       =   BOTH, nx, {x}, AND, {y}
</pre>

<p>The <code>EITHER</code> opcode initializes a choice, and <code>OR</code>
checks what happens after <code>{x}</code> to decide whether or not to continue
with <code>{y}</code>. Similarly, the <code>BOTH</code> and <code>AND</code>
opcodes handle a sequence. The <code>EITHER</code> or <code>BOTH</code> opcode
can be thought of as causing a call to <code>{x}</code> returning to
<code>OR</code> or <code>AND</code>, which causes a tail-call to
<code>{y}</code>.</p>

<pre>{x?}        =   MAYBE, ONE, {x}
{x*}        =   MAYBE, MANY, {x}
{x+}        =   DO, AND, MAYBE, MANY, {x}
{[x]}       =   LOOK, TRY, {x}
{x&amp;}        =   LOOK, HAS, {x}
{x!}        =   LOOK, NOT, {x}
</pre>

<p>The <code>MAYBE</code> opcode initializes a repetition, then causes a call to
<code>{x}</code>, returning to <code>ONE</code> or <code>MANY</code>. The
<code>ONE</code> opcode converts the result of <code>{x}</code> into the result
of <code>x?</code>. The <code>MANY</code> opcode is similarly executed after
<code>{x}</code> and checks the result of <code>{x}</code> to decide whether or
not to call it again. The opcode sequence used here, with the termination check
before the code for <code>{x}</code>, avoids the need for an <code>nx</code>
operand. The code for <code>x+</code> is equivalent to the code for <code>x
x*</code>, except that the <code>DO</code> opcode avoids the need for a second
copy of <code>{x}</code> by jumping forwards to <code>{x}</code>, and arranging
for the call to return to <code>AND</code>. The <code>LOOK</code> opcode
initializes any of the lookahead constructs, arranging to return to
<code>TRY</code> or <code>HAS</code> or <code>NOT</code> which sorts out the
result.</p>


<!--, and a tag is translated using the
<code>TAG</code> opcode-->

<p>Further details of what each opcode does can be gleaned from the provided
interpreters and their comments.</p>

<p>The main example interpreter currently provided is in C. It can be used as
starting point for developing interpreters in other languages:</p>

<p class="indent"><a href="interpret.h">interpret.h</a><br/>
<a href="interpret.c">interpret.c</a></p>

<p>There is an array of characters or tokens as input, and two indexes
<code>start</code> and <code>in</code> into it. The items up to
<code>start</code> have been processed, and <code>in</code> is the current
position. So when an action is performed, the items between <code>start</code>
and <code>in</code> are processed, and <code>start</code> is updated to be equal
to <code>in</code>.</p>

<h2 id="transforms">Transforms</h2>

<p>The Pecan grammar language is intended to be sufficiently simple and precise
to support equational transforms. At present, such transforms are carried out
manually and informally on grammars, but it is possible to imagine a theory of
transforms being developed more formally and used to develop and justify
automatic optimisations, or to build an assistant which would suggest and check
user-driven transforms while developing grammars. Equations such as these can be
used:</p>

<pre>(x y) z == x (y z)
(x / y) / z == x / (y / z)
x+ == x x*
x* = (x+)?
x? = x / ""
[[x] y] z == [x y] z
[x y] z / [x u] v == [x] ([y] z / [u] v)
(x / y) z = x z / y z
</pre>

<p>Care has to be taken, because not all 'obvious' equations hold. For example,
<code>x (y / z)</code> is not equivalent to <code>x y / x z</code> because if
<code>x</code> succeeds, in the first case the parser is free to make the choice
between <code>y</code> and <code>z</code>, but in the second case it is already
committed to <code>y</code>. Also <code>x / y</code> and <code>y / x</code> are
not equivalent. However, they are equivalent if it can be established that
<code>x</code> and <code>y</code> begin differently. In these equations, actions
and error markers are included, and the transformed expression has precisely the
same output effect and error handling properties as the original.</p>

<h2 id="changes">Recent changes</h2>

<p>The previous version of Pecan was 0.4. Changes in version 1.0 are:</p>

<ul>
<li>error markers are no longer postfix</li>
<li>the splitter notation <code>&lt;abc></code> and end notation
    <code>&lt;></code> have been added</li>
<li>backquoted tags have been replaced by literal names</li>
<li>separate grammar and test files are supported</li>
<li>one test file can be called from within another</li>
<li>compilation to recursive functions and bytecode is supported</li>
</ul>

<!--
<h2>Tutorial Topics</h2>

<p>Topics: grammar operators, left recursion, right recursion, iteration.
Stack-based actions. Actions not done and undone if backtrack. Actions can do
stuff or build trees. Built-in scanning and drawbacks. Separate scanner. How
to join them up.</p>
-->

</body>
</html>
